%% This BibTeX bibliography file was created using BibDesk.
%% https://bibdesk.sourceforge.io/

%% Created for Deborah Apthorp at 2024-02-02 13:05:13 +1100 


%% Saved with string encoding Unicode (UTF-8) 



@article{rossion_what_2019,
	abstract = {Typical human adults recognize numerous individuals from their faces accurately, rapidly and automatically, reaching a level of expertise at individual face recognition that is important for the quality of their social interactions. A non-human species of primates, the rhesus monkey, has been used for decades as a model of human face processing, in particular for understanding the neural basis of individual face recognition. However, despite responding specifically to faces behaviourally and neurally, this species, as well as other Old World and New World monkeys, is remarkably poor at individuating faces of conspecifics. Following extensive conditioning, monkeys only achieve moderate performance at individual face matching tasks where image-based cues are available. Contrary to humans, monkeys do not show a systematic inversion effect in such tasks, or an advantage for matching face pictures of familiar versus unfamiliar individuals, indicating that they do not rely on qualitatively similar individual face recognition processes as humans. These observations concur with the characteristics of the rhesus monkey cortical face processing system, which lacks two critical aspects for human expertise at individual face recognition: a distinct ventral face-selective pathway and a right hemispheric specialization. While the rhesus monkey brain is undoubtedly an informative non-human model for studying the neural basis of social behaviour and visual cognition, it does not provide an adequate model of human individual face recognition. More generally, this review urges for caution when drawing direct inferences across species without sufficient homologies in behaviour and anatomico-functional landmarks.},
	author = {Rossion, Bruno and Taubert, Jessica},
	doi = {10.1016/j.visres.2018.03.012},
	file = {ScienceDirect Snapshot:files/3154/S0042698918301160.html:text/html},
	issn = {0042-6989},
	journal = {Vision Research},
	keywords = {Expertise, Fusiform gyrus, Human brain, Individual face recognition, Monkey},
	month = apr,
	pages = {142--158},
	series = {Face perception: {Experience}, models and neural mechanisms},
	title = {What can we learn about human individual face recognition from experimental studies in monkeys?},
	url = {https://www.sciencedirect.com/science/article/pii/S0042698918301160},
	urldate = {2024-02-02},
	volume = {157},
	year = {2019},
	bdsk-url-1 = {https://www.sciencedirect.com/science/article/pii/S0042698918301160},
	bdsk-url-2 = {https://doi.org/10.1016/j.visres.2018.03.012}}

@article{towler_are_2019,
	author = {Towler, A. and Kemp, R. I. and Bruce, V. and Burton, A. M. and Dunn, J. D. and White, D.},
	doi = {10.1098/rsos.180772},
	file = {Full Text PDF:files/3157/Towler et al. - 2019 - Are face recognition abilities in humans and sheep.pdf:application/pdf},
	journal = {Royal Society Open Science},
	month = jan,
	note = {Publisher: Royal Society},
	number = {1},
	pages = {180772},
	title = {Are face recognition abilities in humans and sheep really `comparable'?},
	url = {https://royalsocietypublishing.org/doi/10.1098/rsos.180772},
	urldate = {2024-02-02},
	volume = {6},
	year = {2019},
	bdsk-url-1 = {https://royalsocietypublishing.org/doi/10.1098/rsos.180772},
	bdsk-url-2 = {https://doi.org/10.1098/rsos.180772}}

@article{rossion_picture-plane_2008,
	abstract = {Presenting a face stimulus upside-down generally causes a larger deficit in perceiving metric distances between facial features ("configuration") than local properties of these features. This effect supports a qualitative account of face inversion: the same transformation affects the processing of different kinds of information differently. However, this view has been recently challenged by studies reporting equal inversion costs of performance for discriminating featural and configural manipulations on faces. In this paper I argue that these studies did not replicate previous results due to methodological factors rather than largely irrelevant parameters such as having equal performance for configural and featural conditions at upright orientation, or randomizing trials across conditions. I also argue that identifying similar diagnostic features (eyes and eyebrows) for discriminating individual faces at upright and inverted orientations by means of response classification methods does not dismiss at all the qualitative view of face inversion. Considering these elements as well as both behavioral and neuropsychological evidence, I propose that the generally larger effect of inversion for processing configural than featural cues is a mere consequence of the disruption of holistic face perception. That is, configural relations necessarily involve two or more distant features on the face, such that their perception is most dependent on the ability to perceive simultaneously multiple features of a face as a whole. (PsycINFO Database Record (c) 2017 APA, all rights reserved)},
	author = {Rossion, Bruno},
	doi = {10.1016/j.actpsy.2008.02.003},
	file = {Snapshot:files/3159/2008-07751-009.html:text/html},
	issn = {1873-6297},
	journal = {Acta Psychologica},
	keywords = {Face Perception, Facial Features, Visual Perception},
	note = {Place: Netherlands Publisher: Elsevier Science},
	number = {2},
	pages = {274--289},
	title = {Picture-plane inversion leads to qualitative changes of face perception},
	volume = {128},
	year = {2008},
	bdsk-url-1 = {https://doi.org/10.1016/j.actpsy.2008.02.003}}

@article{hole_effects_2002,
	abstract = {The importance of `configural' processing for face recognition is now well established, but it remains unclear precisely what it entails. Through four experiments we attempted to clarify the nature of configural processing by investigating the effects of various affine transformations on the recognition of familiar faces. Experiment 1 showed that recognition was markedly impaired by inversion of faces, somewhat impaired by shearing or horizontally stretching them, but unaffected by vertical stretching of faces to twice their normal height. In experiment 2 we investigated vertical and horizontal stretching in more detail, and found no effects of either transformation.
Two further experiments were performed to determine whether participants were recognising stretched faces by using configural information. Experiment 3 showed that nonglobal vertical stretching of faces (stretching either the top or the bottom half while leaving the remainder undistorted) impaired recognition, implying that configural information from the stretched part of the face was influencing the process of recognition --- ie that configural processing involves global facial properties. In experiment 4 we examined the effects of Gaussian blurring on recognition of undistorted and vertically stretched faces. Faces remained recognisable even when they were both stretched and blurred, implying that participants were basing their judgments on configural information from these stimuli, rather than resorting to some strategy based on local featural details. The tolerance of spatial distortions in human face recognition suggests that the configural information used as a basis for face recognition is unlikely to involve information about the absolute position of facial features relative to each other, at least not in any simple way},
	author = {Hole, Graham J and George, Patricia A and Eaves, Karen and Rasek, Ayman},
	doi = {10.1068/p3252},
	file = {Accepted Version:files/3161/Hole et al. - 2002 - Effects of Geometric Distortions on Face-Recogniti.pdf:application/pdf},
	issn = {0301-0066},
	journal = {Perception},
	language = {en},
	month = oct,
	note = {Publisher: SAGE Publications Ltd STM},
	number = {10},
	pages = {1221--1240},
	title = {Effects of {Geometric} {Distortions} on {Face}-{Recognition} {Performance}},
	url = {https://doi.org/10.1068/p3252},
	urldate = {2024-02-02},
	volume = {31},
	year = {2002},
	bdsk-url-1 = {https://doi.org/10.1068/p3252}}

@article{white_individual_2022,
	abstract = {Face perception is crucial to social interactions, yet people vary in how easily they can recognize their friends, verify an identification document or notice someone's smile. There are widespread differences in people's ability to recognize faces, and research has particularly focused on exceptionally good or poor recognition performance. In this Review, we synthesize the literature on individual differences in face processing across various tasks including identification and estimates of emotional state and social attributes. The individual differences approach has considerable untapped potential for theoretical progress in understanding the perceptual and cognitive organization of face processing. This approach also has practical consequences --- for example, in determining who is best suited to check passports. We also discuss the underlying structural and anatomical predictors of face perception ability. Furthermore, we highlight problems of measurement that pose challenges for the effective study of individual differences. Finally, we note that research in individual differences rarely addresses perception of familiar faces. Despite people's everyday experience of being `good' or `bad' with faces, a theory of how people recognize their friends remains elusive.},
	author = {White, David and Burton, A. Mike},
	copyright = {2022 Springer Nature America, Inc.},
	doi = {10.1038/s44159-022-00041-3},
	file = {Accepted Version:files/3163/White and Burton - 2022 - Individual differences and the multidimensional na.pdf:application/pdf},
	issn = {2731-0574},
	journal = {Nature Reviews Psychology},
	keywords = {Human behaviour, Perception, Psychology},
	language = {en},
	month = may,
	note = {Number: 5 Publisher: Nature Publishing Group},
	number = {5},
	pages = {287--300},
	title = {Individual differences and the multidimensional nature of face perception},
	url = {https://www.nature.com/articles/s44159-022-00041-3},
	urldate = {2024-02-02},
	volume = {1},
	year = {2022},
	bdsk-url-1 = {https://www.nature.com/articles/s44159-022-00041-3},
	bdsk-url-2 = {https://doi.org/10.1038/s44159-022-00041-3}}

@article{long_database_2023,
	abstract = {Facial expressions are thought to be complex visual signals, critical for communication between social agents. Most prior work aimed at understanding how facial expressions are recognized has relied on stimulus databases featuring posed facial expressions, designed to represent putative emotional categories (such as 'happy' and 'angry'). Here we use an alternative selection strategy to develop the Wild Faces Database (WFD); a set of one thousand images capturing a diverse range of ambient facial behaviors from outside of the laboratory. We characterized the perceived emotional content in these images using a standard categorization task in which participants were asked to classify the apparent facial expression in each image. In addition, participants were asked to indicate the intensity and genuineness of each expression. While modal scores indicate that the WFD captures a range of different emotional expressions, in comparing the WFD to images taken from other, more conventional databases, we found that participants responded more variably and less specifically to the wild-type faces, perhaps indicating that natural expressions are more multiplexed than a categorical model would predict. We argue that this variability can be employed to explore latent dimensions in our mental representation of facial expressions. Further, images in the WFD were rated as less intense and more genuine than images taken from other databases, suggesting a greater degree of authenticity among WFD images. The strong positive correlation between intensity and genuineness scores demonstrating that even the high arousal states captured in the WFD were perceived as authentic. Collectively, these findings highlight the potential utility of the WFD as a new resource for bridging the gap between the laboratory and real world in studies of expression recognition.},
	author = {Long, Houqiu and Peluso, Natalie and Baker, Chris I. and Japee, Shruti and Taubert, Jessica},
	doi = {10.1038/s41598-023-32659-5},
	file = {Full Text:files/3166/Long et al. - 2023 - A database of heterogeneous faces for studying nat.pdf:application/pdf},
	issn = {2045-2322},
	journal = {Scientific Reports},
	keywords = {Anger, Arousal, Emotions, Facial Expression, Happiness, Humans},
	language = {eng},
	month = apr,
	number = {1},
	pages = {5383},
	pmcid = {PMC10070342},
	pmid = {37012369},
	title = {A database of heterogeneous faces for studying naturalistic expressions},
	volume = {13},
	year = {2023},
	bdsk-url-1 = {https://doi.org/10.1038/s41598-023-32659-5}}

@article{dobs_how_2019,
	abstract = {Within a fraction of a second of viewing a face, we have already determined its gender, age and identity. A full understanding of this remarkable feat will require a characterization of the computational steps it entails, along with the representations extracted at each. Here, we used magnetoencephalography (MEG) to measure the time course of neural responses to faces, thereby addressing two fundamental questions about how face processing unfolds over time. First, using representational similarity analysis, we found that facial gender and age information emerged before identity information, suggesting a coarse-to-fine processing of face dimensions. Second, identity and gender representations of familiar faces were enhanced very early on, suggesting that the behavioral benefit for familiar faces results from tuning of early feed-forward processing mechanisms. These findings start to reveal the time course of face processing in humans, and provide powerful new constraints on computational theories of face perception.},
	author = {Dobs, Katharina and Isik, Leyla and Pantazis, Dimitrios and Kanwisher, Nancy},
	copyright = {2019 The Author(s)},
	doi = {10.1038/s41467-019-09239-1},
	file = {Full Text PDF:files/3168/Dobs et al. - 2019 - How face perception unfolds over time.pdf:application/pdf},
	issn = {2041-1723},
	journal = {Nature Communications},
	keywords = {Cognitive neuroscience, Object vision, Perception, Visual system},
	language = {en},
	month = mar,
	note = {Number: 1 Publisher: Nature Publishing Group},
	number = {1},
	pages = {1258},
	title = {How face perception unfolds over time},
	url = {https://www.nature.com/articles/s41467-019-09239-1},
	urldate = {2024-02-02},
	volume = {10},
	year = {2019},
	bdsk-url-1 = {https://www.nature.com/articles/s41467-019-09239-1},
	bdsk-url-2 = {https://doi.org/10.1038/s41467-019-09239-1}}

@article{valentine_upside-down_1988,
	abstract = {Several studies have found that face recognition is disproportionately impaired by stimulus inversion when compated to recognition of other classes of visual stimuli. This effect has been interpreted as evidence that face recognition benefits from a `special' process which is not engaged by an inverted face. This paper reviews studies of the effect of inversion on face recognition in recognition memory tasks, matching tasks and upon cerebral hemisphere asymmetries. Evidence is drawn from developmental studies and from studies of brain-injured and normal adult subjects. It is concluded that the evidence that inverted faces are processed differently from upright faces is far from compelling, and therefore the effect of inversion provides little or no evidence of a unique process in face recognition. The inversion effect is interpreted in terms of expertise in face processing and the highly homogeneous nature of faces as a stimulus class.},
	author = {Valentine, Tim},
	copyright = {1988 The British Psychological Society},
	doi = {10.1111/j.2044-8295.1988.tb02747.x},
	file = {Snapshot:files/3172/j.2044-8295.1988.tb02747.html:text/html},
	issn = {2044-8295},
	journal = {British Journal of Psychology},
	language = {en},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/j.2044-8295.1988.tb02747.x},
	number = {4},
	pages = {471--491},
	shorttitle = {Upside-down faces},
	title = {Upside-down faces: {A} review of the effect of inversion upon face recognition},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/j.2044-8295.1988.tb02747.x},
	urldate = {2024-02-02},
	volume = {79},
	year = {1988},
	bdsk-url-1 = {https://onlinelibrary.wiley.com/doi/abs/10.1111/j.2044-8295.1988.tb02747.x},
	bdsk-url-2 = {https://doi.org/10.1111/j.2044-8295.1988.tb02747.x}}

@article{taubert_effect_2015,
	abstract = {It is widely believed that face processing in the primate brain occurs in a network of category-selective cortical regions. Combined functional MRI (fMRI)-single-cell recording studies in macaques have identified high concentrations of neurons that respond more to faces than objects within face-selective patches. However, cells with a preference for faces over objects are also found scattered throughout inferior temporal (IT) cortex, raising the question whether face-selective cells inside and outside of the face patches differ functionally. Here, we compare the properties of face-selective cells inside and outside of face-selective patches in the IT cortex by means of an image manipulation that reliably disrupts behavior toward face processing: inversion. We recorded IT neurons from two fMRI-defined face-patches (ML and AL) and a region outside of the face patches (herein labeled OUT) during upright and inverted face stimulation. Overall, turning faces upside down reduced the firing rate of face-selective cells. However, there were differences among the recording regions. First, the reduced neuronal response for inverted faces was independent of stimulus position, relative to fixation, in the face-selective patches (ML and AL) only. Additionally, the effect of inversion for face-selective cells in ML, but not those in AL or OUT, was impervious to whether the neurons were initially searched for using upright or inverted stimuli. Collectively, these results show that face-selective cells differ in their functional characteristics depending on their anatomicofunctional location, suggesting that upright faces are preferably coded by face-selective cells inside but not outside of the fMRI-defined face-selective regions of the posterior IT cortex.},
	author = {Taubert, Jessica and Van Belle, Goedele and Vanduffel, Wim and Rossion, Bruno and Vogels, Rufin},
	doi = {10.1152/jn.00700.2014},
	file = {Accepted Version:files/3175/Taubert et al. - 2015 - The effect of face inversion for neurons inside an.pdf:application/pdf},
	issn = {1522-1598},
	journal = {Journal of Neurophysiology},
	keywords = {Animals, Brain Mapping, electrophysiology, Face, face representations, face-selective cells, inversion effect, IT cortex, Macaca mulatta, Magnetic Resonance Imaging, Male, Neurons, Pattern Recognition, Visual, Temporal Lobe},
	language = {eng},
	month = mar,
	number = {5},
	pages = {1644--1655},
	pmcid = {PMC4346728},
	pmid = {25520434},
	title = {The effect of face inversion for neurons inside and outside {fMRI}-defined face-selective cortical regions},
	volume = {113},
	year = {2015},
	bdsk-url-1 = {https://doi.org/10.1152/jn.00700.2014}}

@article{maurer_many_2002,
	abstract = {Adults' expertise in recognizing faces has been attributed to configural processing. We distinguish three types of configural processing: detecting the first-order relations that define faces (i.e. two eyes above a nose and mouth), holistic processing (glueing the features together into a gestalt), and processing second-order relations (i.e. the spacing among features). We provide evidence for their separability based on behavioral marker tasks, their sensitivity to experimental manipulations, and their patterns of development. We note that inversion affects each type of configural processing, not just sensitivity to second-order relations, and we review evidence on whether configural processing is unique to faces.},
	author = {Maurer, Daphne and Grand, Richard Le and Mondloch, Catherine J.},
	doi = {10.1016/S1364-6613(02)01903-4},
	file = {ScienceDirect Snapshot:files/3177/S1364661302019034.html:text/html},
	issn = {1364-6613},
	journal = {Trends in Cognitive Sciences},
	keywords = {configural processing, face processing, faceperception, featural processing, first-order relations, holistic processing, relational processing, second-order relations},
	month = jun,
	number = {6},
	pages = {255--260},
	title = {The many faces of configural processing},
	url = {https://www.sciencedirect.com/science/article/pii/S1364661302019034},
	urldate = {2024-02-02},
	volume = {6},
	year = {2002},
	bdsk-url-1 = {https://www.sciencedirect.com/science/article/pii/S1364661302019034},
	bdsk-url-2 = {https://doi.org/10.1016/S1364-6613(02)01903-4}}

@article{waidmann_local_2022,
	abstract = {Humans and other primates recognize one another in part based on unique structural details of the face, including both local features and their spatial configuration within the head and body. Visual analysis of the face is supported by specialized regions of the primate cerebral cortex, which in macaques are commonly known as face patches. Here we ask whether the responses of neurons in anterior face patches, thought to encode face identity, are more strongly driven by local or holistic facial structure. We created stimuli consisting of recombinant photorealistic images of macaques, where we interchanged the eyes, mouth, head, and body between individuals. Unexpectedly, neurons in the anterior medial (AM) and anterior fundus (AF) face patches were predominantly tuned to local facial features, with minimal neural selectivity for feature combinations. These findings indicate that the high-level structural encoding of face identity rests upon populations of neurons specialized for local features.},
	author = {Waidmann, Elena N. and Koyano, Kenji W. and Hong, Julie J. and Russ, Brian E. and Leopold, David A.},
	copyright = {2022 This is a U.S. Government work and not under copyright protection in the US; foreign copyright protection may apply},
	doi = {10.1038/s41467-022-33240-w},
	file = {Full Text PDF:files/3179/Waidmann et al. - 2022 - Local features drive identity responses in macaque.pdf:application/pdf},
	issn = {2041-1723},
	journal = {Nature Communications},
	keywords = {Extrastriate cortex, Object vision},
	language = {en},
	month = sep,
	note = {Number: 1 Publisher: Nature Publishing Group},
	number = {1},
	pages = {5592},
	title = {Local features drive identity responses in macaque anterior face patches},
	url = {https://www.nature.com/articles/s41467-022-33240-w},
	urldate = {2024-02-02},
	volume = {13},
	year = {2022},
	bdsk-url-1 = {https://www.nature.com/articles/s41467-022-33240-w},
	bdsk-url-2 = {https://doi.org/10.1038/s41467-022-33240-w}}
