<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving
and Interchange DTD v1.2 20190208//EN" "JATS-archivearticle1.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="1.2" article-type="other">
  <front>
    <article-meta>
      <title-group>
        <article-title>Differences in the Perceptual Processing of Unfamiliar
and Familiar Faces</article-title>
      </title-group>
      <contrib-group>
        <contrib contrib-type="author">
          <name>
            <surname>McGinness</surname>
            <given-names>Kasey</given-names>
          </name>
          <string-name>Kasey McGinness</string-name>
          <role vocab="https://credit.niso.org" vocab-term="conceptualization" vocab-term-identifier="https://credit.niso.org/contributor-roles/conceptualization/">Conceptualization</role>
          <role vocab="https://credit.niso.org" vocab-term="investigation" vocab-term-identifier="https://credit.niso.org/contributor-roles/investigation/">Investigation</role>
          <role vocab="https://credit.niso.org" vocab-term="formal analysis" vocab-term-identifier="https://credit.niso.org/contributor-roles/formal-analysis/">Formal
Analysis</role>
          <role>Writing - original draft</role>
          <xref ref-type="aff" rid="aff-1">a</xref>
        </contrib>
        <contrib contrib-type="author">
          <contrib-id contrib-id-type="orcid">0000-0002-6519-8068</contrib-id>
          <name>
            <surname>Taubert</surname>
            <given-names>Jessica</given-names>
          </name>
          <string-name>Jessica Taubert</string-name>
          <role vocab="https://credit.niso.org" vocab-term="conceptualization" vocab-term-identifier="https://credit.niso.org/contributor-roles/conceptualization/">Conceptualization</role>
          <role vocab="https://credit.niso.org" vocab-term="methodology" vocab-term-identifier="https://credit.niso.org/contributor-roles/methodology/">Methodology</role>
          <role>Writing - reviewing &amp; editing</role>
          <xref ref-type="aff" rid="aff-2">b</xref>
        </contrib>
        <contrib contrib-type="author" corresp="yes">
          <contrib-id contrib-id-type="orcid">0000-0001-5785-024X</contrib-id>
          <name>
            <surname>Apthorp</surname>
            <given-names>Deborah</given-names>
          </name>
          <string-name>Deborah Apthorp</string-name>
          <email>dapthorp@une.edu.au</email>
          <role vocab="https://credit.niso.org" vocab-term="conceptualization" vocab-term-identifier="https://credit.niso.org/contributor-roles/conceptualization/">Conceptualization</role>
          <role vocab="https://credit.niso.org" vocab-term="project administration" vocab-term-identifier="https://credit.niso.org/contributor-roles/project-administration/">Project
administration</role>
          <role vocab="https://credit.niso.org" vocab-term="software" vocab-term-identifier="https://credit.niso.org/contributor-roles/software/">Software</role>
          <role vocab="https://credit.niso.org" vocab-term="formal analysis" vocab-term-identifier="https://credit.niso.org/contributor-roles/formal-analysis/">Formal
analysis</role>
          <role>Writing - reviewing &amp; editing</role>
          <role vocab="https://credit.niso.org" vocab-term="visualization" vocab-term-identifier="https://credit.niso.org/contributor-roles/visualization/">Visualization</role>
          <role vocab="https://credit.niso.org" vocab-term="supervision" vocab-term-identifier="https://credit.niso.org/contributor-roles/supervision/">Supervision</role>
          <xref ref-type="aff" rid="aff-1">a</xref>
          <xref ref-type="aff" rid="aff-3">c</xref>
          <xref ref-type="corresp" rid="cor-3">*</xref>
        </contrib>
      </contrib-group>
      <aff id="aff-1">
        <institution-wrap>
          <institution>University of New England</institution>
        </institution-wrap>
      </aff>
      <aff id="aff-2">
        <institution-wrap>
          <institution>University of Queensland</institution>
        </institution-wrap>
      </aff>
      <aff id="aff-3">
        <institution-wrap>
          <institution>Australian National University</institution>
        </institution-wrap>
      </aff>
      <author-notes>
        <corresp id="cor-3">dapthorp@une.edu.au</corresp>
      </author-notes>
      <history/>
      <abstract>
        <p>Evidence that familiar faces are processed differently from
unfamiliar faces has important implications for our understanding of how
we recognise the people around us. Although familiarity effects on face
recognition performance have been extensively researched, the perceptual
and cognitive processes that underlie these differences are
comparatively unknown. Using a psychophysical staircase paradigm, we
collected data from 28 female participants aged 18-65 years
(<inline-formula><alternatives><tex-math><![CDATA[M = 43.1]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline"><mml:mrow><mml:mi>M</mml:mi><mml:mo>=</mml:mo><mml:mn>43.1</mml:mn></mml:mrow></mml:math></alternatives></inline-formula>,
<inline-formula><alternatives><tex-math><![CDATA[SD = 12.7]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline"><mml:mrow><mml:mi>S</mml:mi><mml:mi>D</mml:mi><mml:mo>=</mml:mo><mml:mn>12.7</mml:mn></mml:mrow></mml:math></alternatives></inline-formula>)
and probed perceptual processing by measuring the minimum amount of time
required to recognise a previously seen face across three levels of
familiarity (unfamiliar, familiar, and self). We also measured a second
dependent variable, reaction time, which is thought to reflect both
perceptual and cognitive processes. The results revealed that
participants needed less time to recognise familiar faces compared to
unfamiliar faces. Concomitantly, participants needed less time to
respond when tasked with recognising faces compared to unfamiliar faces.
As expected, inverted faces took longer to recognise than upright faces,
but this effect was reduced for familiar and self-faces. Recognition
times provide evidence for distinct perceptual processing based on level
of familiarity and suggest that our ability to recognise familiar faces
may be poorly characterised by current theories. Overall, the results
emphasise the uniqueness of the self-face within the familiarity
continuum, as all participants were able to recognise their own face
significantly faster than other faces. In light of these results, it is
clear that a full understanding of how face recognition is accomplished
will require a better characterisation of how we respond to highly
familiar faces.</p>
      </abstract>
      <kwd-group kwd-group-type="author">
        <kwd>Face perception</kwd>
        <kwd>Psychophysics</kwd>
        <kwd>Face inversion effect</kwd>
      </kwd-group>
    </article-meta>
  </front>
  <body>
    <sec id="introduction">
      <title>Introduction</title>
      <p>Face recognition is the foundation of our social behaviour; it
  helps us identify the people around us and make inferences about their
  mood and focus of attention
  (<xref alt="Burton et al., 2015" rid="ref-burton2015a" ref-type="bibr">Burton
  et al., 2015</xref>;
  <xref alt="Mohr et al., 2018" rid="ref-mohr2018a" ref-type="bibr">Mohr
  et al., 2018</xref>). It has been estimated that we spend
  20<inline-formula><alternatives><tex-math><![CDATA[\%]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline"><mml:mi>%</mml:mi></mml:math></alternatives></inline-formula>
  of our day looking at faces, and can recognise over 4000 faces during
  our lifetime
  (<xref alt="Jenkins et al., 2018" rid="ref-jenkins2018a" ref-type="bibr">Jenkins
  et al., 2018</xref>;
  <xref alt="Oruc et al., 2019" rid="ref-oruc2019a" ref-type="bibr">Oruc
  et al., 2019</xref>). For most of us, the ability to recognise and
  recall identity-specific information appears to occur almost
  effortlessly, with studies demonstrating that we can recognise a
  familiar face as quickly as 360 ms
  (<xref alt="Besson et al., 2016" rid="ref-besson2016a" ref-type="bibr">Besson
  et al., 2016</xref>;
  <xref alt="Blauch et al., 2021" rid="ref-blauch2021a" ref-type="bibr">Blauch
  et al., 2021</xref>;
  <xref alt="Oruc et al., 2019" rid="ref-oruc2019a" ref-type="bibr">Oruc
  et al., 2019</xref>;
  <xref alt="Ramon &amp; Belle, 2016" rid="ref-ramon2016a" ref-type="bibr">Ramon
  &amp; Belle, 2016</xref>). The efficiency with which humans can
  discriminate within a relatively homogeneous visual category, under
  constantly changing viewing conditions, has earned us the reputation
  for being face experts
  (<xref alt="Collins et al., 2018" rid="ref-collins2018a" ref-type="bibr">Collins
  et al., 2018</xref>;
  <xref alt="Dobs et al., 2019" rid="ref-dobs2019a" ref-type="bibr">Dobs
  et al., 2019</xref>;
  <xref alt="Kramer et al., 2017" rid="ref-kramer2017a" ref-type="bibr">Kramer
  et al., 2017</xref>;
  <xref alt="Quek et al., 2021" rid="ref-quek2021a" ref-type="bibr">Quek
  et al., 2021</xref>;
  <xref alt="Rossion &amp; Taubert, 2019" rid="ref-rossion_what_2019" ref-type="bibr">Rossion
  &amp; Taubert, 2019</xref>;
  <xref alt="Towler et al., 2019" rid="ref-towler_are_2019" ref-type="bibr">Towler
  et al., 2019</xref>).</p>
      <p>The precise nature of our face expertise remains poorly understood,
  with debate around whether the processes that govern face recognition
  are the same for all faces or whether there are distinct perceptual
  processes for familiar faces
  (<xref alt="Abudarham et al., 2019" rid="ref-abudarham2019a" ref-type="bibr">Abudarham
  et al., 2019</xref>;
  <xref alt="Blauch et al., 2021" rid="ref-blauch2021a" ref-type="bibr">Blauch
  et al., 2021</xref>;
  <xref alt="Collins et al., 2018" rid="ref-collins2018a" ref-type="bibr">Collins
  et al., 2018</xref>). Central to the discussion is the idea that there
  may be a familiarity continuum in face recognition, whereby the brain
  will respond differently depending on the level of familiarity one has
  with the face. For example, our friends’ faces are not as familiar to
  us as our own face, and this difference could change the way the brain
  encodes and processes a face at the sensory and cognitive level
  (<xref alt="Bortolon. &amp; Raffard, 2018" rid="ref-bortolon2018a" ref-type="bibr">Bortolon.
  &amp; Raffard, 2018</xref>;
  <xref alt="Rooney et al., 2012" rid="ref-rooney2012a" ref-type="bibr">Rooney
  et al., 2012</xref>;
  <xref alt="Tong &amp; Nakayama, 1999" rid="ref-tong1999a" ref-type="bibr">Tong
  &amp; Nakayama, 1999</xref>). Understanding these differences may
  extend beyond the benefit to basic visual cognition. For example, it
  is possible that the processes responsible for recognising our own
  face index other higher-level constructs such as self-esteem and
  self-identity, which are thought to underlie serious pathologies such
  as depression, schizophrenia, and bipolar disorder
  (<xref alt="Felisberti &amp; Musholt, 2014" rid="ref-felisberti2014a" ref-type="bibr">Felisberti
  &amp; Musholt, 2014</xref>;
  <xref alt="Oliveira et al., 2015" rid="ref-oliveira2015a" ref-type="bibr">Oliveira
  et al., 2015</xref>).</p>
      <p>There is abundant evidence that greater levels of familiarity with
  a person facilitate processing efficiency, as it has been shown that
  the faces of personally familiar people are processed faster and more
  accurately than the faces of familiar celebrities, and both have an
  advantage over strangers faces
  (<xref alt="Bortolon et al., 2017" rid="ref-bortolon2017a" ref-type="bibr">Bortolon
  et al., 2017</xref>;
  <xref alt="Burton et al., 2015" rid="ref-burton2015a" ref-type="bibr">Burton
  et al., 2015</xref>;
  <xref alt="Tong &amp; Nakayama, 1999" rid="ref-tong1999a" ref-type="bibr">Tong
  &amp; Nakayama, 1999</xref>;
  <xref alt="Young &amp; Burton, 2017" rid="ref-young2017a" ref-type="bibr">Young
  &amp; Burton, 2017</xref>). Further, changes in viewing conditions
  have been shown to impede unfamiliar face matching performance whereas
  recognition of familiar faces is extremely robust to within-identity
  image variability and low-quality images
  (<xref alt="Burton, 2013" rid="ref-burton2013a" ref-type="bibr">Burton,
  2013</xref>;
  <xref alt="Jenkins et al., 2011" rid="ref-jenkins2011a" ref-type="bibr">Jenkins
  et al., 2011</xref>;
  <xref alt="Liccione et al., 2014" rid="ref-liccione2014a" ref-type="bibr">Liccione
  et al., 2014</xref>). For example, Burton et al.
  (<xref alt="1999" rid="ref-burton1999a" ref-type="bibr">1999</xref>)
  found performance differences in their study which involved showing
  low resolution CCTV images to familiar and unfamiliar viewers.
  Unfamiliar viewers were able to accurately identify faces
  50<inline-formula><alternatives><tex-math><![CDATA[\%]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline"><mml:mi>%</mml:mi></mml:math></alternatives></inline-formula>
  of the time, whereas familiar viewers could identify faces almost
  perfectly, suggesting that the processing of unfamiliar faces may be
  qualitatively different from familiar faces
  (<xref alt="Burton et al., 1999" rid="ref-burton1999a" ref-type="bibr">Burton
  et al., 1999</xref>). The familiar face advantage has been observed
  across a range of image manipulations including face inversion (i.e.,
  turning faces upside down) and geometric distortion (e.g., compressing
  images of faces) manipulations, highlighting familiarity as an
  important factor in face recognition
  (<xref alt="Allen-Davidian et al., 2021" rid="ref-allen-davidian2021a" ref-type="bibr">Allen-Davidian
  et al., 2021</xref>;
  <xref alt="Hole et al., 2002" rid="ref-hole_effects_2002" ref-type="bibr">Hole
  et al., 2002</xref>;
  <xref alt="Kramer et al., 2018" rid="ref-kramer2018a" ref-type="bibr">Kramer
  et al., 2018</xref>;
  <xref alt="Rossion, 2008" rid="ref-rossion_picture-plane_2008" ref-type="bibr">Rossion,
  2008</xref>;
  <xref alt="Yang et al., 2014" rid="ref-yang2014a" ref-type="bibr">Yang
  et al., 2014</xref>).</p>
      <p>However, familiarity is a challenging dimension to explore because
  its definition is multiplexed, and it is difficult to control in an
  experimental context. First, there are different levels of
  familiarity, ranging from recently recently seen and recently learned
  faces to faces that are familiar but for which we have no personal
  knowledge (famous people, acquaintances), to the faces of those we
  know well (family, close friends, self-face; Ramon et al.
  (<xref alt="2011" rid="ref-ramon2011a" ref-type="bibr">2011</xref>)).
  Levels of familiarity influence the depth of knowledge and experience
  we associate with an individual, which likely impacts the underlying
  mental representation we store in memory
  (<xref alt="Ramon &amp; Gobbini, 2017" rid="ref-ramon2017a" ref-type="bibr">Ramon
  &amp; Gobbini, 2017</xref>). Second, each individual knows a unique
  collection of faces, which limits the type of stimuli that can be used
  in research, adding inherent variability in familiarity levels between
  participants
  (<xref alt="Ramon &amp; Gobbini, 2017" rid="ref-ramon2017a" ref-type="bibr">Ramon
  &amp; Gobbini, 2017</xref>). Third, the way in which faces become
  familiar can differ. For example, some faces become familiar through
  interaction with others in our daily lives, and other faces become
  familiar through repeated exposure (i.e., famous faces or
  experimentally learned faces). In other words, coming to ‘know’ a
  person could be different to image-based familiarity
  (<xref alt="Kramer et al., 2018" rid="ref-kramer2018a" ref-type="bibr">Kramer
  et al., 2018</xref>). Finally, to reduce noise in data, researchers
  often manipulate face images (e.g., cropped, hairless, expressionless)
  which is different to how a face appears under normal circumstances
  (<xref alt="Burton et al., 2011" rid="ref-burton2011a" ref-type="bibr">Burton
  et al., 2011</xref>;
  <xref alt="Long et al., 2023" rid="ref-long_database_2023" ref-type="bibr">Long
  et al., 2023</xref>). These methodological constraints and unique
  challenges have contributed to the inconsistencies in face research,
  particularly regarding familiar face recognition performance.</p>
      <sec id="measuring-face-recognition">
        <title>Measuring Face Recognition</title>
        <p>While in the real world only familiar faces are recognised, in
    face research, “face recognition” also describes an individual’s
    ability to detect a previously unknown face with which they are
    familiarised during an experimental procedure
    (<xref alt="Burton, 2013" rid="ref-burton2013a" ref-type="bibr">Burton,
    2013</xref>;
    <xref alt="Hancock et al., 2000" rid="ref-hancock2000a" ref-type="bibr">Hancock
    et al., 2000</xref>;
    <xref alt="White &amp; Burton, 2022" rid="ref-white_individual_2022" ref-type="bibr">White
    &amp; Burton, 2022</xref>). Consistent with the literature, we will
    conceptualise face recognition as the ability to recognise
    previously known or recently learned faces (familiar) and previously
    unknown faces (unfamiliar).</p>
        <p>Face recognition has been investigated by recording how long it
    takes participants to accurately find targets. These tasks often
    involve participants seeking a target face, where detection is
    indicated using a go/no-go categorisation
    (<xref alt="Kloth et al., 2006" rid="ref-kloth2006a" ref-type="bibr">Kloth
    et al., 2006</xref>;
    <xref alt="Ramon et al., 2011" rid="ref-ramon2011a" ref-type="bibr">Ramon
    et al., 2011</xref>;
    <xref alt="Tong &amp; Nakayama, 1999" rid="ref-tong1999a" ref-type="bibr">Tong
    &amp; Nakayama, 1999</xref>). Reaction time data has mostly shown
    that participants are faster to recognise familiar faces than
    unfamiliar faces, but reported reaction times vary
    (<xref alt="Burton et al., 2015" rid="ref-burton2015a" ref-type="bibr">Burton
    et al., 2015</xref>;
    <xref alt="Ramon et al., 2011" rid="ref-ramon2011a" ref-type="bibr">Ramon
    et al., 2011</xref>;
    <xref alt="Ramon &amp; Gobbini, 2017" rid="ref-ramon2017a" ref-type="bibr">Ramon
    &amp; Gobbini, 2017</xref>). For example, Ramon et al.
    (<xref alt="2011" rid="ref-ramon2011a" ref-type="bibr">2011</xref>)
    asked participants to accurately categorise 52 images of classmates
    and strangers using a go/no-go finger lift response and found
    observers could categorise their classmates within 360 ms, compared
    to 460 ms to categorise a face as unfamiliar. By contrast, Alzueta
    et al.
    (<xref alt="2019" rid="ref-alzueta2019a" ref-type="bibr">2019</xref>)
    asked participants to classify 450 images of their own face,
    friends, and strangers as quickly as possible using a keyboard
    button press. Results showed faster reaction times for the self-face
    (542 ms), but slower reaction times for friends’ faces (570 ms)
    compared with strangers (562 ms), providing conflicting evidence for
    the familiar face advantage. Together, findings highlight a common
    challenge in face recognition research regarding variability in
    reaction time data as a result of different task demands.</p>
        <p>A drawback of relying on average reaction times as a dependent
    variable is that the data represents the elapsed time from stimulus
    onset to motor output, combining perceptual processing time,
    cognitive decision time, and motor response, thus inflating the
    actual time required to recognise a face
    (<xref alt="Alzueta et al., 2019" rid="ref-alzueta2019a" ref-type="bibr">Alzueta
    et al., 2019</xref>;
    <xref alt="Burton et al., 2015" rid="ref-burton2015a" ref-type="bibr">Burton
    et al., 2015</xref>;
    <xref alt="Caharel et al., 2014" rid="ref-caharel2014a" ref-type="bibr">Caharel
    et al., 2014</xref>). Taubert et al.
    (<xref alt="2011" rid="ref-taubert2011a" ref-type="bibr">2011</xref>)
    overcame this issue in their study by using a staircase procedure to
    determine minimum exposure time. Their research revealed that
    participants could accurately discriminate between individual target
    faces when given 50 ms to view a stimulus
    (<xref alt="Taubert et al., 2011" rid="ref-taubert2011a" ref-type="bibr">Taubert
    et al., 2011</xref>). Others have used electroencephalography (EEG)
    frequency tagging to compare neural responses to face images that
    progressively increased in image duration, to identify the threshold
    for successful face recognition
    (<xref alt="Dobs et al., 2019" rid="ref-dobs2019a" ref-type="bibr">Dobs
    et al., 2019</xref>;
    <xref alt="Quek et al., 2021" rid="ref-quek2021a" ref-type="bibr">Quek
    et al., 2021</xref>). Results showed that exposures as brief as 83
    ms enabled observers to consistently recognise familiar (famous)
    faces from unfamiliar faces
    (<xref alt="Quek et al., 2021" rid="ref-quek2021a" ref-type="bibr">Quek
    et al., 2021</xref>). Findings of both studies revealed that
    processing time was much shorter than the reaction times reported in
    other face recognition studies
    (<xref alt="Besson et al., 2016" rid="ref-besson2016a" ref-type="bibr">Besson
    et al., 2016</xref>;
    <xref alt="Blauch et al., 2021" rid="ref-blauch2021a" ref-type="bibr">Blauch
    et al., 2021</xref>;
    <xref alt="Oruc et al., 2019" rid="ref-oruc2019a" ref-type="bibr">Oruc
    et al., 2019</xref>).Here, we employed the same method as Taubert et
    al.
    (<xref alt="2011" rid="ref-taubert2011a" ref-type="bibr">2011</xref>)
    to determine whether different perceptual processes underscore the
    recognition of familiar and unfamiliar faces.</p>
      </sec>
      <sec id="effects-of-different-levels-of-familiarity-on-face-recognition-performance">
        <title>Effects of Different Levels of Familiarity on Face
    Recognition Performance</title>
        <p>The idea that familiar faces may be more easily detected or
    recognised than unfamiliar faces makes intuitive sense, given the
    social importance of correctly identifying familiar faces, and the
    need for humans to efficiently process the enormous amount of visual
    information we are exposed to in our environment
    (<xref alt="Tong &amp; Nakayama, 1999" rid="ref-tong1999a" ref-type="bibr">Tong
    &amp; Nakayama, 1999</xref>). The pursuit of identifying the neural
    mechanisms underlying the recognition of familiar faces has led to
    important discoveries regarding distinct processing capacities
    (<xref alt="Bortolon et al., 2017" rid="ref-bortolon2017a" ref-type="bibr">Bortolon
    et al., 2017</xref>;
    <xref alt="Ramon &amp; Gobbini, 2017" rid="ref-ramon2017a" ref-type="bibr">Ramon
    &amp; Gobbini, 2017</xref>). There is growing evidence in support of
    a familiarity continuum in face recognition highlighting processing
    distinctions not only between unfamiliar and familiar faces, but
    within the familiar face category itself
    (<xref alt="Megreya &amp; Burton, 2006" rid="ref-megraya2006a" ref-type="bibr">Megreya
    &amp; Burton, 2006</xref>;
    <xref alt="Murphy et al., 2015" rid="ref-murphy2015a" ref-type="bibr">Murphy
    et al., 2015</xref>;
    <xref alt="Quek et al., 2021" rid="ref-quek2021a" ref-type="bibr">Quek
    et al., 2021</xref>;
    <xref alt="Wiese et al., 2021" rid="ref-wiese2021a" ref-type="bibr">Wiese
    et al., 2021</xref>).</p>
        <sec id="recently-learned-faces">
          <title>Recently Learned Faces</title>
          <p>Evidence from behavioural studies has indicated that humans
      only need brief exposure for face learning to occur, as recently
      learned faces are more easily matched than unfamiliar faces in
      face matching tasks
      (<xref alt="Dowsett et al., 2016" rid="ref-dowsett2016a" ref-type="bibr">Dowsett
      et al., 2016</xref>;
      <xref alt="Kramer et al., 2017" rid="ref-kramer2017a" ref-type="bibr">Kramer
      et al., 2017</xref>;
      <xref alt="Murphy et al., 2015" rid="ref-murphy2015a" ref-type="bibr">Murphy
      et al., 2015</xref>;
      <xref alt="Quek et al., 2021" rid="ref-quek2021a" ref-type="bibr">Quek
      et al., 2021</xref>). However, unlike recognition of familiar
      faces, which is robust to changes in viewing conditions such as
      lighting, viewpoint, and expression, face matching of recently
      familiar faces is hindered by even slight alterations in the
      appearance of the face
      (<xref alt="Burton et al., 2011" rid="ref-burton2011a" ref-type="bibr">Burton
      et al., 2011</xref>;
      <xref alt="Megreya &amp; Burton, 2008" rid="ref-megraya2008a" ref-type="bibr">Megreya
      &amp; Burton, 2008</xref>;
      <xref alt="Redfern &amp; Benton, 2019" rid="ref-redfern2019a" ref-type="bibr">Redfern
      &amp; Benton, 2019</xref>;
      <xref alt="White et al., 2016" rid="ref-white2016a" ref-type="bibr">White
      et al., 2016</xref>). In addition to perceptual information (e.g.,
      facial features) acquired during face learning, research shows
      sparse conceptual information (e.g., name and occupation) can aid
      recognition
      (<xref alt="Oruc et al., 2019" rid="ref-oruc2019a" ref-type="bibr">Oruc
      et al., 2019</xref>;
      <xref alt="Schwartz &amp; Yovel, 2019" rid="ref-schwartz2019a" ref-type="bibr">Schwartz
      &amp; Yovel, 2019</xref>). Schwartz &amp; Yovel
      (<xref alt="2016" rid="ref-schwartz2016a" ref-type="bibr">2016</xref>)
      compared the contribution of perceptual and conceptual information
      to face recognition performance in their study exposing
      participants to either perceptual information (manipulating
      lighting and facial angles) or conceptual information (name,
      occupation) about target identities. When participants were
      provided with new images of the same identities and tested on
      their recognition ability, results showed better recognition
      following conceptual information compared with perceptual
      information.</p>
        </sec>
        <sec id="personally-familiar-faces">
          <title>Personally Familiar Faces</title>
          <p>Personal information acquired through repeated interaction with
      an identity appears to enhance familiar face recognition, as
      research shows that our face representations for personally
      familiar faces differ from those of recently learned faces and
      familiar celebrity faces
      (<xref alt="Cloutier et al., 2011" rid="ref-cloutier2011a" ref-type="bibr">Cloutier
      et al., 2011</xref>;
      <xref alt="Ramon &amp; Gobbini, 2017" rid="ref-ramon2017a" ref-type="bibr">Ramon
      &amp; Gobbini, 2017</xref>;
      <xref alt="Rooney et al., 2012" rid="ref-rooney2012a" ref-type="bibr">Rooney
      et al., 2012</xref>). Karimi-Rouzbahani et al.
      (<xref alt="2021" rid="ref-karimi-rouzbahani2021a" ref-type="bibr">2021</xref>)
      varied familiarity across stimuli (i.e., unfamiliar, famous,
      personally familiar, and self) and instructed 18 participants to
      categorise the stimulus as familiar or unfamiliar using a button
      press. EEG data, measuring brain electrical activity, showed that
      higher levels of familiarity (self-face and personally familiar)
      generated greater transfer of information flow over the visual
      areas of the brain compared to unfamiliar and famous identities.
      In contrast, Wiese et al.
      (<xref alt="2021" rid="ref-wiese2021a" ref-type="bibr">2021</xref>)
      found substantial EEG event-related potential familiarity effects
      in response to the self-face, personally familiar faces, and
      favourite celebrities compared with other celebrities,
      demonstrating similar processing of personally familiar faces and
      favourite celebrities.</p>
        </sec>
      </sec>
      <sec id="face-processing-efficiency-and-the-inversion-effect">
        <title>Face Processing Efficiency and the Inversion Effect</title>
        <p>The literature provides two interpretations of face processing
    efficiency. The holistic processing perspective emphasises the
    importance of analysing the spatial relations between features,
    providing a unique configuration for each individual so that faces
    are processed whole, rather than in parts
    (<xref alt="Maurer et al., 2002" rid="ref-maurer_many_2002" ref-type="bibr">Maurer
    et al., 2002</xref>;
    <xref alt="Sandford &amp; Burton, 2014" rid="ref-sandford2014a" ref-type="bibr">Sandford
    &amp; Burton, 2014</xref>). Evidence for holistic processing has
    been demonstrated predominantly in studies showing that when a face
    is inverted, disrupting its global configuration, participants find
    it harder to identify target faces
    (<xref alt="Taubert et al., 2011" rid="ref-taubert2011a" ref-type="bibr">Taubert
    et al., 2011</xref>;
    <xref alt="Tong &amp; Nakayama, 1999" rid="ref-tong1999a" ref-type="bibr">Tong
    &amp; Nakayama, 1999</xref>). The face inversion effect has been
    reliably used in the literature to explore face processing
    efficiency
    (<xref alt="Rossion, 2008" rid="ref-rossion_picture-plane_2008" ref-type="bibr">Rossion,
    2008</xref>;
    <xref alt="Taubert et al., 2015" rid="ref-taubert_effect_2015" ref-type="bibr">Taubert
    et al., 2015</xref>;
    <xref alt="Valentine, 1988" rid="ref-valentine_upside-down_1988" ref-type="bibr">Valentine,
    1988</xref>). Interestingly, studies have revealed that the effects
    of inversion are greater for unfamiliar faces than familiar faces,
    suggesting that familiar faces are not a slave to holistic
    processing
    (<xref alt="Oleggio Castello et al., 2017" rid="ref-oleggio2017a" ref-type="bibr">Oleggio
    Castello et al., 2017</xref>;
    <xref alt="Ramon &amp; Belle, 2016" rid="ref-ramon2016a" ref-type="bibr">Ramon
    &amp; Belle, 2016</xref>;
    <xref alt="Waidmann et al., 2022" rid="ref-waidmann_local_2022" ref-type="bibr">Waidmann
    et al., 2022</xref>).</p>
        <p>By contrast, the feature-based processing perspective suggests
    that processing efficiency, as observed with familiar faces, can be
    attributed to the learning of face features, such as eyes, nose, and
    mouth, which are then used as unique identifiers supporting
    processing efficiency
    (<xref alt="Abudarham &amp; Yovel, 2016" rid="ref-abudarham2016a" ref-type="bibr">Abudarham
    &amp; Yovel, 2016</xref>). Lee et al.
    (<xref alt="2022" rid="ref-lee2022a" ref-type="bibr">2022</xref>)
    explored holistic and featural processing effects in a study where
    participants viewed images of unfamiliar faces, friends’ faces, and
    the self-face in an inversion task, and a part-whole (isolated
    features) task. They found no significant difference in inversion
    effects across the unfamiliar, friend and self-face conditions,
    whereas, in the isolated features task, participants were faster and
    more accurate at recognising the self-face compared to friend and
    unfamiliar faces, suggesting the self-face may be processed in a
    more feature-based manner. Therefore, the commonly held belief that
    face recognition relies on holistic processing is being challenged,
    and it seems likely that not all faces are processed in the same
    way.</p>
        <sec id="the-self-face">
          <title>The Self-face</title>
          <p>Our own face is unique, as it plays an influential role in our
      self-consciousness and identity, and is an important tool for
      social engagement
      (<xref alt="Bortolon. &amp; Raffard, 2018" rid="ref-bortolon2018a" ref-type="bibr">Bortolon.
      &amp; Raffard, 2018</xref>). The ‘self-face advantage’ in face
      recognition has been consistently observed across different
      contexts and task demands, however, there is conflicting evidence
      for distinct processing between the self-face and other familiar
      faces
      (<xref alt="Alzueta et al., 2019" rid="ref-alzueta2019a" ref-type="bibr">Alzueta
      et al., 2019</xref>;
      <xref alt="Tong &amp; Nakayama, 1999" rid="ref-tong1999a" ref-type="bibr">Tong
      &amp; Nakayama, 1999</xref>;
      <xref alt="Wiese et al., 2019" rid="ref-wiese2019a" ref-type="bibr">Wiese
      et al., 2019</xref>). For example, Alzueta et al.
      (<xref alt="2019" rid="ref-alzueta2019a" ref-type="bibr">2019</xref>)
      used EEG to investigate whether the self-face elicits distinct
      neural processes compared to friends’ and stranger faces. The N170
      component, a negative-going EEG potential typically associated
      with face perception, did not exhibit sensitivity to the
      self-face, contradicting previous research
      (<xref alt="Caharel &amp; Rossion, 2021" rid="ref-caharel2021a" ref-type="bibr">Caharel
      &amp; Rossion, 2021</xref>;
      <xref alt="Wiese et al., 2019" rid="ref-wiese2019a" ref-type="bibr">Wiese
      et al., 2019</xref>). Findings supported an earlier behavioural
      study, where 40 participants were asked to attend with a friend
      and bring five photographs of their own face unseen by their
      friend. Participants viewed images of themselves, friends, famous,
      and unfamiliar faces and completed a face matching task
      (<xref alt="Bortolon et al., 2017" rid="ref-bortolon2017a" ref-type="bibr">Bortolon
      et al., 2017</xref>). Results showed participants were better at
      matching photographs of their own face than famous and unknown
      faces, but were not faster or more accurate at matching their own
      face than their friend’s face.</p>
          <p>Our understanding of the effects of familiarity on face
      recognition can be improved by experimenting with personally
      familiar faces, compared to famous faces, which would better
      represent familiarity effects as a result of real-world face
      learning. The self-face is arguably the most familiar face to each
      of us, and, thus, is an important inclusion in studies seeking to
      understand the effects of levels of familiarity on facial
      processing. In addition, exploration of an alternative research
      method designed to isolate recognition time (i.e., perceptual
      processes) from reaction time (i.e., perceptual processes +
      cognitive decision + motor response) is warranted to provide a
      more precise measure of the perceptual processing time for faces.
      This information would add value to the debate around whether the
      brain processes faces differently based on the level of
      familiarity.</p>
        </sec>
      </sec>
      <sec id="aims-and-hypotheses">
        <title>Aims and Hypotheses</title>
        <p>The purpose of the present study was to investigate the effect of
    higher levels of face familiarity on face recognition by
    manipulating both familiarity and orientation while measuring the
    minimal display time required for recognition (i.e., recognition
    time) and how quickly participants responded (i.e., reaction time).
    A staircase procedure was used as an alternative method for
    characterising face recognition performance. Familiar and unfamiliar
    faces were presented in both upright and inverted orientations, with
    the overall expectation that participants would need less time to
    recognise their own face compared to familiar and unfamiliar faces,
    and less time to recognise familiar faces compared to unfamiliar
    faces. Our specific hypotheses were as follows:</p>
        <list list-type="order">
          <list-item>
            <p>Participants will be able to recognise their own faces at
        shorter face display times compared with less familiar and
        unfamiliar faces;</p>
          </list-item>
          <list-item>
            <p>Participants will require shorter face display times to
        recognise a familiar face (that of the experimenter) compared to
        an unfamiliar face;</p>
          </list-item>
          <list-item>
            <p>Participants will require longer display times to recognise
        all faces when the face display is inverted;</p>
          </list-item>
          <list-item>
            <p>The face inversion effect (the difference between performance
        in upright and inverted trials) will be reduced for more
        familiar faces.</p>
          </list-item>
        </list>
      </sec>
    </sec>
    <sec id="method">
      <title>Method</title>
      <sec id="participants">
        <title>Participants</title>
        <p>A power analysis using G*Power 3.1.9.6
    (<xref alt="Faul et al., 2009" rid="ref-faul2009a" ref-type="bibr">Faul
    et al., 2009</xref>) determined that a repeated-measures analysis of
    variance (ANOVA) required 30 participants to reach a power of .90,
    with an alpha of .05 and an effect size of .15. This effect size was
    chosen based on previous studies
    (<xref alt="Campbell &amp; Tanaka, 2021" rid="ref-campbell2021a" ref-type="bibr">Campbell
    &amp; Tanaka, 2021</xref>;
    <xref alt="Zimmermann et al., 2019" rid="ref-zimmermann2019a" ref-type="bibr">Zimmermann
    et al., 2019</xref>). This study was approved by the Human Research
    Ethics Committee (Approval No. HE23-030) at the University of New
    England (UNE). Written informed consent was obtained from all
    participants. While 30 participants completed the study, the data
    for two participants was excluded from the analysis based on the
    pre-registered exclusion criteria stating that participants will be
    excluded if their recognition times for the majority of their trials
    were slower than the starting point face display time (18
    frames/66.67ms) for the majority of their trials. The final sample
    consisted of 28 females aged between 18 and 65 years (M = 43.1, SD =
    12.7), recruited through word of mouth and via flyers distributed on
    campus at the University. Participants signed up using the quick
    response (QR) code on the flyer, which generated an email to the
    experimenter. Only female participants were recruited to ensure
    stimulus consistency across conditions and eliminate gender as a
    possible biasing factor in face discrimination. The experiment took
    approximately 45 minutes to complete, and participants were
    compensated with an AUD $25 gift card. All participants had normal
    or corrected-to-normal vision and no self-reported diagnosed
    impairment in face perception (e.g., prosopagnosia).</p>
      </sec>
      <sec id="design-and-stimuli">
        <title>Design and Stimuli</title>
        <p>Stimuli were presented on a 22.5-inch (diagonal) VIEWPixx display
    toolbox, with a display resolution of 1920 (H) x 1200 (V) pixels.
    Face stimuli were programmed in MATLAB using custom code. Stimuli
    for the unfamiliar condition consisted of 16 female face identities
    selected from the NimStim database (the set of calm, neutral faces;
    Tottenham et al.
    (<xref alt="2009" rid="ref-tottenham2009a" ref-type="bibr">2009</xref>)).
    Two photographs of the experimenter were used to create a familiar
    face condition. To create the self-face condition, prior to the
    experiment, participants were asked to send two photographs of
    themselves with a neutral expression, without eyewear and with no
    hair across the face. Several steps were taken to equate image sets
    across all three conditions. First, the faces were aligned at the
    eyes and cropped to an oval to exclude hair and clothing. Second,
    all face identities wore a neutral expression. Third, two images per
    identity were used so that responses would be more likely to
    indicate identity processing rather than image-based processing.
    Fourth, all images were greyscale and root mean square (RMS)
    normalised for contrast.</p>
        <p>The images were presented within a 128-pixel rectangle and viewed
    from a distance of 57 centimetres. Faces were presented upright or
    inverted 180°. To ensure any transients from the onset of stimuli
    were masked, a mask stream was created using a series of 192-pixel
    (6°) square patches of randomly-generated noise filtered with a
    <inline-formula><alternatives><tex-math><![CDATA[1/f]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline"><mml:mrow><mml:mn>1</mml:mn><mml:mi>/</mml:mi><mml:mi>f</mml:mi></mml:mrow></mml:math></alternatives></inline-formula>
    frequency spectrum (see
    <xref alt="Figure 1" rid="fig-procedure">Figure 1</xref>). A mask
    stream of 200 ms appeared after each face image in all trials. Face
    stimuli were randomly offset from trial to trial by between 1 and 32
    pixels from their original display location to avoid the effects of
    low-level feature matching. Trials were presented in random order to
    reduce any systematic effects of practice on the results. Trials
    were pilot tested prior to the experiment to determine a starting
    point of the staircases (18 frames/66.67ms) for each trial.</p>
        <fig id="fig-procedure">
          <caption>
            <p>Figure 1: The visual stimulation sequence for each
      trial</p>
          </caption>
          <graphic mimetype="image" mime-subtype="png" xlink:href="images/FamiliarFace_Procedure.png"/>
        </fig>
      </sec>
      <sec id="threshold-analysis">
        <title>Threshold Analysis</title>
        <p>In this study we used a staircase procedure to measure face
    recognition speed. The staircase began with an easily detected
    visual display of a target face and distractor face (see
    <xref alt="Figure 1" rid="fig-procedure">Figure 1</xref>), with the
    participant’s task being to indicate whether the target face was in
    the upper or lower part of the display. Subsequent face stimuli
    display times were reduced until the participant made an error, at
    which point the staircase reversed so that face stimuli were
    displayed for longer periods of time until the participant responded
    correctly, triggering another reversal. Image display times were
    measured in units of 8.33 millisecond video frames. The staircase
    used a 1-up-3-down design, where a correct response 3 times in a row
    generated a reduction in display time by 1 frame. If the participant
    made an incorrect response, stimulus display times increased by 1
    frame. Each condition (unfamiliar, familiar, self-face) included
    four trials (two with upright faces and two with inverted faces) and
    each trial included two randomly interleaved staircases. The means
    of the thresholds for each staircase were averaged to calculate the
    shortest timeframe in which the face stimuli could be accurately
    recognised for each condition.</p>
      </sec>
      <sec id="procedure">
        <title>Procedure</title>
        <p>Participants were verbally briefed on the aim of the research and
    provided with an information sheet. An overview of the task was
    described as involving recognition of 12 target faces in a series of
    displays over the course of the experiment. Participants were seated
    opposite a desk with the VIEWPixx display screen and a keyboard to
    complete a practice trial to familiarise themselves with the task
    (see <xref alt="Figure 2" rid="fig-setup">Figure 2</xref>). The
    practice trial featured a randomly selected face from the unfamiliar
    face set, which was then excluded from the main experiment. A random
    selection of target and distractor faces were chosen for each
    participant. Before each trial, written instructions appeared on the
    screen advising participants to focus on a fixation cross at the
    centre of the screen and use the up and down arrow keys to indicate
    whether the target face appeared above (up arrow) or below (down
    arrow) the fixation cross. Participants pressed any key to continue
    to initiate the display of a ‘target’ face stimulus for five
    seconds. After the inspection period, participants pressed any key
    to start the trial. Trials began with a mask stream followed by a
    display containing the target face and a distractor face above and
    below the fixation cross. The target face appeared randomly either
    above or below the fixation cross. Faces were displayed in either an
    upright or inverted position.</p>
        <fig id="fig-setup">
          <caption>
            <p>Figure 2: Depiction of experimental setup; image
      created by Simone Hale (2023)</p>
          </caption>
          <graphic mimetype="image" mime-subtype="png" xlink:href="images/setup.png"/>
        </fig>
      </sec>
    </sec>
    <sec id="results">
      <title>Results</title>
      <sec id="data-preparation">
        <title>Data Preparation</title>
        <p>Data analyses were conducted using jamovi (version 2.3.21.0),
    with significance levels set to <inline-formula><alternatives><tex-math><![CDATA[\alpha = .05]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline"><mml:mrow><mml:mi>α</mml:mi><mml:mo>=</mml:mo><mml:mn>.05</mml:mn></mml:mrow></mml:math></alternatives></inline-formula>
    for analysis and <inline-formula><alternatives><tex-math><![CDATA[\alpha = .001]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline"><mml:mrow><mml:mi>α</mml:mi><mml:mo>=</mml:mo><mml:mn>.001</mml:mn></mml:mrow></mml:math></alternatives></inline-formula>
    for assumption testing. Data were examined for missing responses and
    no missingness was found. Two participants were excluded because
    their threshold scores were consistently above the starting point of
    the staircases (18 frames/ 66.67ms) for most of their trials. Thus,
    28 of the original 30 participants were included in the analyses.
    Recognition time was measured using the number of frames required to
    complete the task as determined by the staircase procedure. Frames
    were then converted to milliseconds based on the monitor refresh
    rate of 120 Hz. Reaction time was measured in milliseconds.</p>
      </sec>
      <sec id="data-analysis">
        <title>Data Analysis</title>
        <p>Assumption testing for the two-way repeated-measures analysis of
    variance (ANOVA) indicated no violated assumptions. Visual
    inspection of Q-Q plots showed a normal distribution of face
    recognition times in each condition and no obvious outliers.
    Homogeneity of variance was assumed, as Fmax scores were below 10,
    in both upright, <inline-formula><alternatives><tex-math><![CDATA[F_{max} = 2.110]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline"><mml:mrow><mml:msub><mml:mi>F</mml:mi><mml:mrow><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:mi>x</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>2.110</mml:mn></mml:mrow></mml:math></alternatives></inline-formula>,
    and inverted, <inline-formula><alternatives><tex-math><![CDATA[F_{max} = 1.697]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline"><mml:mrow><mml:msub><mml:mi>F</mml:mi><mml:mrow><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:mi>x</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>1.697</mml:mn></mml:mrow></mml:math></alternatives></inline-formula>,
    orientations. Mauchly’s test indicated that the assumption of
    sphericity was not violated for the main effect of condition,
    <inline-formula><alternatives><tex-math><![CDATA[W(28) = 0.82, p = .081]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline"><mml:mrow><mml:mi>W</mml:mi><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mn>28</mml:mn><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mn>0.82</mml:mn><mml:mo>,</mml:mo><mml:mi>p</mml:mi><mml:mo>=</mml:mo><mml:mn>.081</mml:mn></mml:mrow></mml:math></alternatives></inline-formula>
    and the interaction between condition and face orientation,
    <inline-formula><alternatives><tex-math><![CDATA[W(28) = 0.93, p = .399]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline"><mml:mrow><mml:mi>W</mml:mi><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mn>28</mml:mn><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mn>0.93</mml:mn><mml:mo>,</mml:mo><mml:mi>p</mml:mi><mml:mo>=</mml:mo><mml:mn>.399</mml:mn></mml:mrow></mml:math></alternatives></inline-formula>.</p>
        <p>A 2 x 3 repeated-measures analysis of variance (ANOVA) was used
    to explore the effects of face familiarity on face recognition time.
    The ANOVA showed a main effect of familiarity, with significant
    differences in face recognition times between unfamiliar, familiar
    and self-face conditions <inline-formula><alternatives><tex-math><![CDATA[F(2, 52) = 48.08, p < .001, \eta_p^2 = .649]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline"><mml:mrow><mml:mi>F</mml:mi><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mn>52</mml:mn><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mn>48.08</mml:mn><mml:mo>,</mml:mo><mml:mi>p</mml:mi><mml:mo>&lt;</mml:mo><mml:mn>.001</mml:mn><mml:mo>,</mml:mo><mml:msubsup><mml:mi>η</mml:mi><mml:mi>p</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo>=</mml:mo><mml:mn>.649</mml:mn></mml:mrow></mml:math></alternatives></inline-formula>.
    In support of the first hypothesis, post hoc comparisons with
    Bonferroni corrections showed participants recognised their own
    faces at shorter display times compared with less familiar faces,
    <inline-formula><alternatives><tex-math><![CDATA[t(26) = 3.99, p = .001]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline"><mml:mrow><mml:mi>t</mml:mi><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mn>26</mml:mn><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mn>3.99</mml:mn><mml:mo>,</mml:mo><mml:mi>p</mml:mi><mml:mo>=</mml:mo><mml:mn>.001</mml:mn></mml:mrow></mml:math></alternatives></inline-formula>,
    and unfamiliar faces, <inline-formula><alternatives><tex-math><![CDATA[t(26) = 11.12, p < .001]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline"><mml:mrow><mml:mi>t</mml:mi><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mn>26</mml:mn><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mn>11.12</mml:mn><mml:mo>,</mml:mo><mml:mi>p</mml:mi><mml:mo>&lt;</mml:mo><mml:mn>.001</mml:mn></mml:mrow></mml:math></alternatives></inline-formula>.
    The second hypothesis was also supported, as a post hoc comparison
    showed participants recognised the familiar face (that of the
    experimenter) at shorter display times than unfamiliar faces,
    <inline-formula><alternatives><tex-math><![CDATA[t(26) = 5.11, p < .001]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline"><mml:mrow><mml:mi>t</mml:mi><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mn>26</mml:mn><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mn>5.11</mml:mn><mml:mo>,</mml:mo><mml:mi>p</mml:mi><mml:mo>&lt;</mml:mo><mml:mn>.001</mml:mn></mml:mrow></mml:math></alternatives></inline-formula>.</p>
        <p>Results also supported the third hypothesis that participants
    would require longer display times to recognise all faces when
    displays were inverted. The ANOVA indicated a main effect of
    orientation for face recognition times,
    <inline-formula><alternatives><tex-math><![CDATA[F(1, 26) = 50.22, p <.001, \eta_p^2 = .659]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline"><mml:mrow><mml:mi>F</mml:mi><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>26</mml:mn><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mn>50.22</mml:mn><mml:mo>,</mml:mo><mml:mi>p</mml:mi><mml:mo>&lt;</mml:mo><mml:mn>.001</mml:mn><mml:mo>,</mml:mo><mml:msubsup><mml:mi>η</mml:mi><mml:mi>p</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo>=</mml:mo><mml:mn>.659</mml:mn></mml:mrow></mml:math></alternatives></inline-formula>.
    In addition, the fourth hypothesis was supported: the face inversion
    effect was reduced for more familiar faces. The ANOVA indicated a
    significant interaction between condition and face orientation,
    <inline-formula><alternatives><tex-math><![CDATA[F(2, 52) = 11.21, p < .001, \eta_p^2 = .301]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline"><mml:mrow><mml:mi>F</mml:mi><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mn>52</mml:mn><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mn>11.21</mml:mn><mml:mo>,</mml:mo><mml:mi>p</mml:mi><mml:mo>&lt;</mml:mo><mml:mn>.001</mml:mn><mml:mo>,</mml:mo><mml:msubsup><mml:mi>η</mml:mi><mml:mi>p</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo>=</mml:mo><mml:mn>.301</mml:mn></mml:mrow></mml:math></alternatives></inline-formula>.
    The effects of inversion on recognition time were reduced when faces
    were more familiar.
    <xref alt="Figure 3" rid="fig-recognition-times">Figure 3</xref>
    shows recognition times for inverted and upright face orientations
    for each condition.</p>
        <fig id="fig-recognition-times">
          <caption>
            <p>Figure 3: Recognition Times by Orientation for Each
      Condition</p>
          </caption>
          <graphic mimetype="image" mime-subtype="png" xlink:href="index_files/figure-jats/fig-recognition-times-1.png"/>
        </fig>
        <p>A small but significant interaction was also observed between age
    and condition, <inline-formula><alternatives><tex-math><![CDATA[F(2, 52) = 4.16, p = .021, \eta_p^2 = .138]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline"><mml:mrow><mml:mi>F</mml:mi><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mn>52</mml:mn><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mn>4.16</mml:mn><mml:mo>,</mml:mo><mml:mi>p</mml:mi><mml:mo>=</mml:mo><mml:mn>.021</mml:mn><mml:mo>,</mml:mo><mml:msubsup><mml:mi>η</mml:mi><mml:mi>p</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo>=</mml:mo><mml:mn>.138</mml:mn></mml:mrow></mml:math></alternatives></inline-formula>.
    For older participants, longer display times were required to
    recognise unfamiliar and familiar faces than younger participants,
    whereas older participants required relatively shorter display times
    to recognise the self-face compared to younger participants.
    <xref alt="Figure 4" rid="fig-correlations">Figure 4</xref> shows
    this interaction in more detail, illustrating the relationship
    between age and recognition time in each condition.</p>
        <fig id="fig-correlations">
          <caption>
            <p>Figure 4: Correlations between recognition times and
      age for each condition</p>
          </caption>
          <graphic mimetype="image" mime-subtype="png" xlink:href="index_files/figure-jats/fig-correlations-1.png"/>
        </fig>
      </sec>
      <sec id="exploratory-analysis">
        <title>Exploratory Analysis</title>
        <sec id="reaction-time">
          <title>Reaction Time</title>
          <p>An identical 2 x 3 repeated measures ANOVA was conducted on
      participant reaction times (computed as the elapsed time between
      stimulus presentation and button press), to identify whether
      reaction times would also reveal a familiarity effect in face
      recognition. The ANOVA showed a main effect of face condition,
      with faster reaction times for the more familiar faces,
      <inline-formula><alternatives><tex-math><![CDATA[F(2, 52) = 3.85, p = .028, \eta_p^2 = .129]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline"><mml:mrow><mml:mi>F</mml:mi><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mn>52</mml:mn><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mn>3.85</mml:mn><mml:mo>,</mml:mo><mml:mi>p</mml:mi><mml:mo>=</mml:mo><mml:mn>.028</mml:mn><mml:mo>,</mml:mo><mml:msubsup><mml:mi>η</mml:mi><mml:mi>p</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo>=</mml:mo><mml:mn>.129</mml:mn></mml:mrow></mml:math></alternatives></inline-formula>.
      There was also a significant main effect of face orientation, with
      longer reaction times for inverted faces,
      <inline-formula><alternatives><tex-math><![CDATA[F(1, 26) = 18.71, p <.001, eta_p^2 = .418]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline"><mml:mrow><mml:mi>F</mml:mi><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>26</mml:mn><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mn>18.71</mml:mn><mml:mo>,</mml:mo><mml:mi>p</mml:mi><mml:mo>&lt;</mml:mo><mml:mn>.001</mml:mn><mml:mo>,</mml:mo><mml:mi>e</mml:mi><mml:mi>t</mml:mi><mml:msubsup><mml:mi>a</mml:mi><mml:mi>p</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo>=</mml:mo><mml:mn>.418</mml:mn></mml:mrow></mml:math></alternatives></inline-formula>.
      However, there was no significant interaction between condition
      and face orientation, <inline-formula><alternatives><tex-math><![CDATA[F(2, 52) = 0.14, p = .872, eta_p^2) = .005]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline"><mml:mrow><mml:mi>F</mml:mi><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mn>52</mml:mn><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mn>0.14</mml:mn><mml:mo>,</mml:mo><mml:mi>p</mml:mi><mml:mo>=</mml:mo><mml:mn>.872</mml:mn><mml:mo>,</mml:mo><mml:mi>e</mml:mi><mml:mi>t</mml:mi><mml:msubsup><mml:mi>a</mml:mi><mml:mi>p</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo stretchy="false" form="postfix">)</mml:mo><mml:mo>=</mml:mo><mml:mn>.005</mml:mn></mml:mrow></mml:math></alternatives></inline-formula>.
      <xref alt="Figure 5" rid="fig-reaction-times">Figure 5</xref>
      shows reaction times for inverted and upright face orientations
      for each condition.</p>
          <fig id="fig-reaction-times">
            <caption>
              <p>Figure 5: Reaction times by orientation for each
        condition</p>
            </caption>
            <graphic mimetype="image" mime-subtype="png" xlink:href="index_files/figure-jats/fig-reaction-times-1.png"/>
          </fig>
        </sec>
      </sec>
    </sec>
    <sec id="discussion">
      <title>Discussion</title>
      <p>To better understand the effect of greater levels of familiarity on
  face recognition, the present study used a staircase procedure to
  characterise face recognition performance. Participants responded to
  three different face categories manipulated by familiarity
  (unfamiliar, familiar, and self), and orientation (upright and
  inverted). Recognition time (i.e., perceptual processes) was isolated
  from reaction time (i.e., perceptual processes + cognitive decision +
  motor response) and used as an index of the familiarity effect. The
  overall findings confirmed predictions that more familiar faces are
  processed faster than less familiar and unfamiliar faces. Notably, our
  results underscore the self-face as a unique class of familiar face,
  providing compelling evidence for distinct perceptual processing.</p>
      <sec id="familiarity-and-recognition-time">
        <title>Familiarity and Recognition Time</title>
        <p>In support of hypothesis one, participants recognised their own
    faces at shorter display times compared with other faces, providing
    evidence for distinct perceptual processing
    (<xref alt="Alzueta et al., 2019" rid="ref-alzueta2019a" ref-type="bibr">Alzueta
    et al., 2019</xref>;
    <xref alt="Rooney et al., 2012" rid="ref-rooney2012a" ref-type="bibr">Rooney
    et al., 2012</xref>). Results conflicted with an EEG study
    demonstrating the self-face elicited similar neural responses
    relative to personally familiar faces
    (<xref alt="Wiese et al., 2021" rid="ref-wiese2021a" ref-type="bibr">Wiese
    et al., 2021</xref>). The self-face advantage observed in the
    recognition times may reflect robust self-representations developed
    over time, strengthened by both the amount of exposure and the
    nature of the exposure we have with our own face
    (<xref alt="Bortolon et al., 2017" rid="ref-bortolon2017a" ref-type="bibr">Bortolon
    et al., 2017</xref>;
    <xref alt="Tong &amp; Nakayama, 1999" rid="ref-tong1999a" ref-type="bibr">Tong
    &amp; Nakayama, 1999</xref>). For example, examining our image in
    the mirror is a multisensory encounter, allowing us access to
    motor-sensory and tactile cues that enable us to update our mental
    representations of ourselves
    (<xref alt="Bortolon et al., 2017" rid="ref-bortolon2017a" ref-type="bibr">Bortolon
    et al., 2017</xref>). Further, research linking self-face
    recognition and self-esteem revealed that when participants viewed
    photographs of themselves alongside images that were manipulated to
    look more attractive, observers chose the manipulated images as more
    accurate self-representations, which correlated with higher
    self-esteem
    (<xref alt="Felisberti &amp; Musholt, 2014" rid="ref-felisberti2014a" ref-type="bibr">Felisberti
    &amp; Musholt, 2014</xref>). This tolerance to error, as reflected
    by the perceptual biases, may be a crucial and distinctive component
    of self-face representations that could enhance recognition
    performance
    (<xref alt="Felisberti &amp; Musholt, 2014" rid="ref-felisberti2014a" ref-type="bibr">Felisberti
    &amp; Musholt, 2014</xref>).</p>
        <p>Familiarity effects were also found in the shorter display times
    required to recognise the familiar face (the experimenter) compared
    to unfamiliar faces, supporting hypothesis two. The findings align
    with the abundant research evidence in face recognition
    demonstrating a qualitative and quantitative gap between familiar
    and unfamiliar face processing
    (<xref alt="Burton, 2013" rid="ref-burton2013a" ref-type="bibr">Burton,
    2013</xref>;
    <xref alt="Burton et al., 2016" rid="ref-burton2016a" ref-type="bibr">Burton
    et al., 2016</xref>;
    <xref alt="Ramon &amp; Gobbini, 2017" rid="ref-ramon2017a" ref-type="bibr">Ramon
    &amp; Gobbini, 2017</xref>). It is possible that familiar face
    recognition performance was strengthened by the opportunity for
    participants to learn how the experimenter’s face changed in
    appearance (e.g., different facial expressions and viewing angles),
    and the conceptual information (e.g., name and research interest)
    shared prior to the experiment
    (<xref alt="Dowsett et al., 2016" rid="ref-dowsett2016a" ref-type="bibr">Dowsett
    et al., 2016</xref>).</p>
        <p>The observation that older participants were faster at
    recognising their own face compared to younger participants was
    surprising given the rise in the importance of the “selfie” in
    popular culture
    (<xref alt="Tshidzumba, 2019" rid="ref-tshidzumba2019a" ref-type="bibr">Tshidzumba,
    2019</xref>). In line with previous research suggesting that we are
    better at discriminating faces from our own age group, it is
    possible that older participants found it easier to distinguish
    their own face from the distractor faces, which were young
    identities
    (<xref alt="Rhodes &amp; Anastasi, 2012" rid="ref-rhodes2012a" ref-type="bibr">Rhodes
    &amp; Anastasi, 2012</xref>).</p>
      </sec>
      <sec id="familiarity-and-inversion-effects">
        <title>Familiarity and Inversion Effects</title>
        <p>The present study replicated the face inversion effect, a common
    finding in previous research that suggests human participants
    experience more difficulty recognising faces when they are upside
    down than when they are upright in their canonical orientation.
    Therefore, these findings support the third hypothesis, that
    regardless of familiarity, faces are harder to recognise upside down
    (<xref alt="Allen-Davidian et al., 2021" rid="ref-allen-davidian2021a" ref-type="bibr">Allen-Davidian
    et al., 2021</xref>;
    <xref alt="Kramer et al., 2018" rid="ref-kramer2018a" ref-type="bibr">Kramer
    et al., 2018</xref>;
    <xref alt="Taubert et al., 2011" rid="ref-taubert2011a" ref-type="bibr">Taubert
    et al., 2011</xref>;
    <xref alt="Young &amp; Burton, 2017" rid="ref-young2017a" ref-type="bibr">Young
    &amp; Burton, 2017</xref>). This experiment also yielded empirical
    support for hypothesis four; the face inversion effect was
    significantly smaller for familiar faces than unfamiliar faces.
    Interestingly, the more familiar participants were with the face,
    the more immune they were to the inversion manipulation. This
    finding is consistent with previous studies that have also suggested
    that familiar faces are robust to the deleterious effects of
    inversion
    (<xref alt="Keyes, 2012" rid="ref-keyes2012a" ref-type="bibr">Keyes,
    2012</xref>;
    <xref alt="Keyes &amp; Brady, 2010" rid="ref-keyes2010a" ref-type="bibr">Keyes
    &amp; Brady, 2010</xref>;
    <xref alt="Yang et al., 2014" rid="ref-yang2014a" ref-type="bibr">Yang
    et al., 2014</xref>). However, results contradicted those of Alzueta
    et al.
    (<xref alt="2019" rid="ref-alzueta2019a" ref-type="bibr">2019</xref>),
    who found no significant change in the size of inversion effects
    across unfamiliar, familiar and self-face conditions. Inconsistent
    findings may be explained by the difference in task complexity
    between the studies. For example, the staircase used in the present
    study involved finding a target face between two images, displayed
    for a short period (e.g., 66.67ms starting point), averaging
    performance across 12 trials, whereas Alzueta et al.
    (<xref alt="2019" rid="ref-alzueta2019a" ref-type="bibr">2019</xref>)
    allowed participants 1000ms to categorise a single face display as
    “me”, “friend” or “stranger”, averaging performance across 450
    trials.</p>
        <p>Overall, these findings provide strong behavioural support for
    the idea that images of our face are processed differently to other
    faces, as participants were able to easily recognise their own face
    in the inverted position in less time than was required to recognise
    an upright unfamiliar face. The current results challenge the widely
    accepted view that all human faces are processed holistically, as
    the faster recognition times for inverted faces in the familiar and
    self-face conditions could be interpreted as evidence for stronger
    feature-based representations
    (<xref alt="Gerlach &amp; Mogensen, 2022" rid="ref-gerlach2022a" ref-type="bibr">Gerlach
    &amp; Mogensen, 2022</xref>;
    <xref alt="Tong &amp; Nakayama, 1999" rid="ref-tong1999a" ref-type="bibr">Tong
    &amp; Nakayama, 1999</xref>).</p>
      </sec>
      <sec id="reaction-time-and-levels-of-familiarity">
        <title>Reaction Time and Levels of Familiarity</title>
        <p>Consistent with recognition time results and in alignment with
    the literature, there was a significant difference in reaction times
    between unfamiliar, familiar and self-face conditions
    (<xref alt="Kloth et al., 2006" rid="ref-kloth2006a" ref-type="bibr">Kloth
    et al., 2006</xref>;
    <xref alt="Ramon et al., 2011" rid="ref-ramon2011a" ref-type="bibr">Ramon
    et al., 2011</xref>;
    <xref alt="Young &amp; Burton, 2017" rid="ref-young2017a" ref-type="bibr">Young
    &amp; Burton, 2017</xref>). Interestingly, the reaction times were
    found to be longer than those reported in other studies, which is
    likely due to the inherent task complexity when using a staircase,
    compared to more simple, untimed go/no-go face categorisation tasks
    (<xref alt="Bortolon et al., 2017" rid="ref-bortolon2017a" ref-type="bibr">Bortolon
    et al., 2017</xref>;
    <xref alt="Burton et al., 2016" rid="ref-burton2016a" ref-type="bibr">Burton
    et al., 2016</xref>;
    <xref alt="Ramon et al., 2011" rid="ref-ramon2011a" ref-type="bibr">Ramon
    et al., 2011</xref>;
    <xref alt="Smith et al., 2016" rid="ref-smith2016a" ref-type="bibr">Smith
    et al., 2016</xref>).</p>
        <p>Importantly, the data revealed that recognition times were
    substantially shorter than reaction times for each condition. For
    example, on average, participants recognised (processed) upright
    familiar faces within 43.8ms but required 547ms to respond (process
    + decision + motor response) to the target face. These findings have
    important implications for future research designs, as they suggest
    that reaction times may be underestimating face recognition
    performance. Reaction times were longer for inverted faces compared
    to upright faces, however, the data did not reveal the interaction
    observed in the recognition time data, as there was no significant
    difference in the face inversion effect between conditions. Thus,
    recognition time seems to be a more sensitive measure of familiarity
    effects in face recognition.</p>
      </sec>
      <sec id="future-directions">
        <title>Future Directions</title>
        <p>The staircase procedure was a key strength of the research,
    demonstrating that the reaction times reported in research may be
    underestimating human face recognition ability
    (<xref alt="Besson et al., 2016" rid="ref-besson2016a" ref-type="bibr">Besson
    et al., 2016</xref>;
    <xref alt="Caharel et al., 2014" rid="ref-caharel2014a" ref-type="bibr">Caharel
    et al., 2014</xref>;
    <xref alt="Ramon et al., 2011" rid="ref-ramon2011a" ref-type="bibr">Ramon
    et al., 2011</xref>). However, the study design could be considered
    difficult to compare with other face recognition research. First,
    recognition times cannot be directly compared with reaction times.
    Second, the staircase procedure only measured the ability of
    participants to discriminate between two stimuli, unlike other
    studies that require participants to identify a target face among an
    array of distractor faces
    (<xref alt="Megreya &amp; Burton, 2006" rid="ref-megraya2006a" ref-type="bibr">Megreya
    &amp; Burton, 2006</xref>). Third, the time constraint imposed by
    the staircase is not comparable with studies involving tasks without
    time limits
    (<xref alt="Zimmermann et al., 2019" rid="ref-zimmermann2019a" ref-type="bibr">Zimmermann
    et al., 2019</xref>). Future studies could attempt to address some
    of these comparability concerns by replicating the same study
    together with a standard go/no-go face categorisation task, to allow
    for a comparison of reaction times between the two tasks. Further,
    adapting the staircase to include a four-alternative force choice
    task, rather than the two alternatives used here, would provide a
    better comparison with studies involving recognition tasks that
    require discrimination between multiple exemplars. Although the
    study examined three levels of familiarity (unfamiliar, familiar,
    and self), other highly familiar faces such as famous faces were not
    included
    (<xref alt="Campbell et al., 2020" rid="ref-campbell2020a" ref-type="bibr">Campbell
    et al., 2020</xref>;
    <xref alt="Wiese et al., 2021" rid="ref-wiese2021a" ref-type="bibr">Wiese
    et al., 2021</xref>). Future studies could incorporate famous faces
    and face stimuli of identities that are more intimately known by the
    perceiver such as close friends and family members, to test the
    effects of different levels of familiarity on face recognition in
    both upright and inverted orientations. This would allow further
    exploration of the inversion effect found in the present study. It
    would also assist future face recognition research in defining the
    familiarity construct, particularly with respect to the self-face
    compared with other highly familiar faces. Further, the varying
    levels of familiarity participants had with the experimenter created
    inconsistency in the construct of the familiar condition. Future
    studies could include a larger sample of both previously unknown and
    previously known participants to compare the performance of two
    different levels of familiarity. Including previously unknown
    participants also provides valuable insight into the effects of
    real-world face learning on recognition.</p>
        <p>Future research should aim to involve diverse participants,
    including all genders and representation from all age groups. The
    female-only sample may have influenced results, as there is some
    evidence suggesting a female own-gender bias in face recognition
    performance
    (<xref alt="Herlitz &amp; Lovén, 2013" rid="ref-herlitz2013a" ref-type="bibr">Herlitz
    &amp; Lovén, 2013</xref>;
    <xref alt="Lovén et al., 2011" rid="ref-lov2011a" ref-type="bibr">Lovén
    et al., 2011</xref>;
    <xref alt="Mishra et al., 2019" rid="ref-mishra2019a" ref-type="bibr">Mishra
    et al., 2019</xref>). The mean age (43.1 years) in the present study
    is not reflective of the average age (~ 21-35 years) of participants
    in many other face recognition studies
    (<xref alt="Kloth et al., 2006" rid="ref-kloth2006a" ref-type="bibr">Kloth
    et al., 2006</xref>;
    <xref alt="Mohr et al., 2018" rid="ref-mohr2018a" ref-type="bibr">Mohr
    et al., 2018</xref>;
    <xref alt="Pachai et al., 2017" rid="ref-pachai2017a" ref-type="bibr">Pachai
    et al., 2017</xref>;
    <xref alt="Platek &amp; Kemp, 2009" rid="ref-platek2009a" ref-type="bibr">Platek
    &amp; Kemp, 2009</xref>). Including a range of age groups is
    warranted given the age interaction found in the present study and
    research suggesting an age-bias in face recognition performance
    (<xref alt="Rhodes &amp; Anastasi, 2012" rid="ref-rhodes2012a" ref-type="bibr">Rhodes
    &amp; Anastasi, 2012</xref>).</p>
      </sec>
      <sec id="conclusion">
        <title>Conclusion</title>
        <p>Overall, the findings of the present study demonstrate the
    familiarity advantage in face recognition. We provide strong
    evidence in support of distinct perceptual processing at different
    levels of familiarity, as demonstrated by faster recognition times
    for both the self-face and familiar face compared to unfamiliar
    faces. The self-face appears to be processed differently to other
    familiar faces, validating the self-face as an important inclusion
    in face studies seeking to understand the familiarity effect in face
    recognition. The staircase procedure provided a unique insight into
    processing time, highlighting the potential underestimation of face
    recognition ability in the literature. The finding that face
    inversion is less disruptive to the processing of more familiar
    faces is further evidence of distinct perceptual processes and
    challenges the widely held view that faces are processed
    holistically. We recommend further exploration of the effects of
    inversion at different levels of familiarity, to enhance
    understanding of perceptual processing distinctions, and identify
    implications for holistic and featural processing theories.</p>
      </sec>
    </sec>
  </body>
  <back>
    <ref-list>
      <title/>
      <ref id="ref-hole_effects_2002">
        <element-citation publication-type="article-journal">
          <person-group person-group-type="author">
            <name>
              <surname>Hole</surname>
              <given-names>Graham J</given-names>
            </name>
            <name>
              <surname>George</surname>
              <given-names>Patricia A</given-names>
            </name>
            <name>
              <surname>Eaves</surname>
              <given-names>Karen</given-names>
            </name>
            <name>
              <surname>Rasek</surname>
              <given-names>Ayman</given-names>
            </name>
          </person-group>
          <article-title>Effects of Geometric Distortions on Face-Recognition Performance</article-title>
          <source>Perception</source>
          <year iso-8601-date="2002-10">2002</year>
          <month>10</month>
          <date-in-citation content-type="access-date">
            <year iso-8601-date="2024-02-02">2024</year>
            <month>02</month>
            <day>02</day>
          </date-in-citation>
          <volume>31</volume>
          <issue>10</issue>
          <issn>0301-0066</issn>
          <uri>https://doi.org/10.1068/p3252</uri>
          <pub-id pub-id-type="doi">10.1068/p3252</pub-id>
          <fpage>1221</fpage>
          <lpage>1240</lpage>
        </element-citation>
      </ref>
      <ref id="ref-long_database_2023">
        <element-citation publication-type="article-journal">
          <person-group person-group-type="author">
            <name>
              <surname>Long</surname>
              <given-names>Houqiu</given-names>
            </name>
            <name>
              <surname>Peluso</surname>
              <given-names>Natalie</given-names>
            </name>
            <name>
              <surname>Baker</surname>
              <given-names>Chris I.</given-names>
            </name>
            <name>
              <surname>Japee</surname>
              <given-names>Shruti</given-names>
            </name>
            <name>
              <surname>Taubert</surname>
              <given-names>Jessica</given-names>
            </name>
          </person-group>
          <article-title>A database of heterogeneous faces for studying naturalistic expressions</article-title>
          <source>Scientific Reports</source>
          <year iso-8601-date="2023-04">2023</year>
          <month>04</month>
          <volume>13</volume>
          <issue>1</issue>
          <issn>2045-2322</issn>
          <pub-id pub-id-type="doi">10.1038/s41598-023-32659-5</pub-id>
          <pub-id pub-id-type="pmid">37012369</pub-id>
          <fpage>5383</fpage>
          <lpage/>
        </element-citation>
      </ref>
      <ref id="ref-maurer_many_2002">
        <element-citation publication-type="article-journal">
          <person-group person-group-type="author">
            <name>
              <surname>Maurer</surname>
              <given-names>Daphne</given-names>
            </name>
            <name>
              <surname>Grand</surname>
              <given-names>Richard Le</given-names>
            </name>
            <name>
              <surname>Mondloch</surname>
              <given-names>Catherine J.</given-names>
            </name>
          </person-group>
          <article-title>The many faces of configural processing</article-title>
          <source>Trends in Cognitive Sciences</source>
          <year iso-8601-date="2002-06">2002</year>
          <month>06</month>
          <date-in-citation content-type="access-date">
            <year iso-8601-date="2024-02-02">2024</year>
            <month>02</month>
            <day>02</day>
          </date-in-citation>
          <volume>6</volume>
          <issue>6</issue>
          <issn>1364-6613</issn>
          <uri>https://www.sciencedirect.com/science/article/pii/S1364661302019034</uri>
          <pub-id pub-id-type="doi">10.1016/S1364-6613(02)01903-4</pub-id>
          <fpage>255</fpage>
          <lpage>260</lpage>
        </element-citation>
      </ref>
      <ref id="ref-rossion_picture-plane_2008">
        <element-citation publication-type="article-journal">
          <person-group person-group-type="author">
            <name>
              <surname>Rossion</surname>
              <given-names>Bruno</given-names>
            </name>
          </person-group>
          <article-title>Picture-plane inversion leads to qualitative changes of face perception</article-title>
          <source>Acta Psychologica</source>
          <year iso-8601-date="2008">2008</year>
          <volume>128</volume>
          <issue>2</issue>
          <issn>1873-6297</issn>
          <pub-id pub-id-type="doi">10.1016/j.actpsy.2008.02.003</pub-id>
          <fpage>274</fpage>
          <lpage>289</lpage>
        </element-citation>
      </ref>
      <ref id="ref-rossion_what_2019">
        <element-citation publication-type="article-journal">
          <person-group person-group-type="author">
            <name>
              <surname>Rossion</surname>
              <given-names>Bruno</given-names>
            </name>
            <name>
              <surname>Taubert</surname>
              <given-names>Jessica</given-names>
            </name>
          </person-group>
          <article-title>What can we learn about human individual face recognition from experimental studies in monkeys?</article-title>
          <source>Vision Research</source>
          <year iso-8601-date="2019-04">2019</year>
          <month>04</month>
          <date-in-citation content-type="access-date">
            <year iso-8601-date="2024-02-02">2024</year>
            <month>02</month>
            <day>02</day>
          </date-in-citation>
          <volume>157</volume>
          <issn>0042-6989</issn>
          <uri>https://www.sciencedirect.com/science/article/pii/S0042698918301160</uri>
          <pub-id pub-id-type="doi">10.1016/j.visres.2018.03.012</pub-id>
          <fpage>142</fpage>
          <lpage>158</lpage>
        </element-citation>
      </ref>
      <ref id="ref-taubert_effect_2015">
        <element-citation publication-type="article-journal">
          <person-group person-group-type="author">
            <name>
              <surname>Taubert</surname>
              <given-names>Jessica</given-names>
            </name>
            <name>
              <surname>Van Belle</surname>
              <given-names>Goedele</given-names>
            </name>
            <name>
              <surname>Vanduffel</surname>
              <given-names>Wim</given-names>
            </name>
            <name>
              <surname>Rossion</surname>
              <given-names>Bruno</given-names>
            </name>
            <name>
              <surname>Vogels</surname>
              <given-names>Rufin</given-names>
            </name>
          </person-group>
          <article-title>The effect of face inversion for neurons inside and outside fMRI-defined face-selective cortical regions</article-title>
          <source>Journal of Neurophysiology</source>
          <year iso-8601-date="2015-03">2015</year>
          <month>03</month>
          <volume>113</volume>
          <issue>5</issue>
          <issn>1522-1598</issn>
          <pub-id pub-id-type="doi">10.1152/jn.00700.2014</pub-id>
          <pub-id pub-id-type="pmid">25520434</pub-id>
          <fpage>1644</fpage>
          <lpage>1655</lpage>
        </element-citation>
      </ref>
      <ref id="ref-towler_are_2019">
        <element-citation publication-type="article-journal">
          <person-group person-group-type="author">
            <name>
              <surname>Towler</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Kemp</surname>
              <given-names>R. I.</given-names>
            </name>
            <name>
              <surname>Bruce</surname>
              <given-names>V.</given-names>
            </name>
            <name>
              <surname>Burton</surname>
              <given-names>A. M.</given-names>
            </name>
            <name>
              <surname>Dunn</surname>
              <given-names>J. D.</given-names>
            </name>
            <name>
              <surname>White</surname>
              <given-names>D.</given-names>
            </name>
          </person-group>
          <article-title>Are face recognition abilities in humans and sheep really ‘comparable’?</article-title>
          <source>Royal Society Open Science</source>
          <year iso-8601-date="2019-01">2019</year>
          <month>01</month>
          <date-in-citation content-type="access-date">
            <year iso-8601-date="2024-02-02">2024</year>
            <month>02</month>
            <day>02</day>
          </date-in-citation>
          <volume>6</volume>
          <issue>1</issue>
          <uri>https://royalsocietypublishing.org/doi/10.1098/rsos.180772</uri>
          <pub-id pub-id-type="doi">10.1098/rsos.180772</pub-id>
          <fpage>180772</fpage>
          <lpage/>
        </element-citation>
      </ref>
      <ref id="ref-valentine_upside-down_1988">
        <element-citation publication-type="article-journal">
          <person-group person-group-type="author">
            <name>
              <surname>Valentine</surname>
              <given-names>Tim</given-names>
            </name>
          </person-group>
          <article-title>Upside-down faces: A review of the effect of inversion upon face recognition</article-title>
          <source>British Journal of Psychology</source>
          <year iso-8601-date="1988">1988</year>
          <date-in-citation content-type="access-date">
            <year iso-8601-date="2024-02-02">2024</year>
            <month>02</month>
            <day>02</day>
          </date-in-citation>
          <volume>79</volume>
          <issue>4</issue>
          <issn>2044-8295</issn>
          <uri>https://onlinelibrary.wiley.com/doi/abs/10.1111/j.2044-8295.1988.tb02747.x</uri>
          <pub-id pub-id-type="doi">10.1111/j.2044-8295.1988.tb02747.x</pub-id>
          <fpage>471</fpage>
          <lpage>491</lpage>
        </element-citation>
      </ref>
      <ref id="ref-waidmann_local_2022">
        <element-citation publication-type="article-journal">
          <person-group person-group-type="author">
            <name>
              <surname>Waidmann</surname>
              <given-names>Elena N.</given-names>
            </name>
            <name>
              <surname>Koyano</surname>
              <given-names>Kenji W.</given-names>
            </name>
            <name>
              <surname>Hong</surname>
              <given-names>Julie J.</given-names>
            </name>
            <name>
              <surname>Russ</surname>
              <given-names>Brian E.</given-names>
            </name>
            <name>
              <surname>Leopold</surname>
              <given-names>David A.</given-names>
            </name>
          </person-group>
          <article-title>Local features drive identity responses in macaque anterior face patches</article-title>
          <source>Nature Communications</source>
          <year iso-8601-date="2022-09">2022</year>
          <month>09</month>
          <date-in-citation content-type="access-date">
            <year iso-8601-date="2024-02-02">2024</year>
            <month>02</month>
            <day>02</day>
          </date-in-citation>
          <volume>13</volume>
          <issue>1</issue>
          <issn>2041-1723</issn>
          <uri>https://www.nature.com/articles/s41467-022-33240-w</uri>
          <pub-id pub-id-type="doi">10.1038/s41467-022-33240-w</pub-id>
          <fpage>5592</fpage>
          <lpage/>
        </element-citation>
      </ref>
      <ref id="ref-white_individual_2022">
        <element-citation publication-type="article-journal">
          <person-group person-group-type="author">
            <name>
              <surname>White</surname>
              <given-names>David</given-names>
            </name>
            <name>
              <surname>Burton</surname>
              <given-names>A. Mike</given-names>
            </name>
          </person-group>
          <article-title>Individual differences and the multidimensional nature of face perception</article-title>
          <source>Nature Reviews Psychology</source>
          <year iso-8601-date="2022-05">2022</year>
          <month>05</month>
          <date-in-citation content-type="access-date">
            <year iso-8601-date="2024-02-02">2024</year>
            <month>02</month>
            <day>02</day>
          </date-in-citation>
          <volume>1</volume>
          <issue>5</issue>
          <issn>2731-0574</issn>
          <uri>https://www.nature.com/articles/s44159-022-00041-3</uri>
          <pub-id pub-id-type="doi">10.1038/s44159-022-00041-3</pub-id>
          <fpage>287</fpage>
          <lpage>300</lpage>
        </element-citation>
      </ref>
      <ref id="ref-abudarham2016a">
        <element-citation publication-type="article-journal">
          <person-group person-group-type="author">
            <name>
              <surname>Abudarham</surname>
              <given-names>N.</given-names>
            </name>
            <name>
              <surname>Yovel</surname>
              <given-names>G.</given-names>
            </name>
          </person-group>
          <article-title>Reverse engineering the face space: Discovering the critical features for face identification</article-title>
          <source>Journal of Vision</source>
          <year iso-8601-date="2016">2016</year>
          <volume>16</volume>
          <issue>3</issue>
          <pub-id pub-id-type="doi">10.1167/16.3.40</pub-id>
          <fpage>1</fpage>
          <lpage>18</lpage>
        </element-citation>
      </ref>
      <ref id="ref-abudarham2019a">
        <element-citation publication-type="article-journal">
          <person-group person-group-type="author">
            <name>
              <surname>Abudarham</surname>
              <given-names>N.</given-names>
            </name>
            <name>
              <surname>Shkiller</surname>
              <given-names>L.</given-names>
            </name>
            <name>
              <surname>Yovel</surname>
              <given-names>G.</given-names>
            </name>
          </person-group>
          <article-title>Critical features for face recognition</article-title>
          <source>Cognition</source>
          <year iso-8601-date="2019">2019</year>
          <volume>182</volume>
          <pub-id pub-id-type="doi">10.1016/j.cognition.2018.09.002</pub-id>
          <fpage>73</fpage>
          <lpage>83</lpage>
        </element-citation>
      </ref>
      <ref id="ref-allen-davidian2021a">
        <element-citation publication-type="article-journal">
          <person-group person-group-type="author">
            <name>
              <surname>Allen-Davidian</surname>
              <given-names>Y.</given-names>
            </name>
            <name>
              <surname>Russo</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Yamamoto</surname>
              <given-names>N.</given-names>
            </name>
            <name>
              <surname>Kaufman</surname>
              <given-names>J.</given-names>
            </name>
            <name>
              <surname>Pegna</surname>
              <given-names>A. J.</given-names>
            </name>
            <name>
              <surname>Johnston</surname>
              <given-names>P.</given-names>
            </name>
          </person-group>
          <article-title>Turning the face inversion effect on its head: Violated expectations of orientation, lighting, and gravity enhance N170 amplitudes</article-title>
          <source>The Journal of Cognitive Neuroscience</source>
          <year iso-8601-date="2021">2021</year>
          <volume>33</volume>
          <issue>2</issue>
          <pub-id pub-id-type="doi">10.1162/jocn\_a\_01656</pub-id>
          <fpage>303</fpage>
          <lpage>314</lpage>
        </element-citation>
      </ref>
      <ref id="ref-alzueta2019a">
        <element-citation publication-type="article-journal">
          <person-group person-group-type="author">
            <name>
              <surname>Alzueta</surname>
              <given-names>E.</given-names>
            </name>
            <name>
              <surname>Melcón</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Poch</surname>
              <given-names>C.</given-names>
            </name>
            <name>
              <surname>Capilla</surname>
              <given-names>A.</given-names>
            </name>
          </person-group>
          <article-title>Is your own face more than a highly familiar face?</article-title>
          <source>Biological Psychology</source>
          <year iso-8601-date="2019">2019</year>
          <volume>142</volume>
          <pub-id pub-id-type="doi">10.1016/j.biopsycho.2019.01.018</pub-id>
          <fpage>100</fpage>
          <lpage>107</lpage>
        </element-citation>
      </ref>
      <ref id="ref-besson2016a">
        <element-citation publication-type="article-journal">
          <person-group person-group-type="author">
            <name>
              <surname>Besson</surname>
              <given-names>G.</given-names>
            </name>
            <name>
              <surname>Barragan-Jason</surname>
              <given-names>G.</given-names>
            </name>
            <name>
              <surname>Fabre-Thorpe</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Puma</surname>
              <given-names>S.</given-names>
            </name>
            <name>
              <surname>Ceccaldi</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Barbeau</surname>
              <given-names>E. J.</given-names>
            </name>
          </person-group>
          <article-title>From face processing to face recognition: Comparing three different processing levels</article-title>
          <source>Cognition</source>
          <year iso-8601-date="2016">2016</year>
          <volume>158</volume>
          <pub-id pub-id-type="doi">10.1016/j.cognition.2016.10.004</pub-id>
          <fpage>33</fpage>
          <lpage>43</lpage>
        </element-citation>
      </ref>
      <ref id="ref-bortolon2017a">
        <element-citation publication-type="article-journal">
          <person-group person-group-type="author">
            <name>
              <surname>Bortolon</surname>
              <given-names>C.</given-names>
            </name>
            <name>
              <surname>Lorieux</surname>
              <given-names>S.</given-names>
            </name>
            <name>
              <surname>Raffard</surname>
              <given-names>S.</given-names>
            </name>
          </person-group>
          <article-title>Self or familiar-face recognition advantage? New insight using ambient images</article-title>
          <source>The Quarterly Journal of Experimental Psychology</source>
          <year iso-8601-date="2017">2017</year>
          <volume>71</volume>
          <issue>6</issue>
          <pub-id pub-id-type="doi">10.1080/17470218.2017.1327982</pub-id>
          <fpage>1396</fpage>
          <lpage>1404</lpage>
        </element-citation>
      </ref>
      <ref id="ref-bortolon2018a">
        <element-citation publication-type="article-journal">
          <person-group person-group-type="author">
            <name>
              <surname>Bortolon.</surname>
            </name>
            <name>
              <surname>Raffard</surname>
              <given-names>S.</given-names>
            </name>
          </person-group>
          <article-title>Self-face advantage over familiar and unfamiliar faces: A three-level meta-analytic approach</article-title>
          <source>Psychonomic Bulletin &amp; Review</source>
          <year iso-8601-date="2018">2018</year>
          <volume>25</volume>
          <pub-id pub-id-type="doi">10.3758/s13423-018-1487-9</pub-id>
          <fpage>1287</fpage>
          <lpage>1300</lpage>
        </element-citation>
      </ref>
      <ref id="ref-blauch2021a">
        <element-citation publication-type="article-journal">
          <person-group person-group-type="author">
            <name>
              <surname>Blauch</surname>
              <given-names>N. M.</given-names>
            </name>
            <name>
              <surname>Behrmann</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Plaut</surname>
              <given-names>D. C.</given-names>
            </name>
          </person-group>
          <article-title>Computational insights into human perceptual expertise for familiar and unfamiliar face recognition</article-title>
          <source>Cognition</source>
          <year iso-8601-date="2021">2021</year>
          <volume>208</volume>
          <pub-id pub-id-type="doi">10.1016/j.cognition.2020.104341</pub-id>
          <fpage>1</fpage>
          <lpage>13</lpage>
        </element-citation>
      </ref>
      <ref id="ref-burton1999a">
        <element-citation publication-type="article-journal">
          <person-group person-group-type="author">
            <name>
              <surname>Burton</surname>
              <given-names>A. M.</given-names>
            </name>
            <name>
              <surname>Wilson</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Cowan</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Bruce</surname>
              <given-names>V.</given-names>
            </name>
          </person-group>
          <article-title>Face recognition in poor-quality video: Evidence from security surveillance</article-title>
          <source>Psychological Science</source>
          <year iso-8601-date="1999">1999</year>
          <volume>10</volume>
          <issue>3</issue>
          <pub-id pub-id-type="doi">10.1111/1467-9280.00144</pub-id>
          <fpage>243</fpage>
          <lpage>248</lpage>
        </element-citation>
      </ref>
      <ref id="ref-burton2011a">
        <element-citation publication-type="article-journal">
          <person-group person-group-type="author">
            <name>
              <surname>Burton</surname>
              <given-names>A. M.</given-names>
            </name>
            <name>
              <surname>Jenkins</surname>
              <given-names>R.</given-names>
            </name>
            <name>
              <surname>Schweinberger</surname>
              <given-names>S. R.</given-names>
            </name>
          </person-group>
          <article-title>Mental representations of familiar faces</article-title>
          <source>British Journal of Psychology</source>
          <year iso-8601-date="2011">2011</year>
          <volume>102</volume>
          <pub-id pub-id-type="doi">10.1111/j.2044-8295.2011.02039.x</pub-id>
          <fpage>2943</fpage>
          <lpage>958</lpage>
        </element-citation>
      </ref>
      <ref id="ref-burton2013a">
        <element-citation publication-type="article-journal">
          <person-group person-group-type="author">
            <name>
              <surname>Burton</surname>
              <given-names>A. M.</given-names>
            </name>
          </person-group>
          <article-title>Why has research in face recognition progressed so slowly? The importance of variability</article-title>
          <source>The Quarterly Journal of Experimental Psychology</source>
          <year iso-8601-date="2013">2013</year>
          <volume>66</volume>
          <issue>8</issue>
          <pub-id pub-id-type="doi">10.1080/17470218.2013.800125</pub-id>
          <fpage>1467</fpage>
          <lpage>1485</lpage>
        </element-citation>
      </ref>
      <ref id="ref-burton2016a">
        <element-citation publication-type="article-journal">
          <person-group person-group-type="author">
            <name>
              <surname>Burton</surname>
              <given-names>A. M.</given-names>
            </name>
            <name>
              <surname>Kramer</surname>
              <given-names>R. S. S.</given-names>
            </name>
            <name>
              <surname>Ritchie</surname>
              <given-names>K. L.</given-names>
            </name>
            <name>
              <surname>Jenkins</surname>
              <given-names>R.</given-names>
            </name>
          </person-group>
          <article-title>Identity from variation: Representations of faces derived from multiple instances</article-title>
          <source>Cognitive Science</source>
          <year iso-8601-date="2016">2016</year>
          <volume>40</volume>
          <issue>1</issue>
          <pub-id pub-id-type="doi">10.1111/cogs.12231</pub-id>
          <fpage>202</fpage>
          <lpage>223</lpage>
        </element-citation>
      </ref>
      <ref id="ref-burton2015a">
        <element-citation publication-type="article-journal">
          <person-group person-group-type="author">
            <name>
              <surname>Burton</surname>
              <given-names>A. M.</given-names>
            </name>
            <name>
              <surname>Schweinberger</surname>
              <given-names>S. R.</given-names>
            </name>
            <name>
              <surname>Jenkins</surname>
              <given-names>R.</given-names>
            </name>
            <name>
              <surname>Kaufmann</surname>
              <given-names>J. M.</given-names>
            </name>
          </person-group>
          <article-title>Arguments against a configural processing account of familiar face recognition</article-title>
          <source>Perspectives on Psychological Science</source>
          <year iso-8601-date="2015">2015</year>
          <volume>10</volume>
          <issue>4</issue>
          <pub-id pub-id-type="doi">10.1177/1745691615583129</pub-id>
          <fpage>482</fpage>
          <lpage>496</lpage>
        </element-citation>
      </ref>
      <ref id="ref-caharel2014a">
        <element-citation publication-type="article-journal">
          <person-group person-group-type="author">
            <name>
              <surname>Caharel</surname>
              <given-names>S.</given-names>
            </name>
            <name>
              <surname>Ramon</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Rossion</surname>
              <given-names>B.</given-names>
            </name>
          </person-group>
          <article-title>Face familiarity decisions take 200 msec in the human brain: Electrophysiological evidence from a go/no-go speeded task</article-title>
          <source>Journal of Cognitive Neuroscience</source>
          <year iso-8601-date="2014">2014</year>
          <volume>26</volume>
          <issue>1</issue>
          <pub-id pub-id-type="doi">10.1162/jocn\_a\_00451</pub-id>
          <fpage>81</fpage>
          <lpage>95</lpage>
        </element-citation>
      </ref>
      <ref id="ref-caharel2021a">
        <element-citation publication-type="article-journal">
          <person-group person-group-type="author">
            <name>
              <surname>Caharel</surname>
              <given-names>S.</given-names>
            </name>
            <name>
              <surname>Rossion</surname>
              <given-names>B.</given-names>
            </name>
          </person-group>
          <article-title>The N170 is sensitive to long-term (personal) familiarity of a face identity</article-title>
          <source>Neuroscience</source>
          <year iso-8601-date="2021">2021</year>
          <volume>458</volume>
          <pub-id pub-id-type="doi">10.1016/j.neuroscience.2020.12.036</pub-id>
          <fpage>244</fpage>
          <lpage>255</lpage>
        </element-citation>
      </ref>
      <ref id="ref-campbell2020a">
        <element-citation publication-type="article-journal">
          <person-group person-group-type="author">
            <name>
              <surname>Campbell</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Louw</surname>
              <given-names>R.</given-names>
            </name>
            <name>
              <surname>Michniak</surname>
              <given-names>E.</given-names>
            </name>
            <name>
              <surname>Tanaka</surname>
              <given-names>J. W.</given-names>
            </name>
          </person-group>
          <article-title>Identity-specific neural responses to three categories of face familiarity (own, friend, stranger) using fast periodic visual stimulation</article-title>
          <source>Neuropsychologia</source>
          <year iso-8601-date="2020">2020</year>
          <volume>141</volume>
          <fpage>1</fpage>
          <lpage>12</lpage>
        </element-citation>
      </ref>
      <ref id="ref-campbell2021a">
        <element-citation publication-type="article-journal">
          <person-group person-group-type="author">
            <name>
              <surname>Campbell</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Tanaka</surname>
              <given-names>J. W.</given-names>
            </name>
          </person-group>
          <article-title>When a stranger becomes a friend: Measuring the neural correlates of real-world face familiarisation</article-title>
          <source>Visual Cognition</source>
          <year iso-8601-date="2021">2021</year>
          <volume>29</volume>
          <issue>10</issue>
          <pub-id pub-id-type="doi">10.1080/13506285.2021.20002993</pub-id>
          <fpage>689</fpage>
          <lpage>707</lpage>
        </element-citation>
      </ref>
      <ref id="ref-cloutier2011a">
        <element-citation publication-type="article-journal">
          <person-group person-group-type="author">
            <name>
              <surname>Cloutier</surname>
              <given-names>J.</given-names>
            </name>
            <name>
              <surname>Kelley</surname>
              <given-names>W. M.</given-names>
            </name>
            <name>
              <surname>Heatherton</surname>
              <given-names>T. F.</given-names>
            </name>
          </person-group>
          <article-title>The influence of perceptual and knowledge-based familiarity on the neural substrates of face perception</article-title>
          <source>Social Neuroscience</source>
          <year iso-8601-date="2011">2011</year>
          <volume>6</volume>
          <issue>1</issue>
          <pub-id pub-id-type="doi">10.1080/17470911003693622</pub-id>
          <fpage>63</fpage>
          <lpage>75</lpage>
        </element-citation>
      </ref>
      <ref id="ref-collins2018a">
        <element-citation publication-type="article-journal">
          <person-group person-group-type="author">
            <name>
              <surname>Collins</surname>
              <given-names>E.</given-names>
            </name>
            <name>
              <surname>Robinson</surname>
              <given-names>A. K.</given-names>
            </name>
            <name>
              <surname>Berrmann</surname>
              <given-names>M.</given-names>
            </name>
          </person-group>
          <article-title>Distinct neural processes for the perception of familiar versus unfamiliar faces along the visual hierarchy revealed by EEG</article-title>
          <source>NeuroImage</source>
          <year iso-8601-date="2018">2018</year>
          <volume>181</volume>
          <pub-id pub-id-type="doi">10.1016/j.neuroimage.2018.06.080</pub-id>
          <fpage>120</fpage>
          <lpage>131</lpage>
        </element-citation>
      </ref>
      <ref id="ref-dobs2019a">
        <element-citation publication-type="article-journal">
          <person-group person-group-type="author">
            <name>
              <surname>Dobs</surname>
              <given-names>K.</given-names>
            </name>
            <name>
              <surname>Isik</surname>
              <given-names>L.</given-names>
            </name>
            <name>
              <surname>Pantazis</surname>
              <given-names>D.</given-names>
            </name>
            <name>
              <surname>Kanwisher</surname>
              <given-names>N.</given-names>
            </name>
          </person-group>
          <article-title>How face perception unfolds over time</article-title>
          <source>Nature Communications</source>
          <year iso-8601-date="2019">2019</year>
          <volume>10</volume>
          <issue>1</issue>
          <pub-id pub-id-type="doi">10.1038/s41467-019-09239-1</pub-id>
          <fpage>1</fpage>
          <lpage>10</lpage>
        </element-citation>
      </ref>
      <ref id="ref-dowsett2016a">
        <element-citation publication-type="article-journal">
          <person-group person-group-type="author">
            <name>
              <surname>Dowsett</surname>
              <given-names>A. J.</given-names>
            </name>
            <name>
              <surname>Sandford</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Burton</surname>
              <given-names>A. M.</given-names>
            </name>
          </person-group>
          <article-title>Face learning with multiple images leads to fast acquisition of familiarity for specific individuals</article-title>
          <source>The Quarterly Journal of Experimental Psychology</source>
          <year iso-8601-date="2016">2016</year>
          <volume>69</volume>
          <issue>1</issue>
          <pub-id pub-id-type="doi">10.1080/17470218.2015.1017513</pub-id>
          <fpage>1</fpage>
          <lpage>10</lpage>
        </element-citation>
      </ref>
      <ref id="ref-faul2009a">
        <element-citation publication-type="article-journal">
          <person-group person-group-type="author">
            <name>
              <surname>Faul</surname>
              <given-names>F.</given-names>
            </name>
            <name>
              <surname>Erdfelder</surname>
              <given-names>E.</given-names>
            </name>
            <name>
              <surname>Buchner</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Lang</surname>
              <given-names>A. G.</given-names>
            </name>
          </person-group>
          <article-title>Statistical power analyses using g*power 3.1: Tests for correlation and regression analyses</article-title>
          <source>Behaviour Research Methods</source>
          <year iso-8601-date="2009">2009</year>
          <volume>41</volume>
          <pub-id pub-id-type="doi">10.3758/BRM.41.4.1149</pub-id>
          <fpage>1149</fpage>
          <lpage>1160</lpage>
        </element-citation>
      </ref>
      <ref id="ref-felisberti2014a">
        <element-citation publication-type="article-journal">
          <person-group person-group-type="author">
            <name>
              <surname>Felisberti</surname>
              <given-names>F. M.</given-names>
            </name>
            <name>
              <surname>Musholt</surname>
              <given-names>K.</given-names>
            </name>
          </person-group>
          <article-title>Self-face perception: Individual differences and discrepancies associated with mental self-face representation, attractiveness and self-esteem</article-title>
          <source>Psychology &amp; Neuroscience</source>
          <year iso-8601-date="2014">2014</year>
          <volume>7</volume>
          <issue>2</issue>
          <pub-id pub-id-type="doi">10.3922/j.psns.2014.013</pub-id>
          <fpage>65</fpage>
          <lpage>72</lpage>
        </element-citation>
      </ref>
      <ref id="ref-gerlach2022a">
        <element-citation publication-type="article-journal">
          <person-group person-group-type="author">
            <name>
              <surname>Gerlach</surname>
              <given-names>C.</given-names>
            </name>
            <name>
              <surname>Mogensen</surname>
              <given-names>E.</given-names>
            </name>
          </person-group>
          <article-title>The face inversion effect does not provide a pure measure of holistic face processing</article-title>
          <source>Behaviour Research Methods</source>
          <year iso-8601-date="2022">2022</year>
          <volume>1-12</volume>
          <pub-id pub-id-type="doi">10.3758/s13428-022-02054-5</pub-id>
        </element-citation>
      </ref>
      <ref id="ref-hancock2000a">
        <element-citation publication-type="article-journal">
          <person-group person-group-type="author">
            <name>
              <surname>Hancock</surname>
              <given-names>P. J.</given-names>
            </name>
            <name>
              <surname>Bruce</surname>
              <given-names>V.</given-names>
            </name>
            <name>
              <surname>Burton</surname>
              <given-names>A. M.</given-names>
            </name>
          </person-group>
          <article-title>Recognition of unfamiliar faces</article-title>
          <source>Trends in Cognitive Sciences</source>
          <year iso-8601-date="2000">2000</year>
          <volume>4</volume>
          <issue>9</issue>
          <pub-id pub-id-type="doi">10.1016/s1364-6613(00)01519-9</pub-id>
          <fpage>330</fpage>
          <lpage>337</lpage>
        </element-citation>
      </ref>
      <ref id="ref-herlitz2013a">
        <element-citation publication-type="article-journal">
          <person-group person-group-type="author">
            <name>
              <surname>Herlitz</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Lovén</surname>
              <given-names>J.</given-names>
            </name>
          </person-group>
          <article-title>Sex differences and the own-gender bias in face recognition: A meta-analytic review</article-title>
          <source>Visual Cognition</source>
          <year iso-8601-date="2013">2013</year>
          <volume>21</volume>
          <issue>9-10</issue>
          <pub-id pub-id-type="doi">10.1080/13506285.2013.823140</pub-id>
          <fpage>1306</fpage>
          <lpage>1336</lpage>
        </element-citation>
      </ref>
      <ref id="ref-jenkins2011a">
        <element-citation publication-type="article-journal">
          <person-group person-group-type="author">
            <name>
              <surname>Jenkins</surname>
              <given-names>R.</given-names>
            </name>
            <name>
              <surname>White</surname>
              <given-names>D.</given-names>
            </name>
            <name>
              <surname>Montfort</surname>
              <given-names>X.</given-names>
            </name>
            <name>
              <surname>Burton</surname>
              <given-names>A. M.</given-names>
            </name>
          </person-group>
          <article-title>Variability in photos of the same face</article-title>
          <source>Cognition</source>
          <year iso-8601-date="2011">2011</year>
          <volume>121</volume>
          <pub-id pub-id-type="doi">10.1016/j.cognition.2011.08.001</pub-id>
          <fpage>313</fpage>
          <lpage>323</lpage>
        </element-citation>
      </ref>
      <ref id="ref-jenkins2018a">
        <element-citation publication-type="article-journal">
          <person-group person-group-type="author">
            <name>
              <surname>Jenkins</surname>
              <given-names>R.</given-names>
            </name>
            <name>
              <surname>Dowsett</surname>
              <given-names>A. J.</given-names>
            </name>
            <name>
              <surname>Burton</surname>
              <given-names>A. M.</given-names>
            </name>
          </person-group>
          <article-title>How many faces do people know? Proceedings of the royal society</article-title>
          <source>B, Biological Sciences</source>
          <year iso-8601-date="2018">2018</year>
          <volume>285</volume>
          <pub-id pub-id-type="doi">10.1098/rspb.2018.1319</pub-id>
          <fpage>20181319</fpage>
          <lpage/>
        </element-citation>
      </ref>
      <ref id="ref-karimi-rouzbahani2021a">
        <element-citation publication-type="article-journal">
          <person-group person-group-type="author">
            <name>
              <surname>Karimi-Rouzbahani</surname>
              <given-names>H.</given-names>
            </name>
            <name>
              <surname>Ramezani</surname>
              <given-names>F.</given-names>
            </name>
            <name>
              <surname>Woolgar</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Rich</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Ghodrati</surname>
              <given-names>M.</given-names>
            </name>
          </person-group>
          <article-title>Perceptual difficulty modulates the direction of information flow in familiar face recognition</article-title>
          <source>NeuroImage</source>
          <year iso-8601-date="2021">2021</year>
          <volume>233</volume>
          <pub-id pub-id-type="doi">10.1016/j.neuroimage.2021.117896</pub-id>
          <fpage>1</fpage>
          <lpage>15</lpage>
        </element-citation>
      </ref>
      <ref id="ref-keyes2012a">
        <element-citation publication-type="article-journal">
          <person-group person-group-type="author">
            <name>
              <surname>Keyes</surname>
              <given-names>H.</given-names>
            </name>
          </person-group>
          <article-title>Categorical perception effects for facial identity in robustly represented familiar and self-faces: The role of configural and featural information</article-title>
          <source>The Quarterly Journal of Experimental Psychology</source>
          <year iso-8601-date="2012">2012</year>
          <volume>65</volume>
          <issue>4</issue>
          <pub-id pub-id-type="doi">10.1080/17470218.2011.636822</pub-id>
          <fpage>760</fpage>
          <lpage>772</lpage>
        </element-citation>
      </ref>
      <ref id="ref-keyes2010a">
        <element-citation publication-type="article-journal">
          <person-group person-group-type="author">
            <name>
              <surname>Keyes</surname>
              <given-names>H.</given-names>
            </name>
            <name>
              <surname>Brady</surname>
              <given-names>N.</given-names>
            </name>
          </person-group>
          <article-title>Self-face recognition is characterised by “bi-lateral gain” and by faster, more accurate performance which persists when faces are inverted</article-title>
          <source>The Quarterly Journal of Experimental Psychology</source>
          <year iso-8601-date="2010">2010</year>
          <volume>63</volume>
          <issue>5</issue>
          <pub-id pub-id-type="doi">10.1080/17470211003611264</pub-id>
          <fpage>840</fpage>
          <lpage>847</lpage>
        </element-citation>
      </ref>
      <ref id="ref-kloth2006a">
        <element-citation publication-type="article-journal">
          <person-group person-group-type="author">
            <name>
              <surname>Kloth</surname>
              <given-names>N.</given-names>
            </name>
            <name>
              <surname>Dobel</surname>
              <given-names>C.</given-names>
            </name>
            <name>
              <surname>Schweinberger</surname>
              <given-names>S. R.</given-names>
            </name>
            <name>
              <surname>Zwitserlood</surname>
              <given-names>P.</given-names>
            </name>
            <name>
              <surname>Bölte</surname>
              <given-names>J.</given-names>
            </name>
            <name>
              <surname>Junghöfer</surname>
              <given-names>M.</given-names>
            </name>
          </person-group>
          <article-title>Effects of personal familiarity on early neuromagnetic correlates of face perception</article-title>
          <source>European Journal of Neuroscience</source>
          <year iso-8601-date="2006">2006</year>
          <volume>24</volume>
          <pub-id pub-id-type="doi">10.1111/j.1460-9568.2006.05211.x</pub-id>
          <fpage>3317</fpage>
          <lpage>3321</lpage>
        </element-citation>
      </ref>
      <ref id="ref-kramer2017a">
        <element-citation publication-type="article-journal">
          <person-group person-group-type="author">
            <name>
              <surname>Kramer</surname>
              <given-names>R. S. S.</given-names>
            </name>
            <name>
              <surname>Young</surname>
              <given-names>A. W.</given-names>
            </name>
            <name>
              <surname>Day</surname>
              <given-names>MgG</given-names>
            </name>
            <name>
              <surname>Burton</surname>
              <given-names>A. M.</given-names>
            </name>
          </person-group>
          <article-title>Robust social categorization emerges from learning the identities of very few faces</article-title>
          <source>Psychological Review</source>
          <year iso-8601-date="2017">2017</year>
          <volume>24</volume>
          <issue>2</issue>
          <pub-id pub-id-type="doi">10.1037/rev000048</pub-id>
          <fpage>115</fpage>
          <lpage>129</lpage>
        </element-citation>
      </ref>
      <ref id="ref-kramer2018a">
        <element-citation publication-type="article-journal">
          <person-group person-group-type="author">
            <name>
              <surname>Kramer</surname>
              <given-names>R. S. S.</given-names>
            </name>
            <name>
              <surname>Young</surname>
              <given-names>A. W.</given-names>
            </name>
            <name>
              <surname>Burton</surname>
              <given-names>A. M.</given-names>
            </name>
          </person-group>
          <article-title>Understanding face familiarity</article-title>
          <source>Cognition</source>
          <year iso-8601-date="2018">2018</year>
          <volume>172</volume>
          <pub-id pub-id-type="doi">10.1016/j.cognition.2017.12.005</pub-id>
          <fpage>46</fpage>
          <lpage>58</lpage>
        </element-citation>
      </ref>
      <ref id="ref-lee2022a">
        <element-citation publication-type="article-journal">
          <person-group person-group-type="author">
            <name>
              <surname>Lee</surname>
              <given-names>J. K. W.</given-names>
            </name>
            <name>
              <surname>Janssen</surname>
              <given-names>S. M. J.</given-names>
            </name>
            <name>
              <surname>Estudillo</surname>
              <given-names>A. J.</given-names>
            </name>
          </person-group>
          <article-title>A featural account for own-face processing? Looking for support from face inversion, composite face, and part-whole tasks</article-title>
          <source>i-Perception</source>
          <year iso-8601-date="2022">2022</year>
          <volume>13</volume>
          <issue>4</issue>
          <pub-id pub-id-type="doi">10.1177/20416695221111409</pub-id>
          <fpage>1</fpage>
          <lpage>22</lpage>
        </element-citation>
      </ref>
      <ref id="ref-liccione2014a">
        <element-citation publication-type="article-journal">
          <person-group person-group-type="author">
            <name>
              <surname>Liccione</surname>
              <given-names>D.</given-names>
            </name>
            <name>
              <surname>Moruzzi</surname>
              <given-names>S.</given-names>
            </name>
            <name>
              <surname>Rossi</surname>
              <given-names>F.</given-names>
            </name>
            <name>
              <surname>Manganaro</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Porta</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Nugrahaningsih</surname>
              <given-names>N.</given-names>
            </name>
            <name>
              <surname>Caserio</surname>
              <given-names>V.</given-names>
            </name>
            <name>
              <surname>Allegri</surname>
              <given-names>N.</given-names>
            </name>
          </person-group>
          <article-title>Familiarity is not notoriety</article-title>
          <source>Frontiers in Human Neuroscience</source>
          <year iso-8601-date="2014">2014</year>
          <volume>8</volume>
          <pub-id pub-id-type="doi">10.3389/fnhum.2014.00672</pub-id>
          <fpage>672</fpage>
          <lpage>672</lpage>
        </element-citation>
      </ref>
      <ref id="ref-lov2011a">
        <element-citation publication-type="article-journal">
          <person-group person-group-type="author">
            <name>
              <surname>Lovén</surname>
              <given-names>J.</given-names>
            </name>
            <name>
              <surname>Herlitz</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Rehnman</surname>
              <given-names>J.</given-names>
            </name>
          </person-group>
          <article-title>Women’s own-gender bias in face recognition memory</article-title>
          <source>Experimental Psychology</source>
          <year iso-8601-date="2011">2011</year>
          <volume>58</volume>
          <issue>4</issue>
          <pub-id pub-id-type="doi">10.1027/1618-3169/a000100</pub-id>
          <fpage>333</fpage>
          <lpage>340</lpage>
        </element-citation>
      </ref>
      <ref id="ref-megraya2006a">
        <element-citation publication-type="article-journal">
          <person-group person-group-type="author">
            <name>
              <surname>Megreya</surname>
              <given-names>A. M.</given-names>
            </name>
            <name>
              <surname>Burton</surname>
              <given-names>A. M.</given-names>
            </name>
          </person-group>
          <article-title>Unfamiliar faces are not faces: Evidence from a matching task</article-title>
          <source>Memory &amp; Cognition</source>
          <year iso-8601-date="2006">2006</year>
          <volume>34</volume>
          <issue>4</issue>
          <pub-id pub-id-type="doi">10.3758/BF03193433</pub-id>
          <fpage>865</fpage>
          <lpage>876</lpage>
        </element-citation>
      </ref>
      <ref id="ref-megraya2008a">
        <element-citation publication-type="article-journal">
          <person-group person-group-type="author">
            <name>
              <surname>Megreya</surname>
              <given-names>A. M.</given-names>
            </name>
            <name>
              <surname>Burton</surname>
              <given-names>A. M.</given-names>
            </name>
          </person-group>
          <article-title>Matching faces to photographs: Poor performance in eyewitness memory (without the memory)</article-title>
          <source>Journal of Experimental Psychology: Applied</source>
          <year iso-8601-date="2008">2008</year>
          <volume>14</volume>
          <issue>4</issue>
          <pub-id pub-id-type="doi">10.1037/a0013464</pub-id>
          <fpage>364</fpage>
          <lpage>372</lpage>
        </element-citation>
      </ref>
      <ref id="ref-mishra2019a">
        <element-citation publication-type="article-journal">
          <person-group person-group-type="author">
            <name>
              <surname>Mishra</surname>
              <given-names>M. V.</given-names>
            </name>
            <name>
              <surname>Likitlersuang</surname>
              <given-names>J.</given-names>
            </name>
            <name>
              <surname>Wilmer</surname>
              <given-names>J.</given-names>
            </name>
            <name>
              <surname>Cohan</surname>
              <given-names>S.</given-names>
            </name>
            <name>
              <surname>Germine</surname>
              <given-names>L.</given-names>
            </name>
            <name>
              <surname>DeGutis</surname>
              <given-names>J. M.</given-names>
            </name>
          </person-group>
          <article-title>Gender differences in familiar face recognition and the influence of sociocultural gender inequality</article-title>
          <source>Scientific Reports</source>
          <year iso-8601-date="2019">2019</year>
          <volume>9</volume>
          <pub-id pub-id-type="doi">10.1038/s41598-019-54074-5</pub-id>
          <fpage>1</fpage>
          <lpage>11</lpage>
        </element-citation>
      </ref>
      <ref id="ref-mohr2018a">
        <element-citation publication-type="article-journal">
          <person-group person-group-type="author">
            <name>
              <surname>Mohr</surname>
              <given-names>S.</given-names>
            </name>
            <name>
              <surname>Wang</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Engell</surname>
              <given-names>A. D.</given-names>
            </name>
          </person-group>
          <article-title>Early identity recognition of familiar faces is not dependent on holistic processing</article-title>
          <source>Social Cognitive and Affective Neuroscience</source>
          <year iso-8601-date="2018">2018</year>
          <volume>13</volume>
          <issue>10</issue>
          <pub-id pub-id-type="doi">10.1093/scan/nsy079</pub-id>
          <fpage>1019</fpage>
          <lpage>1027</lpage>
        </element-citation>
      </ref>
      <ref id="ref-murphy2015a">
        <element-citation publication-type="article-journal">
          <person-group person-group-type="author">
            <name>
              <surname>Murphy</surname>
              <given-names>J.</given-names>
            </name>
            <name>
              <surname>Ipser</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Gaigg</surname>
              <given-names>S. B.</given-names>
            </name>
            <name>
              <surname>Cook</surname>
              <given-names>R.</given-names>
            </name>
          </person-group>
          <article-title>Exemplar variance supports robust learning of facial identity</article-title>
          <source>Journal of Experimental Psychology: Human Perception and Performance</source>
          <year iso-8601-date="2015">2015</year>
          <volume>41</volume>
          <issue>3</issue>
          <pub-id pub-id-type="doi">10.1037/xhp0000049</pub-id>
          <fpage>577</fpage>
          <lpage>581</lpage>
        </element-citation>
      </ref>
      <ref id="ref-oliveira2015a">
        <element-citation publication-type="article-journal">
          <person-group person-group-type="author">
            <name>
              <surname>Oliveira</surname>
              <given-names>E. H.</given-names>
            </name>
            <name>
              <surname>Esteves</surname>
              <given-names>F.</given-names>
            </name>
            <name>
              <surname>Carvalho</surname>
              <given-names>H.</given-names>
            </name>
          </person-group>
          <article-title>Clinical profiles of stigma experiences, self-esteem and social relationships among people with schizophrenia, depressive, and bipolar disorders</article-title>
          <source>Psychiatry Research</source>
          <year iso-8601-date="2015">2015</year>
          <volume>229</volume>
          <issue>1-2</issue>
          <pub-id pub-id-type="doi">10.1016/j.psychres.2015.07.047</pub-id>
          <fpage>167</fpage>
          <lpage>173</lpage>
        </element-citation>
      </ref>
      <ref id="ref-oruc2019a">
        <element-citation publication-type="article-journal">
          <person-group person-group-type="author">
            <name>
              <surname>Oruc</surname>
              <given-names>I.</given-names>
            </name>
            <name>
              <surname>Shafai</surname>
              <given-names>F.</given-names>
            </name>
            <name>
              <surname>Murthy</surname>
              <given-names>S.</given-names>
            </name>
            <name>
              <surname>Lages</surname>
              <given-names>P.</given-names>
            </name>
            <name>
              <surname>Ton</surname>
              <given-names>T.</given-names>
            </name>
          </person-group>
          <article-title>The adult face-diet: A naturalistic observation study</article-title>
          <source>Vision Research</source>
          <year iso-8601-date="2019">2019</year>
          <volume>157</volume>
          <pub-id pub-id-type="doi">10.1016/j.visres.2018.01.001</pub-id>
          <fpage>222</fpage>
          <lpage>229</lpage>
        </element-citation>
      </ref>
      <ref id="ref-pachai2017a">
        <element-citation publication-type="article-journal">
          <person-group person-group-type="author">
            <name>
              <surname>Pachai</surname>
              <given-names>M. V.</given-names>
            </name>
            <name>
              <surname>Sekular</surname>
              <given-names>A. B.</given-names>
            </name>
            <name>
              <surname>Bennett</surname>
              <given-names>P. J.</given-names>
            </name>
            <name>
              <surname>Schyns</surname>
              <given-names>P. G.</given-names>
            </name>
            <name>
              <surname>Ramon</surname>
              <given-names>M.</given-names>
            </name>
          </person-group>
          <article-title>Personal familiarity enhances sensitivity to horizontal structure during processing of face identity</article-title>
          <source>Journal of Vision</source>
          <year iso-8601-date="2017">2017</year>
          <volume>17</volume>
          <issue>6</issue>
          <pub-id pub-id-type="doi">10.1167/17.6.5</pub-id>
          <fpage>1</fpage>
          <lpage>11</lpage>
        </element-citation>
      </ref>
      <ref id="ref-platek2009a">
        <element-citation publication-type="article-journal">
          <person-group person-group-type="author">
            <name>
              <surname>Platek</surname>
              <given-names>S. M.</given-names>
            </name>
            <name>
              <surname>Kemp</surname>
              <given-names>S. M.</given-names>
            </name>
          </person-group>
          <article-title>Is family special to the brain? An event-related fMRI study of familiar, familial, and self-face recognition</article-title>
          <source>Neuropsychologia</source>
          <year iso-8601-date="2009">2009</year>
          <volume>47</volume>
          <pub-id pub-id-type="doi">10.1016/j.neuropsychologia.2008.12.027</pub-id>
          <fpage>849</fpage>
          <lpage>858</lpage>
        </element-citation>
      </ref>
      <ref id="ref-quek2021a">
        <element-citation publication-type="article-journal">
          <person-group person-group-type="author">
            <name>
              <surname>Quek</surname>
              <given-names>G. L.</given-names>
            </name>
            <name>
              <surname>Rossion</surname>
              <given-names>B.</given-names>
            </name>
            <name>
              <surname>Liu-Shuang</surname>
              <given-names>J.</given-names>
            </name>
          </person-group>
          <article-title>Critical information thresholds underlying generic and familiar face categorisation at the same face encounter</article-title>
          <source>NeuroImage</source>
          <year iso-8601-date="2021">2021</year>
          <volume>243</volume>
          <pub-id pub-id-type="doi">10.1016/j.neuroimage.2021.118481</pub-id>
          <fpage>1</fpage>
          <lpage>14</lpage>
        </element-citation>
      </ref>
      <ref id="ref-ramon2011a">
        <element-citation publication-type="article-journal">
          <person-group person-group-type="author">
            <name>
              <surname>Ramon</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Caharel</surname>
              <given-names>S.</given-names>
            </name>
            <name>
              <surname>Rossion</surname>
              <given-names>B.</given-names>
            </name>
          </person-group>
          <article-title>The speed of recognition of personally familiar faces</article-title>
          <source>Perception</source>
          <year iso-8601-date="2011">2011</year>
          <volume>40</volume>
          <pub-id pub-id-type="doi">10.1068/p6794</pub-id>
          <fpage>437</fpage>
          <lpage>449</lpage>
        </element-citation>
      </ref>
      <ref id="ref-ramon2016a">
        <element-citation publication-type="article-journal">
          <person-group person-group-type="author">
            <name>
              <surname>Ramon</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Belle</surname>
              <given-names>G. van</given-names>
            </name>
          </person-group>
          <article-title>Real-life experience with personally familiar faces enhances discrimination based on global information</article-title>
          <source>PeerJ</source>
          <year iso-8601-date="2016">2016</year>
          <volume>4</volume>
          <pub-id pub-id-type="doi">10.7717/peerj.1465</pub-id>
          <fpage>1</fpage>
          <lpage>13</lpage>
        </element-citation>
      </ref>
      <ref id="ref-ramon2017a">
        <element-citation publication-type="article-journal">
          <person-group person-group-type="author">
            <name>
              <surname>Ramon</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Gobbini</surname>
              <given-names>M. I.</given-names>
            </name>
          </person-group>
          <article-title>Familiarity matters: A review on prioritized processing of personally familiar faces</article-title>
          <source>Visual Cognition</source>
          <year iso-8601-date="2017">2017</year>
          <volume>26</volume>
          <issue>3</issue>
          <pub-id pub-id-type="doi">10.1080/13506285.2017.1405134</pub-id>
          <fpage>179</fpage>
          <lpage>195</lpage>
        </element-citation>
      </ref>
      <ref id="ref-redfern2019a">
        <element-citation publication-type="article-journal">
          <person-group person-group-type="author">
            <name>
              <surname>Redfern</surname>
              <given-names>A. S.</given-names>
            </name>
            <name>
              <surname>Benton</surname>
              <given-names>C. P.</given-names>
            </name>
          </person-group>
          <article-title>Representation of facial identity includes expression variability</article-title>
          <source>Vision Research</source>
          <year iso-8601-date="2019">2019</year>
          <volume>157</volume>
          <pub-id pub-id-type="doi">10.1016/j.visres.2018.05.004</pub-id>
          <fpage>123</fpage>
          <lpage>131</lpage>
        </element-citation>
      </ref>
      <ref id="ref-rhodes2012a">
        <element-citation publication-type="article-journal">
          <person-group person-group-type="author">
            <name>
              <surname>Rhodes</surname>
              <given-names>M. G.</given-names>
            </name>
            <name>
              <surname>Anastasi</surname>
              <given-names>J. S.</given-names>
            </name>
          </person-group>
          <article-title>The own-age bias in face recognition: A meta-analytic and theoretical view</article-title>
          <source>Psychological Bulletin</source>
          <year iso-8601-date="2012">2012</year>
          <volume>138</volume>
          <issue>1</issue>
          <pub-id pub-id-type="doi">10.1037/a0025750</pub-id>
          <fpage>146</fpage>
          <lpage>174</lpage>
        </element-citation>
      </ref>
      <ref id="ref-rooney2012a">
        <element-citation publication-type="article-journal">
          <person-group person-group-type="author">
            <name>
              <surname>Rooney</surname>
              <given-names>B.</given-names>
            </name>
            <name>
              <surname>Keyes</surname>
              <given-names>H.</given-names>
            </name>
            <name>
              <surname>Brady</surname>
              <given-names>N.</given-names>
            </name>
          </person-group>
          <article-title>Shared or separate mechanisms for self-face and other-face processing? Evidence from adaptation</article-title>
          <source>Frontiers in Psychology</source>
          <year iso-8601-date="2012">2012</year>
          <volume>3</volume>
          <pub-id pub-id-type="doi">https://doi.org.10.3389.fpsyg.2012.00066</pub-id>
          <fpage>1</fpage>
          <lpage>9</lpage>
        </element-citation>
      </ref>
      <ref id="ref-sandford2014a">
        <element-citation publication-type="article-journal">
          <person-group person-group-type="author">
            <name>
              <surname>Sandford</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Burton</surname>
              <given-names>A. M.</given-names>
            </name>
          </person-group>
          <article-title>Tolerance for distorted faces: Challenges to a configural processing account of familiar face recognition</article-title>
          <source>Cognition</source>
          <year iso-8601-date="2014">2014</year>
          <volume>132</volume>
          <issue>3</issue>
          <pub-id pub-id-type="doi">10.1016/j.cognition.2014.04.005</pub-id>
          <fpage>262</fpage>
          <lpage>268</lpage>
        </element-citation>
      </ref>
      <ref id="ref-schwartz2016a">
        <element-citation publication-type="article-journal">
          <person-group person-group-type="author">
            <name>
              <surname>Schwartz</surname>
              <given-names>L.</given-names>
            </name>
            <name>
              <surname>Yovel</surname>
              <given-names>G.</given-names>
            </name>
          </person-group>
          <article-title>The roles of perceptual and conceptual information in face recognition</article-title>
          <source>Journal of Experimental Psychology: General</source>
          <year iso-8601-date="2016">2016</year>
          <volume>145</volume>
          <issue>11</issue>
          <pub-id pub-id-type="doi">10.1037/xge0000220</pub-id>
          <fpage>1493</fpage>
          <lpage>1511</lpage>
        </element-citation>
      </ref>
      <ref id="ref-schwartz2019a">
        <element-citation publication-type="article-journal">
          <person-group person-group-type="author">
            <name>
              <surname>Schwartz</surname>
              <given-names>L.</given-names>
            </name>
            <name>
              <surname>Yovel</surname>
              <given-names>G.</given-names>
            </name>
          </person-group>
          <article-title>Learning faces as concepts rather than percepts improves face recognition</article-title>
          <source>Journal of Experimental Psychology: Learning, Memory, and Cognition</source>
          <year iso-8601-date="2019">2019</year>
          <volume>45</volume>
          <issue>10</issue>
          <pub-id pub-id-type="doi">10.1037/xlm0000673</pub-id>
          <fpage>1733</fpage>
          <lpage>1747</lpage>
        </element-citation>
      </ref>
      <ref id="ref-smith2016a">
        <element-citation publication-type="article-journal">
          <person-group person-group-type="author">
            <name>
              <surname>Smith</surname>
              <given-names>M. L.</given-names>
            </name>
            <name>
              <surname>Volna</surname>
              <given-names>B.</given-names>
            </name>
            <name>
              <surname>Ewing</surname>
              <given-names>L.</given-names>
            </name>
          </person-group>
          <article-title>Distinct information critically distinguishes judgements of face familiarity and identity</article-title>
          <source>Journal of Experimental Psychology: Human Perception and Performance</source>
          <year iso-8601-date="2016">2016</year>
          <volume>42</volume>
          <issue>11</issue>
          <pub-id pub-id-type="doi">10.1037/xhp0000243</pub-id>
          <fpage>1770</fpage>
          <lpage>1779</lpage>
        </element-citation>
      </ref>
      <ref id="ref-taubert2011a">
        <element-citation publication-type="article-journal">
          <person-group person-group-type="author">
            <name>
              <surname>Taubert</surname>
              <given-names>J.</given-names>
            </name>
            <name>
              <surname>Apthorp</surname>
              <given-names>D.</given-names>
            </name>
            <name>
              <surname>Aagten-Murphy</surname>
              <given-names>D.</given-names>
            </name>
            <name>
              <surname>Alais</surname>
              <given-names>D.</given-names>
            </name>
          </person-group>
          <article-title>The role of holistic processing in face perception: Evidence from the face inversion effect</article-title>
          <source>Vision Research</source>
          <year iso-8601-date="2011">2011</year>
          <volume>51</volume>
          <pub-id pub-id-type="doi">10.1016/j.visres.2011.04.002</pub-id>
          <fpage>1273</fpage>
          <lpage>1278</lpage>
        </element-citation>
      </ref>
      <ref id="ref-tong1999a">
        <element-citation publication-type="article-journal">
          <person-group person-group-type="author">
            <name>
              <surname>Tong</surname>
              <given-names>F.</given-names>
            </name>
            <name>
              <surname>Nakayama</surname>
              <given-names>K.</given-names>
            </name>
          </person-group>
          <article-title>Robust representations for faces: Evidence from visual search</article-title>
          <source>Journal of Experimental Psychology: Human Perception and Performance</source>
          <year iso-8601-date="1999">1999</year>
          <volume>25</volume>
          <issue>4</issue>
          <pub-id pub-id-type="doi">10.1037//0096-1523.25.4.1016</pub-id>
          <fpage>1016</fpage>
          <lpage>1035</lpage>
        </element-citation>
      </ref>
      <ref id="ref-tottenham2009a">
        <element-citation publication-type="article-journal">
          <person-group person-group-type="author">
            <name>
              <surname>Tottenham</surname>
              <given-names>N.</given-names>
            </name>
            <name>
              <surname>Tanaka</surname>
              <given-names>J. W.</given-names>
            </name>
            <name>
              <surname>Leon</surname>
              <given-names>A. C.</given-names>
            </name>
            <name>
              <surname>McCarry</surname>
              <given-names>T.</given-names>
            </name>
            <name>
              <surname>Nurse</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Hare</surname>
              <given-names>T. A.</given-names>
            </name>
            <name>
              <surname>Marcus</surname>
              <given-names>D. J.</given-names>
            </name>
            <name>
              <surname>Westerlund</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Casey</surname>
              <given-names>B. J.</given-names>
            </name>
            <name>
              <surname>Nelson</surname>
              <given-names>C.</given-names>
            </name>
          </person-group>
          <article-title>The NimStim set of facial expressions: Judgements from untrained research participants</article-title>
          <source>Psychiatry Research</source>
          <year iso-8601-date="2009">2009</year>
          <volume>168</volume>
          <issue>3</issue>
          <pub-id pub-id-type="doi">10.1016/j.psychres.2008.05.006</pub-id>
          <fpage>242</fpage>
          <lpage>249</lpage>
        </element-citation>
      </ref>
      <ref id="ref-tshidzumba2019a">
        <element-citation publication-type="article-journal">
          <person-group person-group-type="author">
            <name>
              <surname>Tshidzumba</surname>
              <given-names>N. A.</given-names>
            </name>
          </person-group>
          <article-title>The selfie culture: Identity creation and status conferral on social media</article-title>
          <source>Gender &amp; Behaviour</source>
          <year iso-8601-date="2019">2019</year>
          <volume>17</volume>
          <issue>3</issue>
          <fpage>13577</fpage>
          <lpage>13584</lpage>
        </element-citation>
      </ref>
      <ref id="ref-oleggio2017a">
        <element-citation publication-type="article-journal">
          <person-group person-group-type="author">
            <name>
              <surname>Oleggio Castello</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Wheeler</surname>
              <given-names>K. G.</given-names>
            </name>
            <name>
              <surname>Cipolli</surname>
              <given-names>C.</given-names>
            </name>
            <name>
              <surname>Gobbini</surname>
              <given-names>M. I.</given-names>
            </name>
            <name>
              <surname>Urgesi</surname>
              <given-names>C.</given-names>
            </name>
          </person-group>
          <article-title>Familiarity facilitates feature-based face processing</article-title>
          <source>PLoS One</source>
          <year iso-8601-date="2017">2017</year>
          <volume>12</volume>
          <issue>6</issue>
          <pub-id pub-id-type="doi">10.1371/journal.pone.0178895</pub-id>
          <fpage>1</fpage>
          <lpage>13</lpage>
        </element-citation>
      </ref>
      <ref id="ref-white2016a">
        <element-citation publication-type="article-journal">
          <person-group person-group-type="author">
            <name>
              <surname>White</surname>
              <given-names>D.</given-names>
            </name>
            <name>
              <surname>Burton</surname>
              <given-names>A. L.</given-names>
            </name>
            <name>
              <surname>Kemp</surname>
              <given-names>R. I.</given-names>
            </name>
          </person-group>
          <article-title>Not looking yourself: The cost of self-selecting photographs for identity verification</article-title>
          <source>British Journal of Psychology</source>
          <year iso-8601-date="2016">2016</year>
          <volume>107</volume>
          <pub-id pub-id-type="doi">10.1111/bjop.12141</pub-id>
          <fpage>359</fpage>
          <lpage>373</lpage>
        </element-citation>
      </ref>
      <ref id="ref-wiese2019a">
        <element-citation publication-type="article-journal">
          <person-group person-group-type="author">
            <name>
              <surname>Wiese</surname>
              <given-names>H.</given-names>
            </name>
            <name>
              <surname>Tüttenberg</surname>
              <given-names>S. C.</given-names>
            </name>
            <name>
              <surname>Ingram</surname>
              <given-names>B. T.</given-names>
            </name>
            <name>
              <surname>Chan</surname>
              <given-names>C. Y. X.</given-names>
            </name>
            <name>
              <surname>Gurbuz</surname>
              <given-names>Z.</given-names>
            </name>
            <name>
              <surname>Burton</surname>
              <given-names>A. M.</given-names>
            </name>
            <name>
              <surname>Young</surname>
              <given-names>A. W.</given-names>
            </name>
          </person-group>
          <article-title>A robust neural index of high face familiarity</article-title>
          <source>Psychological Science</source>
          <year iso-8601-date="2019">2019</year>
          <volume>30</volume>
          <issue>2</issue>
          <pub-id pub-id-type="doi">10.1177/0956797618813572</pub-id>
          <fpage>261</fpage>
          <lpage>272</lpage>
        </element-citation>
      </ref>
      <ref id="ref-wiese2021a">
        <element-citation publication-type="article-journal">
          <person-group person-group-type="author">
            <name>
              <surname>Wiese</surname>
              <given-names>H.</given-names>
            </name>
            <name>
              <surname>Hobden</surname>
              <given-names>G.</given-names>
            </name>
            <name>
              <surname>Siilbek</surname>
              <given-names>E.</given-names>
            </name>
            <name>
              <surname>Martignac</surname>
              <given-names>V.</given-names>
            </name>
            <name>
              <surname>Flack</surname>
              <given-names>T. R.</given-names>
            </name>
            <name>
              <surname>Ritchie</surname>
              <given-names>K. L.</given-names>
            </name>
            <name>
              <surname>Young</surname>
              <given-names>A. W.</given-names>
            </name>
            <name>
              <surname>Burton</surname>
              <given-names>A. M.</given-names>
            </name>
          </person-group>
          <article-title>Familiarity is familiarity is familiarity: Event-related brain potentials reveal qualitatively similar representations of personally familiar and famous faces</article-title>
          <source>Journal of Experimental Psychology: Learning, Memory, and Cognition</source>
          <year iso-8601-date="2021">2021</year>
          <volume>48</volume>
          <issue>8</issue>
          <pub-id pub-id-type="doi">10.1037/xlm0001063</pub-id>
          <fpage>1144</fpage>
          <lpage>1164</lpage>
        </element-citation>
      </ref>
      <ref id="ref-yang2014a">
        <element-citation publication-type="article-journal">
          <person-group person-group-type="author">
            <name>
              <surname>Yang</surname>
              <given-names>N.</given-names>
            </name>
            <name>
              <surname>Shafai</surname>
              <given-names>F.</given-names>
            </name>
            <name>
              <surname>Oruc</surname>
              <given-names>I.</given-names>
            </name>
          </person-group>
          <article-title>Size determines whether specialized expert processes are engaged for recognition of faces</article-title>
          <source>Journal of Vision</source>
          <year iso-8601-date="2014">2014</year>
          <volume>14</volume>
          <issue>8</issue>
          <pub-id pub-id-type="doi">10.1167/14.8.17</pub-id>
          <fpage>1</fpage>
          <lpage>12</lpage>
        </element-citation>
      </ref>
      <ref id="ref-young2017a">
        <element-citation publication-type="article-journal">
          <person-group person-group-type="author">
            <name>
              <surname>Young</surname>
              <given-names>A. W.</given-names>
            </name>
            <name>
              <surname>Burton</surname>
              <given-names>A. M.</given-names>
            </name>
          </person-group>
          <article-title>Are we face experts?</article-title>
          <source>Trends in Cognitive Sciences</source>
          <year iso-8601-date="2017">2017</year>
          <volume>22</volume>
          <issue>2</issue>
          <pub-id pub-id-type="doi">10.1016/j.tics.2017.11.007</pub-id>
          <fpage>100</fpage>
          <lpage>110</lpage>
        </element-citation>
      </ref>
      <ref id="ref-zimmermann2019a">
        <element-citation publication-type="article-journal">
          <person-group person-group-type="author">
            <name>
              <surname>Zimmermann</surname>
              <given-names>F. G. S.</given-names>
            </name>
            <name>
              <surname>Yan</surname>
              <given-names>X.</given-names>
            </name>
            <name>
              <surname>Rossion</surname>
              <given-names>B.</given-names>
            </name>
          </person-group>
          <article-title>An objective, sensitive and ecologically valid neural measure of rapid human individual face recognition</article-title>
          <source>Royal Society Open Science</source>
          <year iso-8601-date="2019">2019</year>
          <volume>6</volume>
          <pub-id pub-id-type="doi">10.1098/rsos.181904</pub-id>
          <fpage>181904</fpage>
          <lpage/>
        </element-citation>
      </ref>
    </ref-list>
  </back>
  <sub-article article-type="notebook" id="nb-2-nb-article">
    <front-stub>
      <title-group>
        <article-title>Differences in the Perceptual Processing of Unfamiliar
and Familiar Faces</article-title>
      </title-group>
      <contrib-group>
        <contrib contrib-type="author">
          <name>
            <surname>McGinness</surname>
            <given-names>Kasey</given-names>
          </name>
          <string-name>Kasey McGinness</string-name>
          <role vocab="https://credit.niso.org" vocab-term="conceptualization" vocab-term-identifier="https://credit.niso.org/contributor-roles/conceptualization/">Conceptualization</role>
          <role vocab="https://credit.niso.org" vocab-term="investigation" vocab-term-identifier="https://credit.niso.org/contributor-roles/investigation/">Investigation</role>
          <role vocab="https://credit.niso.org" vocab-term="formal analysis" vocab-term-identifier="https://credit.niso.org/contributor-roles/formal-analysis/">Formal
Analysis</role>
          <role>Writing - original draft</role>
          <xref ref-type="aff" rid="aff-1-nb-article">a</xref>
        </contrib>
        <contrib contrib-type="author">
          <contrib-id contrib-id-type="orcid">0000-0002-6519-8068</contrib-id>
          <name>
            <surname>Taubert</surname>
            <given-names>Jessica</given-names>
          </name>
          <string-name>Jessica Taubert</string-name>
          <role vocab="https://credit.niso.org" vocab-term="conceptualization" vocab-term-identifier="https://credit.niso.org/contributor-roles/conceptualization/">Conceptualization</role>
          <role vocab="https://credit.niso.org" vocab-term="methodology" vocab-term-identifier="https://credit.niso.org/contributor-roles/methodology/">Methodology</role>
          <role>Writing - reviewing &amp; editing</role>
          <xref ref-type="aff" rid="aff-2-nb-article">b</xref>
        </contrib>
        <contrib contrib-type="author" corresp="yes">
          <contrib-id contrib-id-type="orcid">0000-0001-5785-024X</contrib-id>
          <name>
            <surname>Apthorp</surname>
            <given-names>Deborah</given-names>
          </name>
          <string-name>Deborah Apthorp</string-name>
          <email>dapthorp@une.edu.au</email>
          <role vocab="https://credit.niso.org" vocab-term="conceptualization" vocab-term-identifier="https://credit.niso.org/contributor-roles/conceptualization/">Conceptualization</role>
          <role vocab="https://credit.niso.org" vocab-term="project administration" vocab-term-identifier="https://credit.niso.org/contributor-roles/project-administration/">Project
administration</role>
          <role vocab="https://credit.niso.org" vocab-term="software" vocab-term-identifier="https://credit.niso.org/contributor-roles/software/">Software</role>
          <role vocab="https://credit.niso.org" vocab-term="formal analysis" vocab-term-identifier="https://credit.niso.org/contributor-roles/formal-analysis/">Formal
analysis</role>
          <role>Writing - reviewing &amp; editing</role>
          <role vocab="https://credit.niso.org" vocab-term="visualization" vocab-term-identifier="https://credit.niso.org/contributor-roles/visualization/">Visualization</role>
          <role vocab="https://credit.niso.org" vocab-term="supervision" vocab-term-identifier="https://credit.niso.org/contributor-roles/supervision/">Supervision</role>
          <xref ref-type="aff" rid="aff-1-nb-article">a</xref>
          <xref ref-type="aff" rid="aff-3-nb-article">c</xref>
          <xref ref-type="corresp" rid="cor-3-nb-article">*</xref>
        </contrib>
      </contrib-group>
      <aff id="aff-1-nb-article">
        <institution-wrap>
          <institution>University of New England</institution>
        </institution-wrap>
      </aff>
      <aff id="aff-2-nb-article">
        <institution-wrap>
          <institution>University of Queensland</institution>
        </institution-wrap>
      </aff>
      <aff id="aff-3-nb-article">
        <institution-wrap>
          <institution>Australian National University</institution>
        </institution-wrap>
      </aff>
      <author-notes>
        <corresp id="cor-3-nb-article">dapthorp@une.edu.au</corresp>
      </author-notes>
      <abstract>
        <p>Evidence that familiar faces are processed differently from
unfamiliar faces has important implications for our understanding of how
we recognise the people around us. Although familiarity effects on face
recognition performance have been extensively researched, the perceptual
and cognitive processes that underlie these differences are
comparatively unknown. Using a psychophysical staircase paradigm, we
collected data from 28 female participants aged 18-65 years
(<inline-formula><alternatives><tex-math><![CDATA[M = 43.1]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline"><mml:mrow><mml:mi>M</mml:mi><mml:mo>=</mml:mo><mml:mn>43.1</mml:mn></mml:mrow></mml:math></alternatives></inline-formula>,
<inline-formula><alternatives><tex-math><![CDATA[SD = 12.7]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline"><mml:mrow><mml:mi>S</mml:mi><mml:mi>D</mml:mi><mml:mo>=</mml:mo><mml:mn>12.7</mml:mn></mml:mrow></mml:math></alternatives></inline-formula>)
and probed perceptual processing by measuring the minimum amount of time
required to recognise a previously seen face across three levels of
familiarity (unfamiliar, familiar, and self). We also measured a second
dependent variable, reaction time, which is thought to reflect both
perceptual and cognitive processes. The results revealed that
participants needed less time to recognise familiar faces compared to
unfamiliar faces. Concomitantly, participants needed less time to
respond when tasked with recognising faces compared to unfamiliar faces.
As expected, inverted faces took longer to recognise than upright faces,
but this effect was reduced for familiar and self-faces. Recognition
times provide evidence for distinct perceptual processing based on level
of familiarity and suggest that our ability to recognise familiar faces
may be poorly characterised by current theories. Overall, the results
emphasise the uniqueness of the self-face within the familiarity
continuum, as all participants were able to recognise their own face
significantly faster than other faces. In light of these results, it is
clear that a full understanding of how face recognition is accomplished
will require a better characterisation of how we respond to highly
familiar faces.</p>
      </abstract>
    </front-stub>
    <body>
      <sec id="nb-code-cell-1-nb-article" specific-use="notebook-code">
        <code language="r script">library(afex)</code>
        <code language="r script">library(emmeans)
library(readr)
library(tidyr)</code>
        <code language="r script">library(reshape2)</code>
        <code language="r script">library(tidyverse)</code>
        <code language="r script">library(dplyr)
library(raincloudplots)
library (patchwork)

#Define colors - upright vs. inverted
upright_col = '#FF3030'
inverted_col = "#836FFF"




Mean_Frames &lt;- read_csv("Mean_Frames_Familiar_Faces_Filtered.csv")</code>
        <code language="r script">Mean_Frames_long &lt;- melt(Mean_Frames, 
                         # ID variables - all the variables to keep but not split apart on
                         id.vars=c("Participant", "Age"),
                         # The source columns
                         measure.vars=c("Unfamiliar_Upright", "Unfamiliar_Inverted", 
                                        "Familiar_Upright", "Familiar_Inverted", 
                                        "Self_Upright", "Self_Inverted"),
                         # Name of the destination column that will identify the original
                         # column that the measurement came from
                         variable.name="Condition",
                         value.name="Mean_N_Frames"               
                         
                         )

Mean_Frames_long &lt;- Mean_Frames_long %&gt;%
  mutate(Orientation = case_when(Condition == 'Unfamiliar_Upright' ~ 'Upright',
                                    Condition == 'Familiar_Upright' ~ 'Upright',
                                    Condition == 'Self_Upright' ~ 'Upright',
                                    TRUE ~ 'Inverted'))

Mean_Frames_long &lt;- Mean_Frames_long %&gt;%
  mutate(Familiarity = case_when(Condition == 'Unfamiliar_Upright' ~ 'Unfamiliar',
                                 Condition == 'Unfamiliar_Inverted' ~ 'Unfamiliar',
                                 Condition == 'Familiar_Upright' ~ 'Familiar',
                                 Condition == 'Familiar_Inverted' ~ 'Familiar',
                                 TRUE ~ 'Self'))

Mean_Frames_long$Mean_time &lt;- Mean_Frames_long$Mean_N_Frames*(1000/120)

MeanFrames_UF_Upright &lt;- filter(Mean_Frames_long, Condition == 'Unfamiliar_Upright')
MeanFrames_UF_Inverted &lt;- filter(Mean_Frames_long, Condition == 'Unfamiliar_Inverted')
MeanFrames_F_Upright&lt;- filter(Mean_Frames_long, Condition == 'Familiar_Upright')
MeanFrames_F_Inverted &lt;- filter(Mean_Frames_long, Condition == 'Familiar_Inverted')
MeanFrames_S_Upright&lt;- filter(Mean_Frames_long, Condition == 'Self_Upright')
MeanFrames_S_Inverted &lt;- filter(Mean_Frames_long, Condition == 'Self_Inverted')

df_2x3_Time_All &lt;- data_2x2(
  array_1 = MeanFrames_UF_Upright$Mean_time,
  array_2 = MeanFrames_UF_Inverted$Mean_time,
  array_3 = MeanFrames_F_Upright$Mean_time,
  array_4 = MeanFrames_F_Inverted$Mean_time,
  array_5 = MeanFrames_S_Upright$Mean_time,
  array_6 = MeanFrames_S_Inverted$Mean_time,
  labels = (c('Upright','Inverted')),
  jit_distance = .09,
  jit_seed = 321,
  # spread_x_ticks = FALSE
) 

# Change column name to be more meaningful
colnames(df_2x3_Time_All)[colnames(df_2x3_Time_All) == "group"] &lt;- "Orientation"

## Raincloud plot for recognition time 


faces_2x3_time &lt;- raincloud_2x3_repmes(
  data = df_2x3_Time_All,
  colors = c(upright_col, inverted_col, upright_col, inverted_col, upright_col, inverted_col),
  fills = c(upright_col, inverted_col, upright_col, inverted_col, upright_col, inverted_col),
  alpha = .5) +
  scale_x_continuous(breaks=c(1,2,3), labels=c("Unfamiliar", "Familiar", "Self"), limits=c(0.5, 4)) +
  xlab("Face Familiarity") + 
  ylab("Mean recognition time (milliseconds)") +
  #labs(title = "Threshold recognition times for face presentation") +
  theme_classic()+
  
  # Add lines for individual subjects 
 geom_path(aes(x = jit, y = y_axis, group = interaction(Orientation, id), color = Orientation), alpha = .5) +
 scale_color_manual(values = c(inverted_col, upright_col))</code>
        <sec id="nb-code-cell-1-output-0-nb-article" specific-use="notebook-output">
          <preformat>Loading required package: lme4</preformat>
        </sec>
        <sec id="nb-code-cell-1-output-1-nb-article" specific-use="notebook-output">
          <preformat>Loading required package: Matrix</preformat>
        </sec>
        <sec id="nb-code-cell-1-output-2-nb-article" specific-use="notebook-output">
          <preformat>************
Welcome to afex. For support visit: http://afex.singmann.science/</preformat>
        </sec>
        <sec id="nb-code-cell-1-output-3-nb-article" specific-use="notebook-output">
          <preformat>- Functions for ANOVAs: aov_car(), aov_ez(), and aov_4()
- Methods for calculating p-values with mixed(): 'S', 'KR', 'LRT', and 'PB'
- 'afex_aov' and 'mixed' objects can be passed to emmeans() for follow-up tests
- Get and set global package options with: afex_options()
- Set sum-to-zero contrasts globally: set_sum_contrasts()
- For example analyses see: browseVignettes("afex")
************</preformat>
        </sec>
        <sec id="nb-code-cell-1-output-4-nb-article" specific-use="notebook-output">
          <preformat>
Attaching package: 'afex'</preformat>
        </sec>
        <sec id="nb-code-cell-1-output-5-nb-article" specific-use="notebook-output">
          <preformat>The following object is masked from 'package:lme4':

    lmer</preformat>
        </sec>
        <sec id="nb-code-cell-1-output-6-nb-article" specific-use="notebook-output">
          <preformat>
Attaching package: 'tidyr'</preformat>
        </sec>
        <sec id="nb-code-cell-1-output-7-nb-article" specific-use="notebook-output">
          <preformat>The following objects are masked from 'package:Matrix':

    expand, pack, unpack</preformat>
        </sec>
        <sec id="nb-code-cell-1-output-8-nb-article" specific-use="notebook-output">
          <preformat>
Attaching package: 'reshape2'</preformat>
        </sec>
        <sec id="nb-code-cell-1-output-9-nb-article" specific-use="notebook-output">
          <preformat>The following object is masked from 'package:tidyr':

    smiths</preformat>
        </sec>
        <sec id="nb-code-cell-1-output-10-nb-article" specific-use="notebook-output">
          <preformat>── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──
✔ dplyr     1.1.4     ✔ purrr     1.0.2
✔ forcats   1.0.0     ✔ stringr   1.5.1
✔ ggplot2   3.5.1     ✔ tibble    3.2.1
✔ lubridate 1.9.3     </preformat>
        </sec>
        <sec id="nb-code-cell-1-output-11-nb-article" specific-use="notebook-output">
          <preformat>── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──
✖ tidyr::expand() masks Matrix::expand()
✖ dplyr::filter() masks stats::filter()
✖ dplyr::lag()    masks stats::lag()
✖ tidyr::pack()   masks Matrix::pack()
✖ tidyr::unpack() masks Matrix::unpack()
ℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors</preformat>
        </sec>
        <sec id="nb-code-cell-1-output-12-nb-article" specific-use="notebook-output">
          <preformat>Rows: 28 Columns: 8
── Column specification ────────────────────────────────────────────────────────
Delimiter: ","
chr (1): Participant
dbl (7): Unfamiliar_Upright, Unfamiliar_Inverted, Familiar_Upright, Familiar...

ℹ Use `spec()` to retrieve the full column specification for this data.
ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.</preformat>
        </sec>
      </sec>
      <sec id="nb-code-cell-2-nb-article" specific-use="notebook-code">
        <code language="r script">Mean_RTs &lt;- read_csv("Mean_Reaction_Times_Familiar_Faces_Filtered.csv")</code>
        <code language="r script">Mean_RTs_long &lt;- melt(Mean_RTs, 
                         # ID variables - all the variables to keep but not split apart on
                         id.vars=c("Participant", "Age"),
                         # The source columns
                         measure.vars=c("Unfamiliar_Upright", "Unfamiliar_Inverted", 
                                        "Familiar_Upright", "Familiar_Inverted", 
                                        "Self_Upright", "Self_Inverted"),
                         # Name of the destination column that will identify the original
                         # column that the measurement came from
                         variable.name="Condition",
                         value.name="Mean_RT_secs"               
                         
                         )

Mean_RTs_long &lt;- Mean_RTs_long %&gt;%
  mutate(Orientation = case_when(Condition == 'Unfamiliar_Upright' ~ 'Upright',
                                    Condition == 'Familiar_Upright' ~ 'Upright',
                                    Condition == 'Self_Upright' ~ 'Upright',
                                    TRUE ~ 'Inverted'))

Mean_RTs_long &lt;- Mean_RTs_long %&gt;%
  mutate(Familiarity = case_when(Condition == 'Unfamiliar_Upright' ~ 'Unfamiliar',
                                 Condition == 'Unfamiliar_Inverted' ~ 'Unfamiliar',
                                 Condition == 'Familiar_Upright' ~ 'Familiar',
                                 Condition == 'Familiar_Inverted' ~ 'Familiar',
                                 TRUE ~ 'Self'))

Mean_RTs_long$Mean_RT_ms &lt;- Mean_RTs_long$Mean_RT_secs*(1000)

MeanRTs_UF_Upright &lt;- filter(Mean_RTs_long, Condition == 'Unfamiliar_Upright')
MeanRTs_UF_Inverted &lt;- filter(Mean_RTs_long, Condition == 'Unfamiliar_Inverted')
MeanRTs_F_Upright&lt;- filter(Mean_RTs_long, Condition == 'Familiar_Upright')
MeanRTs_F_Inverted &lt;- filter(Mean_RTs_long, Condition == 'Familiar_Inverted')
MeanRTs_S_Upright&lt;- filter(Mean_RTs_long, Condition == 'Self_Upright')
MeanRTs_S_Inverted &lt;- filter(Mean_RTs_long, Condition == 'Self_Inverted')

df_2x3_RTs_All &lt;- data_2x2(
  array_1 = MeanRTs_UF_Upright$Mean_RT_ms,
  array_2 = MeanRTs_UF_Inverted$Mean_RT_ms,
  array_3 = MeanRTs_F_Upright$Mean_RT_ms,
  array_4 = MeanRTs_F_Inverted$Mean_RT_ms,
  array_5 = MeanRTs_S_Upright$Mean_RT_ms,
  array_6 = MeanRTs_S_Inverted$Mean_RT_ms,
  labels = (c('Upright','Inverted')),
  jit_distance = .09,
  jit_seed = 321,
  # spread_x_ticks = FALSE
) 

# Change column name to be more meaningful
colnames(df_2x3_RTs_All)[colnames(df_2x3_RTs_All) == "group"] &lt;- "Orientation"

## Raincloud plot for recognition time 
faces_2x3_RTs &lt;- raincloud_2x3_repmes(
  data = df_2x3_RTs_All,
  colors = c(upright_col, inverted_col, upright_col, inverted_col, upright_col, inverted_col),
  fills = c(upright_col, inverted_col, upright_col, inverted_col, upright_col, inverted_col),
  alpha = .5) +
  scale_x_continuous(breaks=c(1,2,3), labels=c("Unfamiliar", "Familiar", "Self"), limits=c(0.5, 4)) +
  xlab("Face Familiarity") + 
  ylab("Mean reaction time (milliseconds)") +
  #labs(title = "Mean reaction times for face recognition") +
  theme_classic()+
    # Add lines for individual subjects 
  geom_path(aes(x = jit, y = y_axis, group = interaction(Orientation, id), color = Orientation), alpha = .5) +
  scale_color_manual(values = c(inverted_col, upright_col))</code>
        <sec id="nb-code-cell-2-output-0-nb-article" specific-use="notebook-output">
          <preformat>Rows: 28 Columns: 8
── Column specification ────────────────────────────────────────────────────────
Delimiter: ","
chr (1): Participant
dbl (7): Unfamiliar_Upright, Unfamiliar_Inverted, Familiar_Upright, Familiar...

ℹ Use `spec()` to retrieve the full column specification for this data.
ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.</preformat>
        </sec>
      </sec>
      <sec id="nb-code-cell-3-nb-article" specific-use="notebook-code">
        <code language="r script"># Do ANOVA analysis of ratings 
RecognitionTimes_ANOVA &lt;- aov_ez("Participant", "Mean_time", Mean_Frames_long, within=c("Orientation", "Familiarity"),
                            factorize = TRUE) # Do ANOVA

EM_Means_RecognitionTimes &lt;- emmeans (RecognitionTimes_ANOVA, ~ Orientation|Familiarity) # Get EM Means</code>
      </sec>
      <sec id="introduction-nb-article">
        <title>Introduction</title>
        <p>Face recognition is the foundation of our social behaviour; it
  helps us identify the people around us and make inferences about their
  mood and focus of attention
  (<xref alt="Burton et al., 2015" rid="ref-burton2015a-nb-article" ref-type="bibr">Burton
  et al., 2015</xref>;
  <xref alt="Mohr et al., 2018" rid="ref-mohr2018a-nb-article" ref-type="bibr">Mohr
  et al., 2018</xref>). It has been estimated that we spend
  20<inline-formula><alternatives><tex-math><![CDATA[\%]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline"><mml:mi>%</mml:mi></mml:math></alternatives></inline-formula>
  of our day looking at faces, and can recognise over 4000 faces during
  our lifetime
  (<xref alt="Jenkins et al., 2018" rid="ref-jenkins2018a-nb-article" ref-type="bibr">Jenkins
  et al., 2018</xref>;
  <xref alt="Oruc et al., 2019" rid="ref-oruc2019a-nb-article" ref-type="bibr">Oruc
  et al., 2019</xref>). For most of us, the ability to recognise and
  recall identity-specific information appears to occur almost
  effortlessly, with studies demonstrating that we can recognise a
  familiar face as quickly as 360 ms
  (<xref alt="Besson et al., 2016" rid="ref-besson2016a-nb-article" ref-type="bibr">Besson
  et al., 2016</xref>;
  <xref alt="Blauch et al., 2021" rid="ref-blauch2021a-nb-article" ref-type="bibr">Blauch
  et al., 2021</xref>;
  <xref alt="Oruc et al., 2019" rid="ref-oruc2019a-nb-article" ref-type="bibr">Oruc
  et al., 2019</xref>;
  <xref alt="Ramon &amp; Belle, 2016" rid="ref-ramon2016a-nb-article" ref-type="bibr">Ramon
  &amp; Belle, 2016</xref>). The efficiency with which humans can
  discriminate within a relatively homogeneous visual category, under
  constantly changing viewing conditions, has earned us the reputation
  for being face experts
  (<xref alt="Collins et al., 2018" rid="ref-collins2018a-nb-article" ref-type="bibr">Collins
  et al., 2018</xref>;
  <xref alt="Dobs et al., 2019" rid="ref-dobs2019a-nb-article" ref-type="bibr">Dobs
  et al., 2019</xref>;
  <xref alt="Kramer et al., 2017" rid="ref-kramer2017a-nb-article" ref-type="bibr">Kramer
  et al., 2017</xref>;
  <xref alt="Quek et al., 2021" rid="ref-quek2021a-nb-article" ref-type="bibr">Quek
  et al., 2021</xref>;
  <xref alt="Rossion &amp; Taubert, 2019" rid="ref-rossion_what_2019-nb-article" ref-type="bibr">Rossion
  &amp; Taubert, 2019</xref>;
  <xref alt="Towler et al., 2019" rid="ref-towler_are_2019-nb-article" ref-type="bibr">Towler
  et al., 2019</xref>).</p>
        <p>The precise nature of our face expertise remains poorly understood,
  with debate around whether the processes that govern face recognition
  are the same for all faces or whether there are distinct perceptual
  processes for familiar faces
  (<xref alt="Abudarham et al., 2019" rid="ref-abudarham2019a-nb-article" ref-type="bibr">Abudarham
  et al., 2019</xref>;
  <xref alt="Blauch et al., 2021" rid="ref-blauch2021a-nb-article" ref-type="bibr">Blauch
  et al., 2021</xref>;
  <xref alt="Collins et al., 2018" rid="ref-collins2018a-nb-article" ref-type="bibr">Collins
  et al., 2018</xref>). Central to the discussion is the idea that there
  may be a familiarity continuum in face recognition, whereby the brain
  will respond differently depending on the level of familiarity one has
  with the face. For example, our friends’ faces are not as familiar to
  us as our own face, and this difference could change the way the brain
  encodes and processes a face at the sensory and cognitive level
  (<xref alt="Bortolon. &amp; Raffard, 2018" rid="ref-bortolon2018a-nb-article" ref-type="bibr">Bortolon.
  &amp; Raffard, 2018</xref>;
  <xref alt="Rooney et al., 2012" rid="ref-rooney2012a-nb-article" ref-type="bibr">Rooney
  et al., 2012</xref>;
  <xref alt="Tong &amp; Nakayama, 1999" rid="ref-tong1999a-nb-article" ref-type="bibr">Tong
  &amp; Nakayama, 1999</xref>). Understanding these differences may
  extend beyond the benefit to basic visual cognition. For example, it
  is possible that the processes responsible for recognising our own
  face index other higher-level constructs such as self-esteem and
  self-identity, which are thought to underlie serious pathologies such
  as depression, schizophrenia, and bipolar disorder
  (<xref alt="Felisberti &amp; Musholt, 2014" rid="ref-felisberti2014a-nb-article" ref-type="bibr">Felisberti
  &amp; Musholt, 2014</xref>;
  <xref alt="Oliveira et al., 2015" rid="ref-oliveira2015a-nb-article" ref-type="bibr">Oliveira
  et al., 2015</xref>).</p>
        <p>There is abundant evidence that greater levels of familiarity with
  a person facilitate processing efficiency, as it has been shown that
  the faces of personally familiar people are processed faster and more
  accurately than the faces of familiar celebrities, and both have an
  advantage over strangers faces
  (<xref alt="Bortolon et al., 2017" rid="ref-bortolon2017a-nb-article" ref-type="bibr">Bortolon
  et al., 2017</xref>;
  <xref alt="Burton et al., 2015" rid="ref-burton2015a-nb-article" ref-type="bibr">Burton
  et al., 2015</xref>;
  <xref alt="Tong &amp; Nakayama, 1999" rid="ref-tong1999a-nb-article" ref-type="bibr">Tong
  &amp; Nakayama, 1999</xref>;
  <xref alt="Young &amp; Burton, 2017" rid="ref-young2017a-nb-article" ref-type="bibr">Young
  &amp; Burton, 2017</xref>). Further, changes in viewing conditions
  have been shown to impede unfamiliar face matching performance whereas
  recognition of familiar faces is extremely robust to within-identity
  image variability and low-quality images
  (<xref alt="Burton, 2013" rid="ref-burton2013a-nb-article" ref-type="bibr">Burton,
  2013</xref>;
  <xref alt="Jenkins et al., 2011" rid="ref-jenkins2011a-nb-article" ref-type="bibr">Jenkins
  et al., 2011</xref>;
  <xref alt="Liccione et al., 2014" rid="ref-liccione2014a-nb-article" ref-type="bibr">Liccione
  et al., 2014</xref>). For example, Burton et al.
  (<xref alt="1999" rid="ref-burton1999a-nb-article" ref-type="bibr">1999</xref>)
  found performance differences in their study which involved showing
  low resolution CCTV images to familiar and unfamiliar viewers.
  Unfamiliar viewers were able to accurately identify faces
  50<inline-formula><alternatives><tex-math><![CDATA[\%]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline"><mml:mi>%</mml:mi></mml:math></alternatives></inline-formula>
  of the time, whereas familiar viewers could identify faces almost
  perfectly, suggesting that the processing of unfamiliar faces may be
  qualitatively different from familiar faces
  (<xref alt="Burton et al., 1999" rid="ref-burton1999a-nb-article" ref-type="bibr">Burton
  et al., 1999</xref>). The familiar face advantage has been observed
  across a range of image manipulations including face inversion (i.e.,
  turning faces upside down) and geometric distortion (e.g., compressing
  images of faces) manipulations, highlighting familiarity as an
  important factor in face recognition
  (<xref alt="Allen-Davidian et al., 2021" rid="ref-allen-davidian2021a-nb-article" ref-type="bibr">Allen-Davidian
  et al., 2021</xref>;
  <xref alt="Hole et al., 2002" rid="ref-hole_effects_2002-nb-article" ref-type="bibr">Hole
  et al., 2002</xref>;
  <xref alt="Kramer et al., 2018" rid="ref-kramer2018a-nb-article" ref-type="bibr">Kramer
  et al., 2018</xref>;
  <xref alt="Rossion, 2008" rid="ref-rossion_picture-plane_2008-nb-article" ref-type="bibr">Rossion,
  2008</xref>;
  <xref alt="Yang et al., 2014" rid="ref-yang2014a-nb-article" ref-type="bibr">Yang
  et al., 2014</xref>).</p>
        <p>However, familiarity is a challenging dimension to explore because
  its definition is multiplexed, and it is difficult to control in an
  experimental context. First, there are different levels of
  familiarity, ranging from recently recently seen and recently learned
  faces to faces that are familiar but for which we have no personal
  knowledge (famous people, acquaintances), to the faces of those we
  know well (family, close friends, self-face; Ramon et al.
  (<xref alt="2011" rid="ref-ramon2011a-nb-article" ref-type="bibr">2011</xref>)).
  Levels of familiarity influence the depth of knowledge and experience
  we associate with an individual, which likely impacts the underlying
  mental representation we store in memory
  (<xref alt="Ramon &amp; Gobbini, 2017" rid="ref-ramon2017a-nb-article" ref-type="bibr">Ramon
  &amp; Gobbini, 2017</xref>). Second, each individual knows a unique
  collection of faces, which limits the type of stimuli that can be used
  in research, adding inherent variability in familiarity levels between
  participants
  (<xref alt="Ramon &amp; Gobbini, 2017" rid="ref-ramon2017a-nb-article" ref-type="bibr">Ramon
  &amp; Gobbini, 2017</xref>). Third, the way in which faces become
  familiar can differ. For example, some faces become familiar through
  interaction with others in our daily lives, and other faces become
  familiar through repeated exposure (i.e., famous faces or
  experimentally learned faces). In other words, coming to ‘know’ a
  person could be different to image-based familiarity
  (<xref alt="Kramer et al., 2018" rid="ref-kramer2018a-nb-article" ref-type="bibr">Kramer
  et al., 2018</xref>). Finally, to reduce noise in data, researchers
  often manipulate face images (e.g., cropped, hairless, expressionless)
  which is different to how a face appears under normal circumstances
  (<xref alt="Burton et al., 2011" rid="ref-burton2011a-nb-article" ref-type="bibr">Burton
  et al., 2011</xref>;
  <xref alt="Long et al., 2023" rid="ref-long_database_2023-nb-article" ref-type="bibr">Long
  et al., 2023</xref>). These methodological constraints and unique
  challenges have contributed to the inconsistencies in face research,
  particularly regarding familiar face recognition performance.</p>
        <sec id="measuring-face-recognition-nb-article">
          <title>Measuring Face Recognition</title>
          <p>While in the real world only familiar faces are recognised, in
    face research, “face recognition” also describes an individual’s
    ability to detect a previously unknown face with which they are
    familiarised during an experimental procedure
    (<xref alt="Burton, 2013" rid="ref-burton2013a-nb-article" ref-type="bibr">Burton,
    2013</xref>;
    <xref alt="Hancock et al., 2000" rid="ref-hancock2000a-nb-article" ref-type="bibr">Hancock
    et al., 2000</xref>;
    <xref alt="White &amp; Burton, 2022" rid="ref-white_individual_2022-nb-article" ref-type="bibr">White
    &amp; Burton, 2022</xref>). Consistent with the literature, we will
    conceptualise face recognition as the ability to recognise
    previously known or recently learned faces (familiar) and previously
    unknown faces (unfamiliar).</p>
          <p>Face recognition has been investigated by recording how long it
    takes participants to accurately find targets. These tasks often
    involve participants seeking a target face, where detection is
    indicated using a go/no-go categorisation
    (<xref alt="Kloth et al., 2006" rid="ref-kloth2006a-nb-article" ref-type="bibr">Kloth
    et al., 2006</xref>;
    <xref alt="Ramon et al., 2011" rid="ref-ramon2011a-nb-article" ref-type="bibr">Ramon
    et al., 2011</xref>;
    <xref alt="Tong &amp; Nakayama, 1999" rid="ref-tong1999a-nb-article" ref-type="bibr">Tong
    &amp; Nakayama, 1999</xref>). Reaction time data has mostly shown
    that participants are faster to recognise familiar faces than
    unfamiliar faces, but reported reaction times vary
    (<xref alt="Burton et al., 2015" rid="ref-burton2015a-nb-article" ref-type="bibr">Burton
    et al., 2015</xref>;
    <xref alt="Ramon et al., 2011" rid="ref-ramon2011a-nb-article" ref-type="bibr">Ramon
    et al., 2011</xref>;
    <xref alt="Ramon &amp; Gobbini, 2017" rid="ref-ramon2017a-nb-article" ref-type="bibr">Ramon
    &amp; Gobbini, 2017</xref>). For example, Ramon et al.
    (<xref alt="2011" rid="ref-ramon2011a-nb-article" ref-type="bibr">2011</xref>)
    asked participants to accurately categorise 52 images of classmates
    and strangers using a go/no-go finger lift response and found
    observers could categorise their classmates within 360 ms, compared
    to 460 ms to categorise a face as unfamiliar. By contrast, Alzueta
    et al.
    (<xref alt="2019" rid="ref-alzueta2019a-nb-article" ref-type="bibr">2019</xref>)
    asked participants to classify 450 images of their own face,
    friends, and strangers as quickly as possible using a keyboard
    button press. Results showed faster reaction times for the self-face
    (542 ms), but slower reaction times for friends’ faces (570 ms)
    compared with strangers (562 ms), providing conflicting evidence for
    the familiar face advantage. Together, findings highlight a common
    challenge in face recognition research regarding variability in
    reaction time data as a result of different task demands.</p>
          <p>A drawback of relying on average reaction times as a dependent
    variable is that the data represents the elapsed time from stimulus
    onset to motor output, combining perceptual processing time,
    cognitive decision time, and motor response, thus inflating the
    actual time required to recognise a face
    (<xref alt="Alzueta et al., 2019" rid="ref-alzueta2019a-nb-article" ref-type="bibr">Alzueta
    et al., 2019</xref>;
    <xref alt="Burton et al., 2015" rid="ref-burton2015a-nb-article" ref-type="bibr">Burton
    et al., 2015</xref>;
    <xref alt="Caharel et al., 2014" rid="ref-caharel2014a-nb-article" ref-type="bibr">Caharel
    et al., 2014</xref>). Taubert et al.
    (<xref alt="2011" rid="ref-taubert2011a-nb-article" ref-type="bibr">2011</xref>)
    overcame this issue in their study by using a staircase procedure to
    determine minimum exposure time. Their research revealed that
    participants could accurately discriminate between individual target
    faces when given 50 ms to view a stimulus
    (<xref alt="Taubert et al., 2011" rid="ref-taubert2011a-nb-article" ref-type="bibr">Taubert
    et al., 2011</xref>). Others have used electroencephalography (EEG)
    frequency tagging to compare neural responses to face images that
    progressively increased in image duration, to identify the threshold
    for successful face recognition
    (<xref alt="Dobs et al., 2019" rid="ref-dobs2019a-nb-article" ref-type="bibr">Dobs
    et al., 2019</xref>;
    <xref alt="Quek et al., 2021" rid="ref-quek2021a-nb-article" ref-type="bibr">Quek
    et al., 2021</xref>). Results showed that exposures as brief as 83
    ms enabled observers to consistently recognise familiar (famous)
    faces from unfamiliar faces
    (<xref alt="Quek et al., 2021" rid="ref-quek2021a-nb-article" ref-type="bibr">Quek
    et al., 2021</xref>). Findings of both studies revealed that
    processing time was much shorter than the reaction times reported in
    other face recognition studies
    (<xref alt="Besson et al., 2016" rid="ref-besson2016a-nb-article" ref-type="bibr">Besson
    et al., 2016</xref>;
    <xref alt="Blauch et al., 2021" rid="ref-blauch2021a-nb-article" ref-type="bibr">Blauch
    et al., 2021</xref>;
    <xref alt="Oruc et al., 2019" rid="ref-oruc2019a-nb-article" ref-type="bibr">Oruc
    et al., 2019</xref>).Here, we employed the same method as Taubert et
    al.
    (<xref alt="2011" rid="ref-taubert2011a-nb-article" ref-type="bibr">2011</xref>)
    to determine whether different perceptual processes underscore the
    recognition of familiar and unfamiliar faces.</p>
        </sec>
        <sec id="effects-of-different-levels-of-familiarity-on-face-recognition-performance-nb-article">
          <title>Effects of Different Levels of Familiarity on Face
    Recognition Performance</title>
          <p>The idea that familiar faces may be more easily detected or
    recognised than unfamiliar faces makes intuitive sense, given the
    social importance of correctly identifying familiar faces, and the
    need for humans to efficiently process the enormous amount of visual
    information we are exposed to in our environment
    (<xref alt="Tong &amp; Nakayama, 1999" rid="ref-tong1999a-nb-article" ref-type="bibr">Tong
    &amp; Nakayama, 1999</xref>). The pursuit of identifying the neural
    mechanisms underlying the recognition of familiar faces has led to
    important discoveries regarding distinct processing capacities
    (<xref alt="Bortolon et al., 2017" rid="ref-bortolon2017a-nb-article" ref-type="bibr">Bortolon
    et al., 2017</xref>;
    <xref alt="Ramon &amp; Gobbini, 2017" rid="ref-ramon2017a-nb-article" ref-type="bibr">Ramon
    &amp; Gobbini, 2017</xref>). There is growing evidence in support of
    a familiarity continuum in face recognition highlighting processing
    distinctions not only between unfamiliar and familiar faces, but
    within the familiar face category itself
    (<xref alt="Megreya &amp; Burton, 2006" rid="ref-megraya2006a-nb-article" ref-type="bibr">Megreya
    &amp; Burton, 2006</xref>;
    <xref alt="Murphy et al., 2015" rid="ref-murphy2015a-nb-article" ref-type="bibr">Murphy
    et al., 2015</xref>;
    <xref alt="Quek et al., 2021" rid="ref-quek2021a-nb-article" ref-type="bibr">Quek
    et al., 2021</xref>;
    <xref alt="Wiese et al., 2021" rid="ref-wiese2021a-nb-article" ref-type="bibr">Wiese
    et al., 2021</xref>).</p>
          <sec id="recently-learned-faces-nb-article">
            <title>Recently Learned Faces</title>
            <p>Evidence from behavioural studies has indicated that humans
      only need brief exposure for face learning to occur, as recently
      learned faces are more easily matched than unfamiliar faces in
      face matching tasks
      (<xref alt="Dowsett et al., 2016" rid="ref-dowsett2016a-nb-article" ref-type="bibr">Dowsett
      et al., 2016</xref>;
      <xref alt="Kramer et al., 2017" rid="ref-kramer2017a-nb-article" ref-type="bibr">Kramer
      et al., 2017</xref>;
      <xref alt="Murphy et al., 2015" rid="ref-murphy2015a-nb-article" ref-type="bibr">Murphy
      et al., 2015</xref>;
      <xref alt="Quek et al., 2021" rid="ref-quek2021a-nb-article" ref-type="bibr">Quek
      et al., 2021</xref>). However, unlike recognition of familiar
      faces, which is robust to changes in viewing conditions such as
      lighting, viewpoint, and expression, face matching of recently
      familiar faces is hindered by even slight alterations in the
      appearance of the face
      (<xref alt="Burton et al., 2011" rid="ref-burton2011a-nb-article" ref-type="bibr">Burton
      et al., 2011</xref>;
      <xref alt="Megreya &amp; Burton, 2008" rid="ref-megraya2008a-nb-article" ref-type="bibr">Megreya
      &amp; Burton, 2008</xref>;
      <xref alt="Redfern &amp; Benton, 2019" rid="ref-redfern2019a-nb-article" ref-type="bibr">Redfern
      &amp; Benton, 2019</xref>;
      <xref alt="White et al., 2016" rid="ref-white2016a-nb-article" ref-type="bibr">White
      et al., 2016</xref>). In addition to perceptual information (e.g.,
      facial features) acquired during face learning, research shows
      sparse conceptual information (e.g., name and occupation) can aid
      recognition
      (<xref alt="Oruc et al., 2019" rid="ref-oruc2019a-nb-article" ref-type="bibr">Oruc
      et al., 2019</xref>;
      <xref alt="Schwartz &amp; Yovel, 2019" rid="ref-schwartz2019a-nb-article" ref-type="bibr">Schwartz
      &amp; Yovel, 2019</xref>). Schwartz &amp; Yovel
      (<xref alt="2016" rid="ref-schwartz2016a-nb-article" ref-type="bibr">2016</xref>)
      compared the contribution of perceptual and conceptual information
      to face recognition performance in their study exposing
      participants to either perceptual information (manipulating
      lighting and facial angles) or conceptual information (name,
      occupation) about target identities. When participants were
      provided with new images of the same identities and tested on
      their recognition ability, results showed better recognition
      following conceptual information compared with perceptual
      information.</p>
          </sec>
          <sec id="personally-familiar-faces-nb-article">
            <title>Personally Familiar Faces</title>
            <p>Personal information acquired through repeated interaction with
      an identity appears to enhance familiar face recognition, as
      research shows that our face representations for personally
      familiar faces differ from those of recently learned faces and
      familiar celebrity faces
      (<xref alt="Cloutier et al., 2011" rid="ref-cloutier2011a-nb-article" ref-type="bibr">Cloutier
      et al., 2011</xref>;
      <xref alt="Ramon &amp; Gobbini, 2017" rid="ref-ramon2017a-nb-article" ref-type="bibr">Ramon
      &amp; Gobbini, 2017</xref>;
      <xref alt="Rooney et al., 2012" rid="ref-rooney2012a-nb-article" ref-type="bibr">Rooney
      et al., 2012</xref>). Karimi-Rouzbahani et al.
      (<xref alt="2021" rid="ref-karimi-rouzbahani2021a-nb-article" ref-type="bibr">2021</xref>)
      varied familiarity across stimuli (i.e., unfamiliar, famous,
      personally familiar, and self) and instructed 18 participants to
      categorise the stimulus as familiar or unfamiliar using a button
      press. EEG data, measuring brain electrical activity, showed that
      higher levels of familiarity (self-face and personally familiar)
      generated greater transfer of information flow over the visual
      areas of the brain compared to unfamiliar and famous identities.
      In contrast, Wiese et al.
      (<xref alt="2021" rid="ref-wiese2021a-nb-article" ref-type="bibr">2021</xref>)
      found substantial EEG event-related potential familiarity effects
      in response to the self-face, personally familiar faces, and
      favourite celebrities compared with other celebrities,
      demonstrating similar processing of personally familiar faces and
      favourite celebrities.</p>
          </sec>
        </sec>
        <sec id="face-processing-efficiency-and-the-inversion-effect-nb-article">
          <title>Face Processing Efficiency and the Inversion Effect</title>
          <p>The literature provides two interpretations of face processing
    efficiency. The holistic processing perspective emphasises the
    importance of analysing the spatial relations between features,
    providing a unique configuration for each individual so that faces
    are processed whole, rather than in parts
    (<xref alt="Maurer et al., 2002" rid="ref-maurer_many_2002-nb-article" ref-type="bibr">Maurer
    et al., 2002</xref>;
    <xref alt="Sandford &amp; Burton, 2014" rid="ref-sandford2014a-nb-article" ref-type="bibr">Sandford
    &amp; Burton, 2014</xref>). Evidence for holistic processing has
    been demonstrated predominantly in studies showing that when a face
    is inverted, disrupting its global configuration, participants find
    it harder to identify target faces
    (<xref alt="Taubert et al., 2011" rid="ref-taubert2011a-nb-article" ref-type="bibr">Taubert
    et al., 2011</xref>;
    <xref alt="Tong &amp; Nakayama, 1999" rid="ref-tong1999a-nb-article" ref-type="bibr">Tong
    &amp; Nakayama, 1999</xref>). The face inversion effect has been
    reliably used in the literature to explore face processing
    efficiency
    (<xref alt="Rossion, 2008" rid="ref-rossion_picture-plane_2008-nb-article" ref-type="bibr">Rossion,
    2008</xref>;
    <xref alt="Taubert et al., 2015" rid="ref-taubert_effect_2015-nb-article" ref-type="bibr">Taubert
    et al., 2015</xref>;
    <xref alt="Valentine, 1988" rid="ref-valentine_upside-down_1988-nb-article" ref-type="bibr">Valentine,
    1988</xref>). Interestingly, studies have revealed that the effects
    of inversion are greater for unfamiliar faces than familiar faces,
    suggesting that familiar faces are not a slave to holistic
    processing
    (<xref alt="Oleggio Castello et al., 2017" rid="ref-oleggio2017a-nb-article" ref-type="bibr">Oleggio
    Castello et al., 2017</xref>;
    <xref alt="Ramon &amp; Belle, 2016" rid="ref-ramon2016a-nb-article" ref-type="bibr">Ramon
    &amp; Belle, 2016</xref>;
    <xref alt="Waidmann et al., 2022" rid="ref-waidmann_local_2022-nb-article" ref-type="bibr">Waidmann
    et al., 2022</xref>).</p>
          <p>By contrast, the feature-based processing perspective suggests
    that processing efficiency, as observed with familiar faces, can be
    attributed to the learning of face features, such as eyes, nose, and
    mouth, which are then used as unique identifiers supporting
    processing efficiency
    (<xref alt="Abudarham &amp; Yovel, 2016" rid="ref-abudarham2016a-nb-article" ref-type="bibr">Abudarham
    &amp; Yovel, 2016</xref>). Lee et al.
    (<xref alt="2022" rid="ref-lee2022a-nb-article" ref-type="bibr">2022</xref>)
    explored holistic and featural processing effects in a study where
    participants viewed images of unfamiliar faces, friends’ faces, and
    the self-face in an inversion task, and a part-whole (isolated
    features) task. They found no significant difference in inversion
    effects across the unfamiliar, friend and self-face conditions,
    whereas, in the isolated features task, participants were faster and
    more accurate at recognising the self-face compared to friend and
    unfamiliar faces, suggesting the self-face may be processed in a
    more feature-based manner. Therefore, the commonly held belief that
    face recognition relies on holistic processing is being challenged,
    and it seems likely that not all faces are processed in the same
    way.</p>
          <sec id="the-self-face-nb-article">
            <title>The Self-face</title>
            <p>Our own face is unique, as it plays an influential role in our
      self-consciousness and identity, and is an important tool for
      social engagement
      (<xref alt="Bortolon. &amp; Raffard, 2018" rid="ref-bortolon2018a-nb-article" ref-type="bibr">Bortolon.
      &amp; Raffard, 2018</xref>). The ‘self-face advantage’ in face
      recognition has been consistently observed across different
      contexts and task demands, however, there is conflicting evidence
      for distinct processing between the self-face and other familiar
      faces
      (<xref alt="Alzueta et al., 2019" rid="ref-alzueta2019a-nb-article" ref-type="bibr">Alzueta
      et al., 2019</xref>;
      <xref alt="Tong &amp; Nakayama, 1999" rid="ref-tong1999a-nb-article" ref-type="bibr">Tong
      &amp; Nakayama, 1999</xref>;
      <xref alt="Wiese et al., 2019" rid="ref-wiese2019a-nb-article" ref-type="bibr">Wiese
      et al., 2019</xref>). For example, Alzueta et al.
      (<xref alt="2019" rid="ref-alzueta2019a-nb-article" ref-type="bibr">2019</xref>)
      used EEG to investigate whether the self-face elicits distinct
      neural processes compared to friends’ and stranger faces. The N170
      component, a negative-going EEG potential typically associated
      with face perception, did not exhibit sensitivity to the
      self-face, contradicting previous research
      (<xref alt="Caharel &amp; Rossion, 2021" rid="ref-caharel2021a-nb-article" ref-type="bibr">Caharel
      &amp; Rossion, 2021</xref>;
      <xref alt="Wiese et al., 2019" rid="ref-wiese2019a-nb-article" ref-type="bibr">Wiese
      et al., 2019</xref>). Findings supported an earlier behavioural
      study, where 40 participants were asked to attend with a friend
      and bring five photographs of their own face unseen by their
      friend. Participants viewed images of themselves, friends, famous,
      and unfamiliar faces and completed a face matching task
      (<xref alt="Bortolon et al., 2017" rid="ref-bortolon2017a-nb-article" ref-type="bibr">Bortolon
      et al., 2017</xref>). Results showed participants were better at
      matching photographs of their own face than famous and unknown
      faces, but were not faster or more accurate at matching their own
      face than their friend’s face.</p>
            <p>Our understanding of the effects of familiarity on face
      recognition can be improved by experimenting with personally
      familiar faces, compared to famous faces, which would better
      represent familiarity effects as a result of real-world face
      learning. The self-face is arguably the most familiar face to each
      of us, and, thus, is an important inclusion in studies seeking to
      understand the effects of levels of familiarity on facial
      processing. In addition, exploration of an alternative research
      method designed to isolate recognition time (i.e., perceptual
      processes) from reaction time (i.e., perceptual processes +
      cognitive decision + motor response) is warranted to provide a
      more precise measure of the perceptual processing time for faces.
      This information would add value to the debate around whether the
      brain processes faces differently based on the level of
      familiarity.</p>
          </sec>
        </sec>
        <sec id="aims-and-hypotheses-nb-article">
          <title>Aims and Hypotheses</title>
          <p>The purpose of the present study was to investigate the effect of
    higher levels of face familiarity on face recognition by
    manipulating both familiarity and orientation while measuring the
    minimal display time required for recognition (i.e., recognition
    time) and how quickly participants responded (i.e., reaction time).
    A staircase procedure was used as an alternative method for
    characterising face recognition performance. Familiar and unfamiliar
    faces were presented in both upright and inverted orientations, with
    the overall expectation that participants would need less time to
    recognise their own face compared to familiar and unfamiliar faces,
    and less time to recognise familiar faces compared to unfamiliar
    faces. Our specific hypotheses were as follows:</p>
          <list list-type="order">
            <list-item>
              <p>Participants will be able to recognise their own faces at
        shorter face display times compared with less familiar and
        unfamiliar faces;</p>
            </list-item>
            <list-item>
              <p>Participants will require shorter face display times to
        recognise a familiar face (that of the experimenter) compared to
        an unfamiliar face;</p>
            </list-item>
            <list-item>
              <p>Participants will require longer display times to recognise
        all faces when the face display is inverted;</p>
            </list-item>
            <list-item>
              <p>The face inversion effect (the difference between performance
        in upright and inverted trials) will be reduced for more
        familiar faces.</p>
            </list-item>
          </list>
        </sec>
      </sec>
      <sec id="method-nb-article">
        <title>Method</title>
        <sec id="participants-nb-article">
          <title>Participants</title>
          <p>A power analysis using G*Power 3.1.9.6
    (<xref alt="Faul et al., 2009" rid="ref-faul2009a-nb-article" ref-type="bibr">Faul
    et al., 2009</xref>) determined that a repeated-measures analysis of
    variance (ANOVA) required 30 participants to reach a power of .90,
    with an alpha of .05 and an effect size of .15. This effect size was
    chosen based on previous studies
    (<xref alt="Campbell &amp; Tanaka, 2021" rid="ref-campbell2021a-nb-article" ref-type="bibr">Campbell
    &amp; Tanaka, 2021</xref>;
    <xref alt="Zimmermann et al., 2019" rid="ref-zimmermann2019a-nb-article" ref-type="bibr">Zimmermann
    et al., 2019</xref>). This study was approved by the Human Research
    Ethics Committee (Approval No. HE23-030) at the University of New
    England (UNE). Written informed consent was obtained from all
    participants. While 30 participants completed the study, the data
    for two participants was excluded from the analysis based on the
    pre-registered exclusion criteria stating that participants will be
    excluded if their recognition times for the majority of their trials
    were slower than the starting point face display time (18
    frames/66.67ms) for the majority of their trials. The final sample
    consisted of 28 females aged between 18 and 65 years (M = 43.1, SD =
    12.7), recruited through word of mouth and via flyers distributed on
    campus at the University. Participants signed up using the quick
    response (QR) code on the flyer, which generated an email to the
    experimenter. Only female participants were recruited to ensure
    stimulus consistency across conditions and eliminate gender as a
    possible biasing factor in face discrimination. The experiment took
    approximately 45 minutes to complete, and participants were
    compensated with an AUD $25 gift card. All participants had normal
    or corrected-to-normal vision and no self-reported diagnosed
    impairment in face perception (e.g., prosopagnosia).</p>
        </sec>
        <sec id="design-and-stimuli-nb-article">
          <title>Design and Stimuli</title>
          <p>Stimuli were presented on a 22.5-inch (diagonal) VIEWPixx display
    toolbox, with a display resolution of 1920 (H) x 1200 (V) pixels.
    Face stimuli were programmed in MATLAB using custom code. Stimuli
    for the unfamiliar condition consisted of 16 female face identities
    selected from the NimStim database (the set of calm, neutral faces;
    Tottenham et al.
    (<xref alt="2009" rid="ref-tottenham2009a-nb-article" ref-type="bibr">2009</xref>)).
    Two photographs of the experimenter were used to create a familiar
    face condition. To create the self-face condition, prior to the
    experiment, participants were asked to send two photographs of
    themselves with a neutral expression, without eyewear and with no
    hair across the face. Several steps were taken to equate image sets
    across all three conditions. First, the faces were aligned at the
    eyes and cropped to an oval to exclude hair and clothing. Second,
    all face identities wore a neutral expression. Third, two images per
    identity were used so that responses would be more likely to
    indicate identity processing rather than image-based processing.
    Fourth, all images were greyscale and root mean square (RMS)
    normalised for contrast.</p>
          <p>The images were presented within a 128-pixel rectangle and viewed
    from a distance of 57 centimetres. Faces were presented upright or
    inverted 180°. To ensure any transients from the onset of stimuli
    were masked, a mask stream was created using a series of 192-pixel
    (6°) square patches of randomly-generated noise filtered with a
    <inline-formula><alternatives><tex-math><![CDATA[1/f]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline"><mml:mrow><mml:mn>1</mml:mn><mml:mi>/</mml:mi><mml:mi>f</mml:mi></mml:mrow></mml:math></alternatives></inline-formula>
    frequency spectrum (see
    <xref alt="Figure 1" rid="fig-procedure-nb-article">Figure 1</xref>). A mask
    stream of 200 ms appeared after each face image in all trials. Face
    stimuli were randomly offset from trial to trial by between 1 and 32
    pixels from their original display location to avoid the effects of
    low-level feature matching. Trials were presented in random order to
    reduce any systematic effects of practice on the results. Trials
    were pilot tested prior to the experiment to determine a starting
    point of the staircases (18 frames/66.67ms) for each trial.</p>
          <fig id="fig-procedure-nb-article">
            <caption>
              <p>Figure 1: The visual stimulation sequence for each
      trial</p>
            </caption>
            <graphic mimetype="image" mime-subtype="png" xlink:href="images/FamiliarFace_Procedure.png"/>
          </fig>
        </sec>
        <sec id="threshold-analysis-nb-article">
          <title>Threshold Analysis</title>
          <p>In this study we used a staircase procedure to measure face
    recognition speed. The staircase began with an easily detected
    visual display of a target face and distractor face (see
    <xref alt="Figure 1" rid="fig-procedure-nb-article">Figure 1</xref>), with the
    participant’s task being to indicate whether the target face was in
    the upper or lower part of the display. Subsequent face stimuli
    display times were reduced until the participant made an error, at
    which point the staircase reversed so that face stimuli were
    displayed for longer periods of time until the participant responded
    correctly, triggering another reversal. Image display times were
    measured in units of 8.33 millisecond video frames. The staircase
    used a 1-up-3-down design, where a correct response 3 times in a row
    generated a reduction in display time by 1 frame. If the participant
    made an incorrect response, stimulus display times increased by 1
    frame. Each condition (unfamiliar, familiar, self-face) included
    four trials (two with upright faces and two with inverted faces) and
    each trial included two randomly interleaved staircases. The means
    of the thresholds for each staircase were averaged to calculate the
    shortest timeframe in which the face stimuli could be accurately
    recognised for each condition.</p>
        </sec>
        <sec id="procedure-nb-article">
          <title>Procedure</title>
          <p>Participants were verbally briefed on the aim of the research and
    provided with an information sheet. An overview of the task was
    described as involving recognition of 12 target faces in a series of
    displays over the course of the experiment. Participants were seated
    opposite a desk with the VIEWPixx display screen and a keyboard to
    complete a practice trial to familiarise themselves with the task
    (see <xref alt="Figure 2" rid="fig-setup-nb-article">Figure 2</xref>). The
    practice trial featured a randomly selected face from the unfamiliar
    face set, which was then excluded from the main experiment. A random
    selection of target and distractor faces were chosen for each
    participant. Before each trial, written instructions appeared on the
    screen advising participants to focus on a fixation cross at the
    centre of the screen and use the up and down arrow keys to indicate
    whether the target face appeared above (up arrow) or below (down
    arrow) the fixation cross. Participants pressed any key to continue
    to initiate the display of a ‘target’ face stimulus for five
    seconds. After the inspection period, participants pressed any key
    to start the trial. Trials began with a mask stream followed by a
    display containing the target face and a distractor face above and
    below the fixation cross. The target face appeared randomly either
    above or below the fixation cross. Faces were displayed in either an
    upright or inverted position.</p>
          <fig id="fig-setup-nb-article">
            <caption>
              <p>Figure 2: Depiction of experimental setup; image
      created by Simone Hale (2023)</p>
            </caption>
            <graphic mimetype="image" mime-subtype="png" xlink:href="images/setup.png"/>
          </fig>
        </sec>
      </sec>
      <sec id="results-nb-article">
        <title>Results</title>
        <sec id="data-preparation-nb-article">
          <title>Data Preparation</title>
          <p>Data analyses were conducted using jamovi (version 2.3.21.0),
    with significance levels set to <inline-formula><alternatives><tex-math><![CDATA[\alpha = .05]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline"><mml:mrow><mml:mi>α</mml:mi><mml:mo>=</mml:mo><mml:mn>.05</mml:mn></mml:mrow></mml:math></alternatives></inline-formula>
    for analysis and <inline-formula><alternatives><tex-math><![CDATA[\alpha = .001]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline"><mml:mrow><mml:mi>α</mml:mi><mml:mo>=</mml:mo><mml:mn>.001</mml:mn></mml:mrow></mml:math></alternatives></inline-formula>
    for assumption testing. Data were examined for missing responses and
    no missingness was found. Two participants were excluded because
    their threshold scores were consistently above the starting point of
    the staircases (18 frames/ 66.67ms) for most of their trials. Thus,
    28 of the original 30 participants were included in the analyses.
    Recognition time was measured using the number of frames required to
    complete the task as determined by the staircase procedure. Frames
    were then converted to milliseconds based on the monitor refresh
    rate of 120 Hz. Reaction time was measured in milliseconds.</p>
        </sec>
        <sec id="data-analysis-nb-article">
          <title>Data Analysis</title>
          <p>Assumption testing for the two-way repeated-measures analysis of
    variance (ANOVA) indicated no violated assumptions. Visual
    inspection of Q-Q plots showed a normal distribution of face
    recognition times in each condition and no obvious outliers.
    Homogeneity of variance was assumed, as Fmax scores were below 10,
    in both upright, <inline-formula><alternatives><tex-math><![CDATA[F_{max} = 2.110]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline"><mml:mrow><mml:msub><mml:mi>F</mml:mi><mml:mrow><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:mi>x</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>2.110</mml:mn></mml:mrow></mml:math></alternatives></inline-formula>,
    and inverted, <inline-formula><alternatives><tex-math><![CDATA[F_{max} = 1.697]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline"><mml:mrow><mml:msub><mml:mi>F</mml:mi><mml:mrow><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:mi>x</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>1.697</mml:mn></mml:mrow></mml:math></alternatives></inline-formula>,
    orientations. Mauchly’s test indicated that the assumption of
    sphericity was not violated for the main effect of condition,
    <inline-formula><alternatives><tex-math><![CDATA[W(28) = 0.82, p = .081]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline"><mml:mrow><mml:mi>W</mml:mi><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mn>28</mml:mn><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mn>0.82</mml:mn><mml:mo>,</mml:mo><mml:mi>p</mml:mi><mml:mo>=</mml:mo><mml:mn>.081</mml:mn></mml:mrow></mml:math></alternatives></inline-formula>
    and the interaction between condition and face orientation,
    <inline-formula><alternatives><tex-math><![CDATA[W(28) = 0.93, p = .399]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline"><mml:mrow><mml:mi>W</mml:mi><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mn>28</mml:mn><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mn>0.93</mml:mn><mml:mo>,</mml:mo><mml:mi>p</mml:mi><mml:mo>=</mml:mo><mml:mn>.399</mml:mn></mml:mrow></mml:math></alternatives></inline-formula>.</p>
          <p>A 2 x 3 repeated-measures analysis of variance (ANOVA) was used
    to explore the effects of face familiarity on face recognition time.
    The ANOVA showed a main effect of familiarity, with significant
    differences in face recognition times between unfamiliar, familiar
    and self-face conditions <inline-formula><alternatives><tex-math><![CDATA[F(2, 52) = 48.08, p < .001, \eta_p^2 = .649]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline"><mml:mrow><mml:mi>F</mml:mi><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mn>52</mml:mn><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mn>48.08</mml:mn><mml:mo>,</mml:mo><mml:mi>p</mml:mi><mml:mo>&lt;</mml:mo><mml:mn>.001</mml:mn><mml:mo>,</mml:mo><mml:msubsup><mml:mi>η</mml:mi><mml:mi>p</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo>=</mml:mo><mml:mn>.649</mml:mn></mml:mrow></mml:math></alternatives></inline-formula>.
    In support of the first hypothesis, post hoc comparisons with
    Bonferroni corrections showed participants recognised their own
    faces at shorter display times compared with less familiar faces,
    <inline-formula><alternatives><tex-math><![CDATA[t(26) = 3.99, p = .001]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline"><mml:mrow><mml:mi>t</mml:mi><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mn>26</mml:mn><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mn>3.99</mml:mn><mml:mo>,</mml:mo><mml:mi>p</mml:mi><mml:mo>=</mml:mo><mml:mn>.001</mml:mn></mml:mrow></mml:math></alternatives></inline-formula>,
    and unfamiliar faces, <inline-formula><alternatives><tex-math><![CDATA[t(26) = 11.12, p < .001]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline"><mml:mrow><mml:mi>t</mml:mi><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mn>26</mml:mn><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mn>11.12</mml:mn><mml:mo>,</mml:mo><mml:mi>p</mml:mi><mml:mo>&lt;</mml:mo><mml:mn>.001</mml:mn></mml:mrow></mml:math></alternatives></inline-formula>.
    The second hypothesis was also supported, as a post hoc comparison
    showed participants recognised the familiar face (that of the
    experimenter) at shorter display times than unfamiliar faces,
    <inline-formula><alternatives><tex-math><![CDATA[t(26) = 5.11, p < .001]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline"><mml:mrow><mml:mi>t</mml:mi><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mn>26</mml:mn><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mn>5.11</mml:mn><mml:mo>,</mml:mo><mml:mi>p</mml:mi><mml:mo>&lt;</mml:mo><mml:mn>.001</mml:mn></mml:mrow></mml:math></alternatives></inline-formula>.</p>
          <p>Results also supported the third hypothesis that participants
    would require longer display times to recognise all faces when
    displays were inverted. The ANOVA indicated a main effect of
    orientation for face recognition times,
    <inline-formula><alternatives><tex-math><![CDATA[F(1, 26) = 50.22, p <.001, \eta_p^2 = .659]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline"><mml:mrow><mml:mi>F</mml:mi><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>26</mml:mn><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mn>50.22</mml:mn><mml:mo>,</mml:mo><mml:mi>p</mml:mi><mml:mo>&lt;</mml:mo><mml:mn>.001</mml:mn><mml:mo>,</mml:mo><mml:msubsup><mml:mi>η</mml:mi><mml:mi>p</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo>=</mml:mo><mml:mn>.659</mml:mn></mml:mrow></mml:math></alternatives></inline-formula>.
    In addition, the fourth hypothesis was supported: the face inversion
    effect was reduced for more familiar faces. The ANOVA indicated a
    significant interaction between condition and face orientation,
    <inline-formula><alternatives><tex-math><![CDATA[F(2, 52) = 11.21, p < .001, \eta_p^2 = .301]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline"><mml:mrow><mml:mi>F</mml:mi><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mn>52</mml:mn><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mn>11.21</mml:mn><mml:mo>,</mml:mo><mml:mi>p</mml:mi><mml:mo>&lt;</mml:mo><mml:mn>.001</mml:mn><mml:mo>,</mml:mo><mml:msubsup><mml:mi>η</mml:mi><mml:mi>p</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo>=</mml:mo><mml:mn>.301</mml:mn></mml:mrow></mml:math></alternatives></inline-formula>.
    The effects of inversion on recognition time were reduced when faces
    were more familiar.
    <xref alt="Figure 3" rid="fig-recognition-times-nb-article">Figure 3</xref>
    shows recognition times for inverted and upright face orientations
    for each condition.</p>
          <sec id="cell-fig-recognition-times-nb-article" specific-use="notebook-code">
            <code language="r script">faces_2x3_time</code>
            <fig id="fig-recognition-times-nb-article">
              <caption>
                <p>Figure 3: Recognition Times by Orientation for Each
      Condition</p>
              </caption>
              <graphic mimetype="image" mime-subtype="png" xlink:href="index_files/figure-jats/fig-recognition-times-1.png"/>
            </fig>
          </sec>
          <p>A small but significant interaction was also observed between age
    and condition, <inline-formula><alternatives><tex-math><![CDATA[F(2, 52) = 4.16, p = .021, \eta_p^2 = .138]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline"><mml:mrow><mml:mi>F</mml:mi><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mn>52</mml:mn><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mn>4.16</mml:mn><mml:mo>,</mml:mo><mml:mi>p</mml:mi><mml:mo>=</mml:mo><mml:mn>.021</mml:mn><mml:mo>,</mml:mo><mml:msubsup><mml:mi>η</mml:mi><mml:mi>p</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo>=</mml:mo><mml:mn>.138</mml:mn></mml:mrow></mml:math></alternatives></inline-formula>.
    For older participants, longer display times were required to
    recognise unfamiliar and familiar faces than younger participants,
    whereas older participants required relatively shorter display times
    to recognise the self-face compared to younger participants.
    <xref alt="Figure 4" rid="fig-correlations-nb-article">Figure 4</xref> shows
    this interaction in more detail, illustrating the relationship
    between age and recognition time in each condition.</p>
          <sec id="cell-fig-correlations-nb-article" specific-use="notebook-code">
            <code language="r script">p1 &lt;- ggplot(Mean_Frames, aes(x=Age, y=Unfamiliar_Upright*(1000/120))) +
  geom_point(shape=1) +    # Use hollow circles
  geom_smooth(method=lm,color="black") +  # Add linear regression line 
  #  (by default includes 95% confidence region)
  labs(x="Age", y = "Unfamiliar, Upright")+
  ylim (0, 200)+
  theme_classic() 

p2 &lt;- ggplot(Mean_Frames, aes(x=Age, y=Familiar_Upright*(1000/120))) +
  geom_point(shape=1) +    # Use hollow circles
  geom_smooth(method=lm,color="black") +  # Add linear regression line 
  #  (by default includes 95% confidence region)
  labs(x="Age", y = "Familiar, Upright")+
  ylim (0, 200)+
  theme_classic() 


p3 &lt;- ggplot(Mean_Frames, aes(x=Age, y=Self_Upright*(1000/120))) +
  geom_point(shape=1) +    # Use hollow circles
  geom_smooth(method=lm,color="black") +  # Add linear regression line 
  #  (by default includes 95% confidence region)
  labs(x="Age", y = "Self, Upright")+
  ylim (0, 200)+
  theme_classic() 


p4 &lt;- ggplot(Mean_Frames, aes(x=Age, y=Unfamiliar_Inverted*(1000/120))) +
  geom_point(shape=1) +    # Use hollow circles
  geom_smooth(method=lm,color="black") +  # Add linear regression line 
  #  (by default includes 95% confidence region)
  labs(x="Age", y = "Unfamiliar, Inverted")+
  ylim (0, 220)+
  theme_classic() 

p5 &lt;- ggplot(Mean_Frames, aes(x=Age, y=Familiar_Inverted*(1000/120))) +
  geom_point(shape=1) +    # Use hollow circles
  geom_smooth(method=lm,color="black") +  # Add linear regression line 
  #  (by default includes 95% confidence region)
  labs(x="Age", y = "Familiar, Inverted")+
  ylim (0, 220)+
  theme_classic() 


p6 &lt;- ggplot(Mean_Frames, aes(x=Age, y=Self_Inverted*(1000/120))) +
  geom_point(shape=1) +    # Use hollow circles
  geom_smooth(method=lm,color="black") +  # Add linear regression line 
  #  (by default includes 95% confidence region)
  labs(x="Age", y = "Self, Inverted")+
  ylim (0, 220)+
  theme_classic() 

p1 + p2 + p3 + p4 + p5 + p6</code>
            <fig id="fig-correlations-nb-article">
              <caption>
                <p>Figure 4: Correlations between recognition times and
      age for each condition</p>
              </caption>
              <graphic mimetype="image" mime-subtype="png" xlink:href="index_files/figure-jats/fig-correlations-1.png"/>
            </fig>
            <sec id="cell-fig-correlations-output-0-nb-article" specific-use="notebook-output">
              <preformat>`geom_smooth()` using formula = 'y ~ x'
`geom_smooth()` using formula = 'y ~ x'
`geom_smooth()` using formula = 'y ~ x'
`geom_smooth()` using formula = 'y ~ x'
`geom_smooth()` using formula = 'y ~ x'
`geom_smooth()` using formula = 'y ~ x'</preformat>
            </sec>
          </sec>
        </sec>
        <sec id="exploratory-analysis-nb-article">
          <title>Exploratory Analysis</title>
          <sec id="reaction-time-nb-article">
            <title>Reaction Time</title>
            <p>An identical 2 x 3 repeated measures ANOVA was conducted on
      participant reaction times (computed as the elapsed time between
      stimulus presentation and button press), to identify whether
      reaction times would also reveal a familiarity effect in face
      recognition. The ANOVA showed a main effect of face condition,
      with faster reaction times for the more familiar faces,
      <inline-formula><alternatives><tex-math><![CDATA[F(2, 52) = 3.85, p = .028, \eta_p^2 = .129]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline"><mml:mrow><mml:mi>F</mml:mi><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mn>52</mml:mn><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mn>3.85</mml:mn><mml:mo>,</mml:mo><mml:mi>p</mml:mi><mml:mo>=</mml:mo><mml:mn>.028</mml:mn><mml:mo>,</mml:mo><mml:msubsup><mml:mi>η</mml:mi><mml:mi>p</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo>=</mml:mo><mml:mn>.129</mml:mn></mml:mrow></mml:math></alternatives></inline-formula>.
      There was also a significant main effect of face orientation, with
      longer reaction times for inverted faces,
      <inline-formula><alternatives><tex-math><![CDATA[F(1, 26) = 18.71, p <.001, eta_p^2 = .418]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline"><mml:mrow><mml:mi>F</mml:mi><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>26</mml:mn><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mn>18.71</mml:mn><mml:mo>,</mml:mo><mml:mi>p</mml:mi><mml:mo>&lt;</mml:mo><mml:mn>.001</mml:mn><mml:mo>,</mml:mo><mml:mi>e</mml:mi><mml:mi>t</mml:mi><mml:msubsup><mml:mi>a</mml:mi><mml:mi>p</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo>=</mml:mo><mml:mn>.418</mml:mn></mml:mrow></mml:math></alternatives></inline-formula>.
      However, there was no significant interaction between condition
      and face orientation, <inline-formula><alternatives><tex-math><![CDATA[F(2, 52) = 0.14, p = .872, eta_p^2) = .005]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline"><mml:mrow><mml:mi>F</mml:mi><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mn>52</mml:mn><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mn>0.14</mml:mn><mml:mo>,</mml:mo><mml:mi>p</mml:mi><mml:mo>=</mml:mo><mml:mn>.872</mml:mn><mml:mo>,</mml:mo><mml:mi>e</mml:mi><mml:mi>t</mml:mi><mml:msubsup><mml:mi>a</mml:mi><mml:mi>p</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo stretchy="false" form="postfix">)</mml:mo><mml:mo>=</mml:mo><mml:mn>.005</mml:mn></mml:mrow></mml:math></alternatives></inline-formula>.
      <xref alt="Figure 5" rid="fig-reaction-times-nb-article">Figure 5</xref>
      shows reaction times for inverted and upright face orientations
      for each condition.</p>
            <sec id="cell-fig-reaction-times-nb-article" specific-use="notebook-code">
              <code language="r script">faces_2x3_RTs</code>
              <fig id="fig-reaction-times-nb-article">
                <caption>
                  <p>Figure 5: Reaction times by orientation for each
        condition</p>
                </caption>
                <graphic mimetype="image" mime-subtype="png" xlink:href="index_files/figure-jats/fig-reaction-times-1.png"/>
              </fig>
            </sec>
          </sec>
        </sec>
      </sec>
      <sec id="discussion-nb-article">
        <title>Discussion</title>
        <p>To better understand the effect of greater levels of familiarity on
  face recognition, the present study used a staircase procedure to
  characterise face recognition performance. Participants responded to
  three different face categories manipulated by familiarity
  (unfamiliar, familiar, and self), and orientation (upright and
  inverted). Recognition time (i.e., perceptual processes) was isolated
  from reaction time (i.e., perceptual processes + cognitive decision +
  motor response) and used as an index of the familiarity effect. The
  overall findings confirmed predictions that more familiar faces are
  processed faster than less familiar and unfamiliar faces. Notably, our
  results underscore the self-face as a unique class of familiar face,
  providing compelling evidence for distinct perceptual processing.</p>
        <sec id="familiarity-and-recognition-time-nb-article">
          <title>Familiarity and Recognition Time</title>
          <p>In support of hypothesis one, participants recognised their own
    faces at shorter display times compared with other faces, providing
    evidence for distinct perceptual processing
    (<xref alt="Alzueta et al., 2019" rid="ref-alzueta2019a-nb-article" ref-type="bibr">Alzueta
    et al., 2019</xref>;
    <xref alt="Rooney et al., 2012" rid="ref-rooney2012a-nb-article" ref-type="bibr">Rooney
    et al., 2012</xref>). Results conflicted with an EEG study
    demonstrating the self-face elicited similar neural responses
    relative to personally familiar faces
    (<xref alt="Wiese et al., 2021" rid="ref-wiese2021a-nb-article" ref-type="bibr">Wiese
    et al., 2021</xref>). The self-face advantage observed in the
    recognition times may reflect robust self-representations developed
    over time, strengthened by both the amount of exposure and the
    nature of the exposure we have with our own face
    (<xref alt="Bortolon et al., 2017" rid="ref-bortolon2017a-nb-article" ref-type="bibr">Bortolon
    et al., 2017</xref>;
    <xref alt="Tong &amp; Nakayama, 1999" rid="ref-tong1999a-nb-article" ref-type="bibr">Tong
    &amp; Nakayama, 1999</xref>). For example, examining our image in
    the mirror is a multisensory encounter, allowing us access to
    motor-sensory and tactile cues that enable us to update our mental
    representations of ourselves
    (<xref alt="Bortolon et al., 2017" rid="ref-bortolon2017a-nb-article" ref-type="bibr">Bortolon
    et al., 2017</xref>). Further, research linking self-face
    recognition and self-esteem revealed that when participants viewed
    photographs of themselves alongside images that were manipulated to
    look more attractive, observers chose the manipulated images as more
    accurate self-representations, which correlated with higher
    self-esteem
    (<xref alt="Felisberti &amp; Musholt, 2014" rid="ref-felisberti2014a-nb-article" ref-type="bibr">Felisberti
    &amp; Musholt, 2014</xref>). This tolerance to error, as reflected
    by the perceptual biases, may be a crucial and distinctive component
    of self-face representations that could enhance recognition
    performance
    (<xref alt="Felisberti &amp; Musholt, 2014" rid="ref-felisberti2014a-nb-article" ref-type="bibr">Felisberti
    &amp; Musholt, 2014</xref>).</p>
          <p>Familiarity effects were also found in the shorter display times
    required to recognise the familiar face (the experimenter) compared
    to unfamiliar faces, supporting hypothesis two. The findings align
    with the abundant research evidence in face recognition
    demonstrating a qualitative and quantitative gap between familiar
    and unfamiliar face processing
    (<xref alt="Burton, 2013" rid="ref-burton2013a-nb-article" ref-type="bibr">Burton,
    2013</xref>;
    <xref alt="Burton et al., 2016" rid="ref-burton2016a-nb-article" ref-type="bibr">Burton
    et al., 2016</xref>;
    <xref alt="Ramon &amp; Gobbini, 2017" rid="ref-ramon2017a-nb-article" ref-type="bibr">Ramon
    &amp; Gobbini, 2017</xref>). It is possible that familiar face
    recognition performance was strengthened by the opportunity for
    participants to learn how the experimenter’s face changed in
    appearance (e.g., different facial expressions and viewing angles),
    and the conceptual information (e.g., name and research interest)
    shared prior to the experiment
    (<xref alt="Dowsett et al., 2016" rid="ref-dowsett2016a-nb-article" ref-type="bibr">Dowsett
    et al., 2016</xref>).</p>
          <p>The observation that older participants were faster at
    recognising their own face compared to younger participants was
    surprising given the rise in the importance of the “selfie” in
    popular culture
    (<xref alt="Tshidzumba, 2019" rid="ref-tshidzumba2019a-nb-article" ref-type="bibr">Tshidzumba,
    2019</xref>). In line with previous research suggesting that we are
    better at discriminating faces from our own age group, it is
    possible that older participants found it easier to distinguish
    their own face from the distractor faces, which were young
    identities
    (<xref alt="Rhodes &amp; Anastasi, 2012" rid="ref-rhodes2012a-nb-article" ref-type="bibr">Rhodes
    &amp; Anastasi, 2012</xref>).</p>
        </sec>
        <sec id="familiarity-and-inversion-effects-nb-article">
          <title>Familiarity and Inversion Effects</title>
          <p>The present study replicated the face inversion effect, a common
    finding in previous research that suggests human participants
    experience more difficulty recognising faces when they are upside
    down than when they are upright in their canonical orientation.
    Therefore, these findings support the third hypothesis, that
    regardless of familiarity, faces are harder to recognise upside down
    (<xref alt="Allen-Davidian et al., 2021" rid="ref-allen-davidian2021a-nb-article" ref-type="bibr">Allen-Davidian
    et al., 2021</xref>;
    <xref alt="Kramer et al., 2018" rid="ref-kramer2018a-nb-article" ref-type="bibr">Kramer
    et al., 2018</xref>;
    <xref alt="Taubert et al., 2011" rid="ref-taubert2011a-nb-article" ref-type="bibr">Taubert
    et al., 2011</xref>;
    <xref alt="Young &amp; Burton, 2017" rid="ref-young2017a-nb-article" ref-type="bibr">Young
    &amp; Burton, 2017</xref>). This experiment also yielded empirical
    support for hypothesis four; the face inversion effect was
    significantly smaller for familiar faces than unfamiliar faces.
    Interestingly, the more familiar participants were with the face,
    the more immune they were to the inversion manipulation. This
    finding is consistent with previous studies that have also suggested
    that familiar faces are robust to the deleterious effects of
    inversion
    (<xref alt="Keyes, 2012" rid="ref-keyes2012a-nb-article" ref-type="bibr">Keyes,
    2012</xref>;
    <xref alt="Keyes &amp; Brady, 2010" rid="ref-keyes2010a-nb-article" ref-type="bibr">Keyes
    &amp; Brady, 2010</xref>;
    <xref alt="Yang et al., 2014" rid="ref-yang2014a-nb-article" ref-type="bibr">Yang
    et al., 2014</xref>). However, results contradicted those of Alzueta
    et al.
    (<xref alt="2019" rid="ref-alzueta2019a-nb-article" ref-type="bibr">2019</xref>),
    who found no significant change in the size of inversion effects
    across unfamiliar, familiar and self-face conditions. Inconsistent
    findings may be explained by the difference in task complexity
    between the studies. For example, the staircase used in the present
    study involved finding a target face between two images, displayed
    for a short period (e.g., 66.67ms starting point), averaging
    performance across 12 trials, whereas Alzueta et al.
    (<xref alt="2019" rid="ref-alzueta2019a-nb-article" ref-type="bibr">2019</xref>)
    allowed participants 1000ms to categorise a single face display as
    “me”, “friend” or “stranger”, averaging performance across 450
    trials.</p>
          <p>Overall, these findings provide strong behavioural support for
    the idea that images of our face are processed differently to other
    faces, as participants were able to easily recognise their own face
    in the inverted position in less time than was required to recognise
    an upright unfamiliar face. The current results challenge the widely
    accepted view that all human faces are processed holistically, as
    the faster recognition times for inverted faces in the familiar and
    self-face conditions could be interpreted as evidence for stronger
    feature-based representations
    (<xref alt="Gerlach &amp; Mogensen, 2022" rid="ref-gerlach2022a-nb-article" ref-type="bibr">Gerlach
    &amp; Mogensen, 2022</xref>;
    <xref alt="Tong &amp; Nakayama, 1999" rid="ref-tong1999a-nb-article" ref-type="bibr">Tong
    &amp; Nakayama, 1999</xref>).</p>
        </sec>
        <sec id="reaction-time-and-levels-of-familiarity-nb-article">
          <title>Reaction Time and Levels of Familiarity</title>
          <p>Consistent with recognition time results and in alignment with
    the literature, there was a significant difference in reaction times
    between unfamiliar, familiar and self-face conditions
    (<xref alt="Kloth et al., 2006" rid="ref-kloth2006a-nb-article" ref-type="bibr">Kloth
    et al., 2006</xref>;
    <xref alt="Ramon et al., 2011" rid="ref-ramon2011a-nb-article" ref-type="bibr">Ramon
    et al., 2011</xref>;
    <xref alt="Young &amp; Burton, 2017" rid="ref-young2017a-nb-article" ref-type="bibr">Young
    &amp; Burton, 2017</xref>). Interestingly, the reaction times were
    found to be longer than those reported in other studies, which is
    likely due to the inherent task complexity when using a staircase,
    compared to more simple, untimed go/no-go face categorisation tasks
    (<xref alt="Bortolon et al., 2017" rid="ref-bortolon2017a-nb-article" ref-type="bibr">Bortolon
    et al., 2017</xref>;
    <xref alt="Burton et al., 2016" rid="ref-burton2016a-nb-article" ref-type="bibr">Burton
    et al., 2016</xref>;
    <xref alt="Ramon et al., 2011" rid="ref-ramon2011a-nb-article" ref-type="bibr">Ramon
    et al., 2011</xref>;
    <xref alt="Smith et al., 2016" rid="ref-smith2016a-nb-article" ref-type="bibr">Smith
    et al., 2016</xref>).</p>
          <p>Importantly, the data revealed that recognition times were
    substantially shorter than reaction times for each condition. For
    example, on average, participants recognised (processed) upright
    familiar faces within 43.8ms but required 547ms to respond (process
    + decision + motor response) to the target face. These findings have
    important implications for future research designs, as they suggest
    that reaction times may be underestimating face recognition
    performance. Reaction times were longer for inverted faces compared
    to upright faces, however, the data did not reveal the interaction
    observed in the recognition time data, as there was no significant
    difference in the face inversion effect between conditions. Thus,
    recognition time seems to be a more sensitive measure of familiarity
    effects in face recognition.</p>
        </sec>
        <sec id="future-directions-nb-article">
          <title>Future Directions</title>
          <p>The staircase procedure was a key strength of the research,
    demonstrating that the reaction times reported in research may be
    underestimating human face recognition ability
    (<xref alt="Besson et al., 2016" rid="ref-besson2016a-nb-article" ref-type="bibr">Besson
    et al., 2016</xref>;
    <xref alt="Caharel et al., 2014" rid="ref-caharel2014a-nb-article" ref-type="bibr">Caharel
    et al., 2014</xref>;
    <xref alt="Ramon et al., 2011" rid="ref-ramon2011a-nb-article" ref-type="bibr">Ramon
    et al., 2011</xref>). However, the study design could be considered
    difficult to compare with other face recognition research. First,
    recognition times cannot be directly compared with reaction times.
    Second, the staircase procedure only measured the ability of
    participants to discriminate between two stimuli, unlike other
    studies that require participants to identify a target face among an
    array of distractor faces
    (<xref alt="Megreya &amp; Burton, 2006" rid="ref-megraya2006a-nb-article" ref-type="bibr">Megreya
    &amp; Burton, 2006</xref>). Third, the time constraint imposed by
    the staircase is not comparable with studies involving tasks without
    time limits
    (<xref alt="Zimmermann et al., 2019" rid="ref-zimmermann2019a-nb-article" ref-type="bibr">Zimmermann
    et al., 2019</xref>). Future studies could attempt to address some
    of these comparability concerns by replicating the same study
    together with a standard go/no-go face categorisation task, to allow
    for a comparison of reaction times between the two tasks. Further,
    adapting the staircase to include a four-alternative force choice
    task, rather than the two alternatives used here, would provide a
    better comparison with studies involving recognition tasks that
    require discrimination between multiple exemplars. Although the
    study examined three levels of familiarity (unfamiliar, familiar,
    and self), other highly familiar faces such as famous faces were not
    included
    (<xref alt="Campbell et al., 2020" rid="ref-campbell2020a-nb-article" ref-type="bibr">Campbell
    et al., 2020</xref>;
    <xref alt="Wiese et al., 2021" rid="ref-wiese2021a-nb-article" ref-type="bibr">Wiese
    et al., 2021</xref>). Future studies could incorporate famous faces
    and face stimuli of identities that are more intimately known by the
    perceiver such as close friends and family members, to test the
    effects of different levels of familiarity on face recognition in
    both upright and inverted orientations. This would allow further
    exploration of the inversion effect found in the present study. It
    would also assist future face recognition research in defining the
    familiarity construct, particularly with respect to the self-face
    compared with other highly familiar faces. Further, the varying
    levels of familiarity participants had with the experimenter created
    inconsistency in the construct of the familiar condition. Future
    studies could include a larger sample of both previously unknown and
    previously known participants to compare the performance of two
    different levels of familiarity. Including previously unknown
    participants also provides valuable insight into the effects of
    real-world face learning on recognition.</p>
          <p>Future research should aim to involve diverse participants,
    including all genders and representation from all age groups. The
    female-only sample may have influenced results, as there is some
    evidence suggesting a female own-gender bias in face recognition
    performance
    (<xref alt="Herlitz &amp; Lovén, 2013" rid="ref-herlitz2013a-nb-article" ref-type="bibr">Herlitz
    &amp; Lovén, 2013</xref>;
    <xref alt="Lovén et al., 2011" rid="ref-lov2011a-nb-article" ref-type="bibr">Lovén
    et al., 2011</xref>;
    <xref alt="Mishra et al., 2019" rid="ref-mishra2019a-nb-article" ref-type="bibr">Mishra
    et al., 2019</xref>). The mean age (43.1 years) in the present study
    is not reflective of the average age (~ 21-35 years) of participants
    in many other face recognition studies
    (<xref alt="Kloth et al., 2006" rid="ref-kloth2006a-nb-article" ref-type="bibr">Kloth
    et al., 2006</xref>;
    <xref alt="Mohr et al., 2018" rid="ref-mohr2018a-nb-article" ref-type="bibr">Mohr
    et al., 2018</xref>;
    <xref alt="Pachai et al., 2017" rid="ref-pachai2017a-nb-article" ref-type="bibr">Pachai
    et al., 2017</xref>;
    <xref alt="Platek &amp; Kemp, 2009" rid="ref-platek2009a-nb-article" ref-type="bibr">Platek
    &amp; Kemp, 2009</xref>). Including a range of age groups is
    warranted given the age interaction found in the present study and
    research suggesting an age-bias in face recognition performance
    (<xref alt="Rhodes &amp; Anastasi, 2012" rid="ref-rhodes2012a-nb-article" ref-type="bibr">Rhodes
    &amp; Anastasi, 2012</xref>).</p>
        </sec>
        <sec id="conclusion-nb-article">
          <title>Conclusion</title>
          <p>Overall, the findings of the present study demonstrate the
    familiarity advantage in face recognition. We provide strong
    evidence in support of distinct perceptual processing at different
    levels of familiarity, as demonstrated by faster recognition times
    for both the self-face and familiar face compared to unfamiliar
    faces. The self-face appears to be processed differently to other
    familiar faces, validating the self-face as an important inclusion
    in face studies seeking to understand the familiarity effect in face
    recognition. The staircase procedure provided a unique insight into
    processing time, highlighting the potential underestimation of face
    recognition ability in the literature. The finding that face
    inversion is less disruptive to the processing of more familiar
    faces is further evidence of distinct perceptual processes and
    challenges the widely held view that faces are processed
    holistically. We recommend further exploration of the effects of
    inversion at different levels of familiarity, to enhance
    understanding of perceptual processing distinctions, and identify
    implications for holistic and featural processing theories.</p>
        </sec>
      </sec>
    </body>
    <back>
      <ref-list>
        <title/>
        <ref id="ref-hole_effects_2002-nb-article">
          <element-citation publication-type="article-journal">
            <person-group person-group-type="author">
              <name>
                <surname>Hole</surname>
                <given-names>Graham J</given-names>
              </name>
              <name>
                <surname>George</surname>
                <given-names>Patricia A</given-names>
              </name>
              <name>
                <surname>Eaves</surname>
                <given-names>Karen</given-names>
              </name>
              <name>
                <surname>Rasek</surname>
                <given-names>Ayman</given-names>
              </name>
            </person-group>
            <article-title>Effects of Geometric Distortions on Face-Recognition Performance</article-title>
            <source>Perception</source>
            <year iso-8601-date="2002-10">2002</year>
            <month>10</month>
            <date-in-citation content-type="access-date">
              <year iso-8601-date="2024-02-02">2024</year>
              <month>02</month>
              <day>02</day>
            </date-in-citation>
            <volume>31</volume>
            <issue>10</issue>
            <issn>0301-0066</issn>
            <uri>https://doi.org/10.1068/p3252</uri>
            <pub-id pub-id-type="doi">10.1068/p3252</pub-id>
            <fpage>1221</fpage>
            <lpage>1240</lpage>
          </element-citation>
        </ref>
        <ref id="ref-long_database_2023-nb-article">
          <element-citation publication-type="article-journal">
            <person-group person-group-type="author">
              <name>
                <surname>Long</surname>
                <given-names>Houqiu</given-names>
              </name>
              <name>
                <surname>Peluso</surname>
                <given-names>Natalie</given-names>
              </name>
              <name>
                <surname>Baker</surname>
                <given-names>Chris I.</given-names>
              </name>
              <name>
                <surname>Japee</surname>
                <given-names>Shruti</given-names>
              </name>
              <name>
                <surname>Taubert</surname>
                <given-names>Jessica</given-names>
              </name>
            </person-group>
            <article-title>A database of heterogeneous faces for studying naturalistic expressions</article-title>
            <source>Scientific Reports</source>
            <year iso-8601-date="2023-04">2023</year>
            <month>04</month>
            <volume>13</volume>
            <issue>1</issue>
            <issn>2045-2322</issn>
            <pub-id pub-id-type="doi">10.1038/s41598-023-32659-5</pub-id>
            <pub-id pub-id-type="pmid">37012369</pub-id>
            <fpage>5383</fpage>
            <lpage/>
          </element-citation>
        </ref>
        <ref id="ref-maurer_many_2002-nb-article">
          <element-citation publication-type="article-journal">
            <person-group person-group-type="author">
              <name>
                <surname>Maurer</surname>
                <given-names>Daphne</given-names>
              </name>
              <name>
                <surname>Grand</surname>
                <given-names>Richard Le</given-names>
              </name>
              <name>
                <surname>Mondloch</surname>
                <given-names>Catherine J.</given-names>
              </name>
            </person-group>
            <article-title>The many faces of configural processing</article-title>
            <source>Trends in Cognitive Sciences</source>
            <year iso-8601-date="2002-06">2002</year>
            <month>06</month>
            <date-in-citation content-type="access-date">
              <year iso-8601-date="2024-02-02">2024</year>
              <month>02</month>
              <day>02</day>
            </date-in-citation>
            <volume>6</volume>
            <issue>6</issue>
            <issn>1364-6613</issn>
            <uri>https://www.sciencedirect.com/science/article/pii/S1364661302019034</uri>
            <pub-id pub-id-type="doi">10.1016/S1364-6613(02)01903-4</pub-id>
            <fpage>255</fpage>
            <lpage>260</lpage>
          </element-citation>
        </ref>
        <ref id="ref-rossion_picture-plane_2008-nb-article">
          <element-citation publication-type="article-journal">
            <person-group person-group-type="author">
              <name>
                <surname>Rossion</surname>
                <given-names>Bruno</given-names>
              </name>
            </person-group>
            <article-title>Picture-plane inversion leads to qualitative changes of face perception</article-title>
            <source>Acta Psychologica</source>
            <year iso-8601-date="2008">2008</year>
            <volume>128</volume>
            <issue>2</issue>
            <issn>1873-6297</issn>
            <pub-id pub-id-type="doi">10.1016/j.actpsy.2008.02.003</pub-id>
            <fpage>274</fpage>
            <lpage>289</lpage>
          </element-citation>
        </ref>
        <ref id="ref-rossion_what_2019-nb-article">
          <element-citation publication-type="article-journal">
            <person-group person-group-type="author">
              <name>
                <surname>Rossion</surname>
                <given-names>Bruno</given-names>
              </name>
              <name>
                <surname>Taubert</surname>
                <given-names>Jessica</given-names>
              </name>
            </person-group>
            <article-title>What can we learn about human individual face recognition from experimental studies in monkeys?</article-title>
            <source>Vision Research</source>
            <year iso-8601-date="2019-04">2019</year>
            <month>04</month>
            <date-in-citation content-type="access-date">
              <year iso-8601-date="2024-02-02">2024</year>
              <month>02</month>
              <day>02</day>
            </date-in-citation>
            <volume>157</volume>
            <issn>0042-6989</issn>
            <uri>https://www.sciencedirect.com/science/article/pii/S0042698918301160</uri>
            <pub-id pub-id-type="doi">10.1016/j.visres.2018.03.012</pub-id>
            <fpage>142</fpage>
            <lpage>158</lpage>
          </element-citation>
        </ref>
        <ref id="ref-taubert_effect_2015-nb-article">
          <element-citation publication-type="article-journal">
            <person-group person-group-type="author">
              <name>
                <surname>Taubert</surname>
                <given-names>Jessica</given-names>
              </name>
              <name>
                <surname>Van Belle</surname>
                <given-names>Goedele</given-names>
              </name>
              <name>
                <surname>Vanduffel</surname>
                <given-names>Wim</given-names>
              </name>
              <name>
                <surname>Rossion</surname>
                <given-names>Bruno</given-names>
              </name>
              <name>
                <surname>Vogels</surname>
                <given-names>Rufin</given-names>
              </name>
            </person-group>
            <article-title>The effect of face inversion for neurons inside and outside fMRI-defined face-selective cortical regions</article-title>
            <source>Journal of Neurophysiology</source>
            <year iso-8601-date="2015-03">2015</year>
            <month>03</month>
            <volume>113</volume>
            <issue>5</issue>
            <issn>1522-1598</issn>
            <pub-id pub-id-type="doi">10.1152/jn.00700.2014</pub-id>
            <pub-id pub-id-type="pmid">25520434</pub-id>
            <fpage>1644</fpage>
            <lpage>1655</lpage>
          </element-citation>
        </ref>
        <ref id="ref-towler_are_2019-nb-article">
          <element-citation publication-type="article-journal">
            <person-group person-group-type="author">
              <name>
                <surname>Towler</surname>
                <given-names>A.</given-names>
              </name>
              <name>
                <surname>Kemp</surname>
                <given-names>R. I.</given-names>
              </name>
              <name>
                <surname>Bruce</surname>
                <given-names>V.</given-names>
              </name>
              <name>
                <surname>Burton</surname>
                <given-names>A. M.</given-names>
              </name>
              <name>
                <surname>Dunn</surname>
                <given-names>J. D.</given-names>
              </name>
              <name>
                <surname>White</surname>
                <given-names>D.</given-names>
              </name>
            </person-group>
            <article-title>Are face recognition abilities in humans and sheep really ‘comparable’?</article-title>
            <source>Royal Society Open Science</source>
            <year iso-8601-date="2019-01">2019</year>
            <month>01</month>
            <date-in-citation content-type="access-date">
              <year iso-8601-date="2024-02-02">2024</year>
              <month>02</month>
              <day>02</day>
            </date-in-citation>
            <volume>6</volume>
            <issue>1</issue>
            <uri>https://royalsocietypublishing.org/doi/10.1098/rsos.180772</uri>
            <pub-id pub-id-type="doi">10.1098/rsos.180772</pub-id>
            <fpage>180772</fpage>
            <lpage/>
          </element-citation>
        </ref>
        <ref id="ref-valentine_upside-down_1988-nb-article">
          <element-citation publication-type="article-journal">
            <person-group person-group-type="author">
              <name>
                <surname>Valentine</surname>
                <given-names>Tim</given-names>
              </name>
            </person-group>
            <article-title>Upside-down faces: A review of the effect of inversion upon face recognition</article-title>
            <source>British Journal of Psychology</source>
            <year iso-8601-date="1988">1988</year>
            <date-in-citation content-type="access-date">
              <year iso-8601-date="2024-02-02">2024</year>
              <month>02</month>
              <day>02</day>
            </date-in-citation>
            <volume>79</volume>
            <issue>4</issue>
            <issn>2044-8295</issn>
            <uri>https://onlinelibrary.wiley.com/doi/abs/10.1111/j.2044-8295.1988.tb02747.x</uri>
            <pub-id pub-id-type="doi">10.1111/j.2044-8295.1988.tb02747.x</pub-id>
            <fpage>471</fpage>
            <lpage>491</lpage>
          </element-citation>
        </ref>
        <ref id="ref-waidmann_local_2022-nb-article">
          <element-citation publication-type="article-journal">
            <person-group person-group-type="author">
              <name>
                <surname>Waidmann</surname>
                <given-names>Elena N.</given-names>
              </name>
              <name>
                <surname>Koyano</surname>
                <given-names>Kenji W.</given-names>
              </name>
              <name>
                <surname>Hong</surname>
                <given-names>Julie J.</given-names>
              </name>
              <name>
                <surname>Russ</surname>
                <given-names>Brian E.</given-names>
              </name>
              <name>
                <surname>Leopold</surname>
                <given-names>David A.</given-names>
              </name>
            </person-group>
            <article-title>Local features drive identity responses in macaque anterior face patches</article-title>
            <source>Nature Communications</source>
            <year iso-8601-date="2022-09">2022</year>
            <month>09</month>
            <date-in-citation content-type="access-date">
              <year iso-8601-date="2024-02-02">2024</year>
              <month>02</month>
              <day>02</day>
            </date-in-citation>
            <volume>13</volume>
            <issue>1</issue>
            <issn>2041-1723</issn>
            <uri>https://www.nature.com/articles/s41467-022-33240-w</uri>
            <pub-id pub-id-type="doi">10.1038/s41467-022-33240-w</pub-id>
            <fpage>5592</fpage>
            <lpage/>
          </element-citation>
        </ref>
        <ref id="ref-white_individual_2022-nb-article">
          <element-citation publication-type="article-journal">
            <person-group person-group-type="author">
              <name>
                <surname>White</surname>
                <given-names>David</given-names>
              </name>
              <name>
                <surname>Burton</surname>
                <given-names>A. Mike</given-names>
              </name>
            </person-group>
            <article-title>Individual differences and the multidimensional nature of face perception</article-title>
            <source>Nature Reviews Psychology</source>
            <year iso-8601-date="2022-05">2022</year>
            <month>05</month>
            <date-in-citation content-type="access-date">
              <year iso-8601-date="2024-02-02">2024</year>
              <month>02</month>
              <day>02</day>
            </date-in-citation>
            <volume>1</volume>
            <issue>5</issue>
            <issn>2731-0574</issn>
            <uri>https://www.nature.com/articles/s44159-022-00041-3</uri>
            <pub-id pub-id-type="doi">10.1038/s44159-022-00041-3</pub-id>
            <fpage>287</fpage>
            <lpage>300</lpage>
          </element-citation>
        </ref>
        <ref id="ref-abudarham2016a-nb-article">
          <element-citation publication-type="article-journal">
            <person-group person-group-type="author">
              <name>
                <surname>Abudarham</surname>
                <given-names>N.</given-names>
              </name>
              <name>
                <surname>Yovel</surname>
                <given-names>G.</given-names>
              </name>
            </person-group>
            <article-title>Reverse engineering the face space: Discovering the critical features for face identification</article-title>
            <source>Journal of Vision</source>
            <year iso-8601-date="2016">2016</year>
            <volume>16</volume>
            <issue>3</issue>
            <pub-id pub-id-type="doi">10.1167/16.3.40</pub-id>
            <fpage>1</fpage>
            <lpage>18</lpage>
          </element-citation>
        </ref>
        <ref id="ref-abudarham2019a-nb-article">
          <element-citation publication-type="article-journal">
            <person-group person-group-type="author">
              <name>
                <surname>Abudarham</surname>
                <given-names>N.</given-names>
              </name>
              <name>
                <surname>Shkiller</surname>
                <given-names>L.</given-names>
              </name>
              <name>
                <surname>Yovel</surname>
                <given-names>G.</given-names>
              </name>
            </person-group>
            <article-title>Critical features for face recognition</article-title>
            <source>Cognition</source>
            <year iso-8601-date="2019">2019</year>
            <volume>182</volume>
            <pub-id pub-id-type="doi">10.1016/j.cognition.2018.09.002</pub-id>
            <fpage>73</fpage>
            <lpage>83</lpage>
          </element-citation>
        </ref>
        <ref id="ref-allen-davidian2021a-nb-article">
          <element-citation publication-type="article-journal">
            <person-group person-group-type="author">
              <name>
                <surname>Allen-Davidian</surname>
                <given-names>Y.</given-names>
              </name>
              <name>
                <surname>Russo</surname>
                <given-names>M.</given-names>
              </name>
              <name>
                <surname>Yamamoto</surname>
                <given-names>N.</given-names>
              </name>
              <name>
                <surname>Kaufman</surname>
                <given-names>J.</given-names>
              </name>
              <name>
                <surname>Pegna</surname>
                <given-names>A. J.</given-names>
              </name>
              <name>
                <surname>Johnston</surname>
                <given-names>P.</given-names>
              </name>
            </person-group>
            <article-title>Turning the face inversion effect on its head: Violated expectations of orientation, lighting, and gravity enhance N170 amplitudes</article-title>
            <source>The Journal of Cognitive Neuroscience</source>
            <year iso-8601-date="2021">2021</year>
            <volume>33</volume>
            <issue>2</issue>
            <pub-id pub-id-type="doi">10.1162/jocn\_a\_01656</pub-id>
            <fpage>303</fpage>
            <lpage>314</lpage>
          </element-citation>
        </ref>
        <ref id="ref-alzueta2019a-nb-article">
          <element-citation publication-type="article-journal">
            <person-group person-group-type="author">
              <name>
                <surname>Alzueta</surname>
                <given-names>E.</given-names>
              </name>
              <name>
                <surname>Melcón</surname>
                <given-names>M.</given-names>
              </name>
              <name>
                <surname>Poch</surname>
                <given-names>C.</given-names>
              </name>
              <name>
                <surname>Capilla</surname>
                <given-names>A.</given-names>
              </name>
            </person-group>
            <article-title>Is your own face more than a highly familiar face?</article-title>
            <source>Biological Psychology</source>
            <year iso-8601-date="2019">2019</year>
            <volume>142</volume>
            <pub-id pub-id-type="doi">10.1016/j.biopsycho.2019.01.018</pub-id>
            <fpage>100</fpage>
            <lpage>107</lpage>
          </element-citation>
        </ref>
        <ref id="ref-besson2016a-nb-article">
          <element-citation publication-type="article-journal">
            <person-group person-group-type="author">
              <name>
                <surname>Besson</surname>
                <given-names>G.</given-names>
              </name>
              <name>
                <surname>Barragan-Jason</surname>
                <given-names>G.</given-names>
              </name>
              <name>
                <surname>Fabre-Thorpe</surname>
                <given-names>M.</given-names>
              </name>
              <name>
                <surname>Puma</surname>
                <given-names>S.</given-names>
              </name>
              <name>
                <surname>Ceccaldi</surname>
                <given-names>M.</given-names>
              </name>
              <name>
                <surname>Barbeau</surname>
                <given-names>E. J.</given-names>
              </name>
            </person-group>
            <article-title>From face processing to face recognition: Comparing three different processing levels</article-title>
            <source>Cognition</source>
            <year iso-8601-date="2016">2016</year>
            <volume>158</volume>
            <pub-id pub-id-type="doi">10.1016/j.cognition.2016.10.004</pub-id>
            <fpage>33</fpage>
            <lpage>43</lpage>
          </element-citation>
        </ref>
        <ref id="ref-bortolon2017a-nb-article">
          <element-citation publication-type="article-journal">
            <person-group person-group-type="author">
              <name>
                <surname>Bortolon</surname>
                <given-names>C.</given-names>
              </name>
              <name>
                <surname>Lorieux</surname>
                <given-names>S.</given-names>
              </name>
              <name>
                <surname>Raffard</surname>
                <given-names>S.</given-names>
              </name>
            </person-group>
            <article-title>Self or familiar-face recognition advantage? New insight using ambient images</article-title>
            <source>The Quarterly Journal of Experimental Psychology</source>
            <year iso-8601-date="2017">2017</year>
            <volume>71</volume>
            <issue>6</issue>
            <pub-id pub-id-type="doi">10.1080/17470218.2017.1327982</pub-id>
            <fpage>1396</fpage>
            <lpage>1404</lpage>
          </element-citation>
        </ref>
        <ref id="ref-bortolon2018a-nb-article">
          <element-citation publication-type="article-journal">
            <person-group person-group-type="author">
              <name>
                <surname>Bortolon.</surname>
              </name>
              <name>
                <surname>Raffard</surname>
                <given-names>S.</given-names>
              </name>
            </person-group>
            <article-title>Self-face advantage over familiar and unfamiliar faces: A three-level meta-analytic approach</article-title>
            <source>Psychonomic Bulletin &amp; Review</source>
            <year iso-8601-date="2018">2018</year>
            <volume>25</volume>
            <pub-id pub-id-type="doi">10.3758/s13423-018-1487-9</pub-id>
            <fpage>1287</fpage>
            <lpage>1300</lpage>
          </element-citation>
        </ref>
        <ref id="ref-blauch2021a-nb-article">
          <element-citation publication-type="article-journal">
            <person-group person-group-type="author">
              <name>
                <surname>Blauch</surname>
                <given-names>N. M.</given-names>
              </name>
              <name>
                <surname>Behrmann</surname>
                <given-names>M.</given-names>
              </name>
              <name>
                <surname>Plaut</surname>
                <given-names>D. C.</given-names>
              </name>
            </person-group>
            <article-title>Computational insights into human perceptual expertise for familiar and unfamiliar face recognition</article-title>
            <source>Cognition</source>
            <year iso-8601-date="2021">2021</year>
            <volume>208</volume>
            <pub-id pub-id-type="doi">10.1016/j.cognition.2020.104341</pub-id>
            <fpage>1</fpage>
            <lpage>13</lpage>
          </element-citation>
        </ref>
        <ref id="ref-burton1999a-nb-article">
          <element-citation publication-type="article-journal">
            <person-group person-group-type="author">
              <name>
                <surname>Burton</surname>
                <given-names>A. M.</given-names>
              </name>
              <name>
                <surname>Wilson</surname>
                <given-names>M.</given-names>
              </name>
              <name>
                <surname>Cowan</surname>
                <given-names>M.</given-names>
              </name>
              <name>
                <surname>Bruce</surname>
                <given-names>V.</given-names>
              </name>
            </person-group>
            <article-title>Face recognition in poor-quality video: Evidence from security surveillance</article-title>
            <source>Psychological Science</source>
            <year iso-8601-date="1999">1999</year>
            <volume>10</volume>
            <issue>3</issue>
            <pub-id pub-id-type="doi">10.1111/1467-9280.00144</pub-id>
            <fpage>243</fpage>
            <lpage>248</lpage>
          </element-citation>
        </ref>
        <ref id="ref-burton2011a-nb-article">
          <element-citation publication-type="article-journal">
            <person-group person-group-type="author">
              <name>
                <surname>Burton</surname>
                <given-names>A. M.</given-names>
              </name>
              <name>
                <surname>Jenkins</surname>
                <given-names>R.</given-names>
              </name>
              <name>
                <surname>Schweinberger</surname>
                <given-names>S. R.</given-names>
              </name>
            </person-group>
            <article-title>Mental representations of familiar faces</article-title>
            <source>British Journal of Psychology</source>
            <year iso-8601-date="2011">2011</year>
            <volume>102</volume>
            <pub-id pub-id-type="doi">10.1111/j.2044-8295.2011.02039.x</pub-id>
            <fpage>2943</fpage>
            <lpage>958</lpage>
          </element-citation>
        </ref>
        <ref id="ref-burton2013a-nb-article">
          <element-citation publication-type="article-journal">
            <person-group person-group-type="author">
              <name>
                <surname>Burton</surname>
                <given-names>A. M.</given-names>
              </name>
            </person-group>
            <article-title>Why has research in face recognition progressed so slowly? The importance of variability</article-title>
            <source>The Quarterly Journal of Experimental Psychology</source>
            <year iso-8601-date="2013">2013</year>
            <volume>66</volume>
            <issue>8</issue>
            <pub-id pub-id-type="doi">10.1080/17470218.2013.800125</pub-id>
            <fpage>1467</fpage>
            <lpage>1485</lpage>
          </element-citation>
        </ref>
        <ref id="ref-burton2016a-nb-article">
          <element-citation publication-type="article-journal">
            <person-group person-group-type="author">
              <name>
                <surname>Burton</surname>
                <given-names>A. M.</given-names>
              </name>
              <name>
                <surname>Kramer</surname>
                <given-names>R. S. S.</given-names>
              </name>
              <name>
                <surname>Ritchie</surname>
                <given-names>K. L.</given-names>
              </name>
              <name>
                <surname>Jenkins</surname>
                <given-names>R.</given-names>
              </name>
            </person-group>
            <article-title>Identity from variation: Representations of faces derived from multiple instances</article-title>
            <source>Cognitive Science</source>
            <year iso-8601-date="2016">2016</year>
            <volume>40</volume>
            <issue>1</issue>
            <pub-id pub-id-type="doi">10.1111/cogs.12231</pub-id>
            <fpage>202</fpage>
            <lpage>223</lpage>
          </element-citation>
        </ref>
        <ref id="ref-burton2015a-nb-article">
          <element-citation publication-type="article-journal">
            <person-group person-group-type="author">
              <name>
                <surname>Burton</surname>
                <given-names>A. M.</given-names>
              </name>
              <name>
                <surname>Schweinberger</surname>
                <given-names>S. R.</given-names>
              </name>
              <name>
                <surname>Jenkins</surname>
                <given-names>R.</given-names>
              </name>
              <name>
                <surname>Kaufmann</surname>
                <given-names>J. M.</given-names>
              </name>
            </person-group>
            <article-title>Arguments against a configural processing account of familiar face recognition</article-title>
            <source>Perspectives on Psychological Science</source>
            <year iso-8601-date="2015">2015</year>
            <volume>10</volume>
            <issue>4</issue>
            <pub-id pub-id-type="doi">10.1177/1745691615583129</pub-id>
            <fpage>482</fpage>
            <lpage>496</lpage>
          </element-citation>
        </ref>
        <ref id="ref-caharel2014a-nb-article">
          <element-citation publication-type="article-journal">
            <person-group person-group-type="author">
              <name>
                <surname>Caharel</surname>
                <given-names>S.</given-names>
              </name>
              <name>
                <surname>Ramon</surname>
                <given-names>M.</given-names>
              </name>
              <name>
                <surname>Rossion</surname>
                <given-names>B.</given-names>
              </name>
            </person-group>
            <article-title>Face familiarity decisions take 200 msec in the human brain: Electrophysiological evidence from a go/no-go speeded task</article-title>
            <source>Journal of Cognitive Neuroscience</source>
            <year iso-8601-date="2014">2014</year>
            <volume>26</volume>
            <issue>1</issue>
            <pub-id pub-id-type="doi">10.1162/jocn\_a\_00451</pub-id>
            <fpage>81</fpage>
            <lpage>95</lpage>
          </element-citation>
        </ref>
        <ref id="ref-caharel2021a-nb-article">
          <element-citation publication-type="article-journal">
            <person-group person-group-type="author">
              <name>
                <surname>Caharel</surname>
                <given-names>S.</given-names>
              </name>
              <name>
                <surname>Rossion</surname>
                <given-names>B.</given-names>
              </name>
            </person-group>
            <article-title>The N170 is sensitive to long-term (personal) familiarity of a face identity</article-title>
            <source>Neuroscience</source>
            <year iso-8601-date="2021">2021</year>
            <volume>458</volume>
            <pub-id pub-id-type="doi">10.1016/j.neuroscience.2020.12.036</pub-id>
            <fpage>244</fpage>
            <lpage>255</lpage>
          </element-citation>
        </ref>
        <ref id="ref-campbell2020a-nb-article">
          <element-citation publication-type="article-journal">
            <person-group person-group-type="author">
              <name>
                <surname>Campbell</surname>
                <given-names>A.</given-names>
              </name>
              <name>
                <surname>Louw</surname>
                <given-names>R.</given-names>
              </name>
              <name>
                <surname>Michniak</surname>
                <given-names>E.</given-names>
              </name>
              <name>
                <surname>Tanaka</surname>
                <given-names>J. W.</given-names>
              </name>
            </person-group>
            <article-title>Identity-specific neural responses to three categories of face familiarity (own, friend, stranger) using fast periodic visual stimulation</article-title>
            <source>Neuropsychologia</source>
            <year iso-8601-date="2020">2020</year>
            <volume>141</volume>
            <fpage>1</fpage>
            <lpage>12</lpage>
          </element-citation>
        </ref>
        <ref id="ref-campbell2021a-nb-article">
          <element-citation publication-type="article-journal">
            <person-group person-group-type="author">
              <name>
                <surname>Campbell</surname>
                <given-names>A.</given-names>
              </name>
              <name>
                <surname>Tanaka</surname>
                <given-names>J. W.</given-names>
              </name>
            </person-group>
            <article-title>When a stranger becomes a friend: Measuring the neural correlates of real-world face familiarisation</article-title>
            <source>Visual Cognition</source>
            <year iso-8601-date="2021">2021</year>
            <volume>29</volume>
            <issue>10</issue>
            <pub-id pub-id-type="doi">10.1080/13506285.2021.20002993</pub-id>
            <fpage>689</fpage>
            <lpage>707</lpage>
          </element-citation>
        </ref>
        <ref id="ref-cloutier2011a-nb-article">
          <element-citation publication-type="article-journal">
            <person-group person-group-type="author">
              <name>
                <surname>Cloutier</surname>
                <given-names>J.</given-names>
              </name>
              <name>
                <surname>Kelley</surname>
                <given-names>W. M.</given-names>
              </name>
              <name>
                <surname>Heatherton</surname>
                <given-names>T. F.</given-names>
              </name>
            </person-group>
            <article-title>The influence of perceptual and knowledge-based familiarity on the neural substrates of face perception</article-title>
            <source>Social Neuroscience</source>
            <year iso-8601-date="2011">2011</year>
            <volume>6</volume>
            <issue>1</issue>
            <pub-id pub-id-type="doi">10.1080/17470911003693622</pub-id>
            <fpage>63</fpage>
            <lpage>75</lpage>
          </element-citation>
        </ref>
        <ref id="ref-collins2018a-nb-article">
          <element-citation publication-type="article-journal">
            <person-group person-group-type="author">
              <name>
                <surname>Collins</surname>
                <given-names>E.</given-names>
              </name>
              <name>
                <surname>Robinson</surname>
                <given-names>A. K.</given-names>
              </name>
              <name>
                <surname>Berrmann</surname>
                <given-names>M.</given-names>
              </name>
            </person-group>
            <article-title>Distinct neural processes for the perception of familiar versus unfamiliar faces along the visual hierarchy revealed by EEG</article-title>
            <source>NeuroImage</source>
            <year iso-8601-date="2018">2018</year>
            <volume>181</volume>
            <pub-id pub-id-type="doi">10.1016/j.neuroimage.2018.06.080</pub-id>
            <fpage>120</fpage>
            <lpage>131</lpage>
          </element-citation>
        </ref>
        <ref id="ref-dobs2019a-nb-article">
          <element-citation publication-type="article-journal">
            <person-group person-group-type="author">
              <name>
                <surname>Dobs</surname>
                <given-names>K.</given-names>
              </name>
              <name>
                <surname>Isik</surname>
                <given-names>L.</given-names>
              </name>
              <name>
                <surname>Pantazis</surname>
                <given-names>D.</given-names>
              </name>
              <name>
                <surname>Kanwisher</surname>
                <given-names>N.</given-names>
              </name>
            </person-group>
            <article-title>How face perception unfolds over time</article-title>
            <source>Nature Communications</source>
            <year iso-8601-date="2019">2019</year>
            <volume>10</volume>
            <issue>1</issue>
            <pub-id pub-id-type="doi">10.1038/s41467-019-09239-1</pub-id>
            <fpage>1</fpage>
            <lpage>10</lpage>
          </element-citation>
        </ref>
        <ref id="ref-dowsett2016a-nb-article">
          <element-citation publication-type="article-journal">
            <person-group person-group-type="author">
              <name>
                <surname>Dowsett</surname>
                <given-names>A. J.</given-names>
              </name>
              <name>
                <surname>Sandford</surname>
                <given-names>A.</given-names>
              </name>
              <name>
                <surname>Burton</surname>
                <given-names>A. M.</given-names>
              </name>
            </person-group>
            <article-title>Face learning with multiple images leads to fast acquisition of familiarity for specific individuals</article-title>
            <source>The Quarterly Journal of Experimental Psychology</source>
            <year iso-8601-date="2016">2016</year>
            <volume>69</volume>
            <issue>1</issue>
            <pub-id pub-id-type="doi">10.1080/17470218.2015.1017513</pub-id>
            <fpage>1</fpage>
            <lpage>10</lpage>
          </element-citation>
        </ref>
        <ref id="ref-faul2009a-nb-article">
          <element-citation publication-type="article-journal">
            <person-group person-group-type="author">
              <name>
                <surname>Faul</surname>
                <given-names>F.</given-names>
              </name>
              <name>
                <surname>Erdfelder</surname>
                <given-names>E.</given-names>
              </name>
              <name>
                <surname>Buchner</surname>
                <given-names>A.</given-names>
              </name>
              <name>
                <surname>Lang</surname>
                <given-names>A. G.</given-names>
              </name>
            </person-group>
            <article-title>Statistical power analyses using g*power 3.1: Tests for correlation and regression analyses</article-title>
            <source>Behaviour Research Methods</source>
            <year iso-8601-date="2009">2009</year>
            <volume>41</volume>
            <pub-id pub-id-type="doi">10.3758/BRM.41.4.1149</pub-id>
            <fpage>1149</fpage>
            <lpage>1160</lpage>
          </element-citation>
        </ref>
        <ref id="ref-felisberti2014a-nb-article">
          <element-citation publication-type="article-journal">
            <person-group person-group-type="author">
              <name>
                <surname>Felisberti</surname>
                <given-names>F. M.</given-names>
              </name>
              <name>
                <surname>Musholt</surname>
                <given-names>K.</given-names>
              </name>
            </person-group>
            <article-title>Self-face perception: Individual differences and discrepancies associated with mental self-face representation, attractiveness and self-esteem</article-title>
            <source>Psychology &amp; Neuroscience</source>
            <year iso-8601-date="2014">2014</year>
            <volume>7</volume>
            <issue>2</issue>
            <pub-id pub-id-type="doi">10.3922/j.psns.2014.013</pub-id>
            <fpage>65</fpage>
            <lpage>72</lpage>
          </element-citation>
        </ref>
        <ref id="ref-gerlach2022a-nb-article">
          <element-citation publication-type="article-journal">
            <person-group person-group-type="author">
              <name>
                <surname>Gerlach</surname>
                <given-names>C.</given-names>
              </name>
              <name>
                <surname>Mogensen</surname>
                <given-names>E.</given-names>
              </name>
            </person-group>
            <article-title>The face inversion effect does not provide a pure measure of holistic face processing</article-title>
            <source>Behaviour Research Methods</source>
            <year iso-8601-date="2022">2022</year>
            <volume>1-12</volume>
            <pub-id pub-id-type="doi">10.3758/s13428-022-02054-5</pub-id>
          </element-citation>
        </ref>
        <ref id="ref-hancock2000a-nb-article">
          <element-citation publication-type="article-journal">
            <person-group person-group-type="author">
              <name>
                <surname>Hancock</surname>
                <given-names>P. J.</given-names>
              </name>
              <name>
                <surname>Bruce</surname>
                <given-names>V.</given-names>
              </name>
              <name>
                <surname>Burton</surname>
                <given-names>A. M.</given-names>
              </name>
            </person-group>
            <article-title>Recognition of unfamiliar faces</article-title>
            <source>Trends in Cognitive Sciences</source>
            <year iso-8601-date="2000">2000</year>
            <volume>4</volume>
            <issue>9</issue>
            <pub-id pub-id-type="doi">10.1016/s1364-6613(00)01519-9</pub-id>
            <fpage>330</fpage>
            <lpage>337</lpage>
          </element-citation>
        </ref>
        <ref id="ref-herlitz2013a-nb-article">
          <element-citation publication-type="article-journal">
            <person-group person-group-type="author">
              <name>
                <surname>Herlitz</surname>
                <given-names>A.</given-names>
              </name>
              <name>
                <surname>Lovén</surname>
                <given-names>J.</given-names>
              </name>
            </person-group>
            <article-title>Sex differences and the own-gender bias in face recognition: A meta-analytic review</article-title>
            <source>Visual Cognition</source>
            <year iso-8601-date="2013">2013</year>
            <volume>21</volume>
            <issue>9-10</issue>
            <pub-id pub-id-type="doi">10.1080/13506285.2013.823140</pub-id>
            <fpage>1306</fpage>
            <lpage>1336</lpage>
          </element-citation>
        </ref>
        <ref id="ref-jenkins2011a-nb-article">
          <element-citation publication-type="article-journal">
            <person-group person-group-type="author">
              <name>
                <surname>Jenkins</surname>
                <given-names>R.</given-names>
              </name>
              <name>
                <surname>White</surname>
                <given-names>D.</given-names>
              </name>
              <name>
                <surname>Montfort</surname>
                <given-names>X.</given-names>
              </name>
              <name>
                <surname>Burton</surname>
                <given-names>A. M.</given-names>
              </name>
            </person-group>
            <article-title>Variability in photos of the same face</article-title>
            <source>Cognition</source>
            <year iso-8601-date="2011">2011</year>
            <volume>121</volume>
            <pub-id pub-id-type="doi">10.1016/j.cognition.2011.08.001</pub-id>
            <fpage>313</fpage>
            <lpage>323</lpage>
          </element-citation>
        </ref>
        <ref id="ref-jenkins2018a-nb-article">
          <element-citation publication-type="article-journal">
            <person-group person-group-type="author">
              <name>
                <surname>Jenkins</surname>
                <given-names>R.</given-names>
              </name>
              <name>
                <surname>Dowsett</surname>
                <given-names>A. J.</given-names>
              </name>
              <name>
                <surname>Burton</surname>
                <given-names>A. M.</given-names>
              </name>
            </person-group>
            <article-title>How many faces do people know? Proceedings of the royal society</article-title>
            <source>B, Biological Sciences</source>
            <year iso-8601-date="2018">2018</year>
            <volume>285</volume>
            <pub-id pub-id-type="doi">10.1098/rspb.2018.1319</pub-id>
            <fpage>20181319</fpage>
            <lpage/>
          </element-citation>
        </ref>
        <ref id="ref-karimi-rouzbahani2021a-nb-article">
          <element-citation publication-type="article-journal">
            <person-group person-group-type="author">
              <name>
                <surname>Karimi-Rouzbahani</surname>
                <given-names>H.</given-names>
              </name>
              <name>
                <surname>Ramezani</surname>
                <given-names>F.</given-names>
              </name>
              <name>
                <surname>Woolgar</surname>
                <given-names>A.</given-names>
              </name>
              <name>
                <surname>Rich</surname>
                <given-names>A.</given-names>
              </name>
              <name>
                <surname>Ghodrati</surname>
                <given-names>M.</given-names>
              </name>
            </person-group>
            <article-title>Perceptual difficulty modulates the direction of information flow in familiar face recognition</article-title>
            <source>NeuroImage</source>
            <year iso-8601-date="2021">2021</year>
            <volume>233</volume>
            <pub-id pub-id-type="doi">10.1016/j.neuroimage.2021.117896</pub-id>
            <fpage>1</fpage>
            <lpage>15</lpage>
          </element-citation>
        </ref>
        <ref id="ref-keyes2012a-nb-article">
          <element-citation publication-type="article-journal">
            <person-group person-group-type="author">
              <name>
                <surname>Keyes</surname>
                <given-names>H.</given-names>
              </name>
            </person-group>
            <article-title>Categorical perception effects for facial identity in robustly represented familiar and self-faces: The role of configural and featural information</article-title>
            <source>The Quarterly Journal of Experimental Psychology</source>
            <year iso-8601-date="2012">2012</year>
            <volume>65</volume>
            <issue>4</issue>
            <pub-id pub-id-type="doi">10.1080/17470218.2011.636822</pub-id>
            <fpage>760</fpage>
            <lpage>772</lpage>
          </element-citation>
        </ref>
        <ref id="ref-keyes2010a-nb-article">
          <element-citation publication-type="article-journal">
            <person-group person-group-type="author">
              <name>
                <surname>Keyes</surname>
                <given-names>H.</given-names>
              </name>
              <name>
                <surname>Brady</surname>
                <given-names>N.</given-names>
              </name>
            </person-group>
            <article-title>Self-face recognition is characterised by “bi-lateral gain” and by faster, more accurate performance which persists when faces are inverted</article-title>
            <source>The Quarterly Journal of Experimental Psychology</source>
            <year iso-8601-date="2010">2010</year>
            <volume>63</volume>
            <issue>5</issue>
            <pub-id pub-id-type="doi">10.1080/17470211003611264</pub-id>
            <fpage>840</fpage>
            <lpage>847</lpage>
          </element-citation>
        </ref>
        <ref id="ref-kloth2006a-nb-article">
          <element-citation publication-type="article-journal">
            <person-group person-group-type="author">
              <name>
                <surname>Kloth</surname>
                <given-names>N.</given-names>
              </name>
              <name>
                <surname>Dobel</surname>
                <given-names>C.</given-names>
              </name>
              <name>
                <surname>Schweinberger</surname>
                <given-names>S. R.</given-names>
              </name>
              <name>
                <surname>Zwitserlood</surname>
                <given-names>P.</given-names>
              </name>
              <name>
                <surname>Bölte</surname>
                <given-names>J.</given-names>
              </name>
              <name>
                <surname>Junghöfer</surname>
                <given-names>M.</given-names>
              </name>
            </person-group>
            <article-title>Effects of personal familiarity on early neuromagnetic correlates of face perception</article-title>
            <source>European Journal of Neuroscience</source>
            <year iso-8601-date="2006">2006</year>
            <volume>24</volume>
            <pub-id pub-id-type="doi">10.1111/j.1460-9568.2006.05211.x</pub-id>
            <fpage>3317</fpage>
            <lpage>3321</lpage>
          </element-citation>
        </ref>
        <ref id="ref-kramer2017a-nb-article">
          <element-citation publication-type="article-journal">
            <person-group person-group-type="author">
              <name>
                <surname>Kramer</surname>
                <given-names>R. S. S.</given-names>
              </name>
              <name>
                <surname>Young</surname>
                <given-names>A. W.</given-names>
              </name>
              <name>
                <surname>Day</surname>
                <given-names>MgG</given-names>
              </name>
              <name>
                <surname>Burton</surname>
                <given-names>A. M.</given-names>
              </name>
            </person-group>
            <article-title>Robust social categorization emerges from learning the identities of very few faces</article-title>
            <source>Psychological Review</source>
            <year iso-8601-date="2017">2017</year>
            <volume>24</volume>
            <issue>2</issue>
            <pub-id pub-id-type="doi">10.1037/rev000048</pub-id>
            <fpage>115</fpage>
            <lpage>129</lpage>
          </element-citation>
        </ref>
        <ref id="ref-kramer2018a-nb-article">
          <element-citation publication-type="article-journal">
            <person-group person-group-type="author">
              <name>
                <surname>Kramer</surname>
                <given-names>R. S. S.</given-names>
              </name>
              <name>
                <surname>Young</surname>
                <given-names>A. W.</given-names>
              </name>
              <name>
                <surname>Burton</surname>
                <given-names>A. M.</given-names>
              </name>
            </person-group>
            <article-title>Understanding face familiarity</article-title>
            <source>Cognition</source>
            <year iso-8601-date="2018">2018</year>
            <volume>172</volume>
            <pub-id pub-id-type="doi">10.1016/j.cognition.2017.12.005</pub-id>
            <fpage>46</fpage>
            <lpage>58</lpage>
          </element-citation>
        </ref>
        <ref id="ref-lee2022a-nb-article">
          <element-citation publication-type="article-journal">
            <person-group person-group-type="author">
              <name>
                <surname>Lee</surname>
                <given-names>J. K. W.</given-names>
              </name>
              <name>
                <surname>Janssen</surname>
                <given-names>S. M. J.</given-names>
              </name>
              <name>
                <surname>Estudillo</surname>
                <given-names>A. J.</given-names>
              </name>
            </person-group>
            <article-title>A featural account for own-face processing? Looking for support from face inversion, composite face, and part-whole tasks</article-title>
            <source>i-Perception</source>
            <year iso-8601-date="2022">2022</year>
            <volume>13</volume>
            <issue>4</issue>
            <pub-id pub-id-type="doi">10.1177/20416695221111409</pub-id>
            <fpage>1</fpage>
            <lpage>22</lpage>
          </element-citation>
        </ref>
        <ref id="ref-liccione2014a-nb-article">
          <element-citation publication-type="article-journal">
            <person-group person-group-type="author">
              <name>
                <surname>Liccione</surname>
                <given-names>D.</given-names>
              </name>
              <name>
                <surname>Moruzzi</surname>
                <given-names>S.</given-names>
              </name>
              <name>
                <surname>Rossi</surname>
                <given-names>F.</given-names>
              </name>
              <name>
                <surname>Manganaro</surname>
                <given-names>A.</given-names>
              </name>
              <name>
                <surname>Porta</surname>
                <given-names>M.</given-names>
              </name>
              <name>
                <surname>Nugrahaningsih</surname>
                <given-names>N.</given-names>
              </name>
              <name>
                <surname>Caserio</surname>
                <given-names>V.</given-names>
              </name>
              <name>
                <surname>Allegri</surname>
                <given-names>N.</given-names>
              </name>
            </person-group>
            <article-title>Familiarity is not notoriety</article-title>
            <source>Frontiers in Human Neuroscience</source>
            <year iso-8601-date="2014">2014</year>
            <volume>8</volume>
            <pub-id pub-id-type="doi">10.3389/fnhum.2014.00672</pub-id>
            <fpage>672</fpage>
            <lpage>672</lpage>
          </element-citation>
        </ref>
        <ref id="ref-lov2011a-nb-article">
          <element-citation publication-type="article-journal">
            <person-group person-group-type="author">
              <name>
                <surname>Lovén</surname>
                <given-names>J.</given-names>
              </name>
              <name>
                <surname>Herlitz</surname>
                <given-names>A.</given-names>
              </name>
              <name>
                <surname>Rehnman</surname>
                <given-names>J.</given-names>
              </name>
            </person-group>
            <article-title>Women’s own-gender bias in face recognition memory</article-title>
            <source>Experimental Psychology</source>
            <year iso-8601-date="2011">2011</year>
            <volume>58</volume>
            <issue>4</issue>
            <pub-id pub-id-type="doi">10.1027/1618-3169/a000100</pub-id>
            <fpage>333</fpage>
            <lpage>340</lpage>
          </element-citation>
        </ref>
        <ref id="ref-megraya2006a-nb-article">
          <element-citation publication-type="article-journal">
            <person-group person-group-type="author">
              <name>
                <surname>Megreya</surname>
                <given-names>A. M.</given-names>
              </name>
              <name>
                <surname>Burton</surname>
                <given-names>A. M.</given-names>
              </name>
            </person-group>
            <article-title>Unfamiliar faces are not faces: Evidence from a matching task</article-title>
            <source>Memory &amp; Cognition</source>
            <year iso-8601-date="2006">2006</year>
            <volume>34</volume>
            <issue>4</issue>
            <pub-id pub-id-type="doi">10.3758/BF03193433</pub-id>
            <fpage>865</fpage>
            <lpage>876</lpage>
          </element-citation>
        </ref>
        <ref id="ref-megraya2008a-nb-article">
          <element-citation publication-type="article-journal">
            <person-group person-group-type="author">
              <name>
                <surname>Megreya</surname>
                <given-names>A. M.</given-names>
              </name>
              <name>
                <surname>Burton</surname>
                <given-names>A. M.</given-names>
              </name>
            </person-group>
            <article-title>Matching faces to photographs: Poor performance in eyewitness memory (without the memory)</article-title>
            <source>Journal of Experimental Psychology: Applied</source>
            <year iso-8601-date="2008">2008</year>
            <volume>14</volume>
            <issue>4</issue>
            <pub-id pub-id-type="doi">10.1037/a0013464</pub-id>
            <fpage>364</fpage>
            <lpage>372</lpage>
          </element-citation>
        </ref>
        <ref id="ref-mishra2019a-nb-article">
          <element-citation publication-type="article-journal">
            <person-group person-group-type="author">
              <name>
                <surname>Mishra</surname>
                <given-names>M. V.</given-names>
              </name>
              <name>
                <surname>Likitlersuang</surname>
                <given-names>J.</given-names>
              </name>
              <name>
                <surname>Wilmer</surname>
                <given-names>J.</given-names>
              </name>
              <name>
                <surname>Cohan</surname>
                <given-names>S.</given-names>
              </name>
              <name>
                <surname>Germine</surname>
                <given-names>L.</given-names>
              </name>
              <name>
                <surname>DeGutis</surname>
                <given-names>J. M.</given-names>
              </name>
            </person-group>
            <article-title>Gender differences in familiar face recognition and the influence of sociocultural gender inequality</article-title>
            <source>Scientific Reports</source>
            <year iso-8601-date="2019">2019</year>
            <volume>9</volume>
            <pub-id pub-id-type="doi">10.1038/s41598-019-54074-5</pub-id>
            <fpage>1</fpage>
            <lpage>11</lpage>
          </element-citation>
        </ref>
        <ref id="ref-mohr2018a-nb-article">
          <element-citation publication-type="article-journal">
            <person-group person-group-type="author">
              <name>
                <surname>Mohr</surname>
                <given-names>S.</given-names>
              </name>
              <name>
                <surname>Wang</surname>
                <given-names>A.</given-names>
              </name>
              <name>
                <surname>Engell</surname>
                <given-names>A. D.</given-names>
              </name>
            </person-group>
            <article-title>Early identity recognition of familiar faces is not dependent on holistic processing</article-title>
            <source>Social Cognitive and Affective Neuroscience</source>
            <year iso-8601-date="2018">2018</year>
            <volume>13</volume>
            <issue>10</issue>
            <pub-id pub-id-type="doi">10.1093/scan/nsy079</pub-id>
            <fpage>1019</fpage>
            <lpage>1027</lpage>
          </element-citation>
        </ref>
        <ref id="ref-murphy2015a-nb-article">
          <element-citation publication-type="article-journal">
            <person-group person-group-type="author">
              <name>
                <surname>Murphy</surname>
                <given-names>J.</given-names>
              </name>
              <name>
                <surname>Ipser</surname>
                <given-names>A.</given-names>
              </name>
              <name>
                <surname>Gaigg</surname>
                <given-names>S. B.</given-names>
              </name>
              <name>
                <surname>Cook</surname>
                <given-names>R.</given-names>
              </name>
            </person-group>
            <article-title>Exemplar variance supports robust learning of facial identity</article-title>
            <source>Journal of Experimental Psychology: Human Perception and Performance</source>
            <year iso-8601-date="2015">2015</year>
            <volume>41</volume>
            <issue>3</issue>
            <pub-id pub-id-type="doi">10.1037/xhp0000049</pub-id>
            <fpage>577</fpage>
            <lpage>581</lpage>
          </element-citation>
        </ref>
        <ref id="ref-oliveira2015a-nb-article">
          <element-citation publication-type="article-journal">
            <person-group person-group-type="author">
              <name>
                <surname>Oliveira</surname>
                <given-names>E. H.</given-names>
              </name>
              <name>
                <surname>Esteves</surname>
                <given-names>F.</given-names>
              </name>
              <name>
                <surname>Carvalho</surname>
                <given-names>H.</given-names>
              </name>
            </person-group>
            <article-title>Clinical profiles of stigma experiences, self-esteem and social relationships among people with schizophrenia, depressive, and bipolar disorders</article-title>
            <source>Psychiatry Research</source>
            <year iso-8601-date="2015">2015</year>
            <volume>229</volume>
            <issue>1-2</issue>
            <pub-id pub-id-type="doi">10.1016/j.psychres.2015.07.047</pub-id>
            <fpage>167</fpage>
            <lpage>173</lpage>
          </element-citation>
        </ref>
        <ref id="ref-oruc2019a-nb-article">
          <element-citation publication-type="article-journal">
            <person-group person-group-type="author">
              <name>
                <surname>Oruc</surname>
                <given-names>I.</given-names>
              </name>
              <name>
                <surname>Shafai</surname>
                <given-names>F.</given-names>
              </name>
              <name>
                <surname>Murthy</surname>
                <given-names>S.</given-names>
              </name>
              <name>
                <surname>Lages</surname>
                <given-names>P.</given-names>
              </name>
              <name>
                <surname>Ton</surname>
                <given-names>T.</given-names>
              </name>
            </person-group>
            <article-title>The adult face-diet: A naturalistic observation study</article-title>
            <source>Vision Research</source>
            <year iso-8601-date="2019">2019</year>
            <volume>157</volume>
            <pub-id pub-id-type="doi">10.1016/j.visres.2018.01.001</pub-id>
            <fpage>222</fpage>
            <lpage>229</lpage>
          </element-citation>
        </ref>
        <ref id="ref-pachai2017a-nb-article">
          <element-citation publication-type="article-journal">
            <person-group person-group-type="author">
              <name>
                <surname>Pachai</surname>
                <given-names>M. V.</given-names>
              </name>
              <name>
                <surname>Sekular</surname>
                <given-names>A. B.</given-names>
              </name>
              <name>
                <surname>Bennett</surname>
                <given-names>P. J.</given-names>
              </name>
              <name>
                <surname>Schyns</surname>
                <given-names>P. G.</given-names>
              </name>
              <name>
                <surname>Ramon</surname>
                <given-names>M.</given-names>
              </name>
            </person-group>
            <article-title>Personal familiarity enhances sensitivity to horizontal structure during processing of face identity</article-title>
            <source>Journal of Vision</source>
            <year iso-8601-date="2017">2017</year>
            <volume>17</volume>
            <issue>6</issue>
            <pub-id pub-id-type="doi">10.1167/17.6.5</pub-id>
            <fpage>1</fpage>
            <lpage>11</lpage>
          </element-citation>
        </ref>
        <ref id="ref-platek2009a-nb-article">
          <element-citation publication-type="article-journal">
            <person-group person-group-type="author">
              <name>
                <surname>Platek</surname>
                <given-names>S. M.</given-names>
              </name>
              <name>
                <surname>Kemp</surname>
                <given-names>S. M.</given-names>
              </name>
            </person-group>
            <article-title>Is family special to the brain? An event-related fMRI study of familiar, familial, and self-face recognition</article-title>
            <source>Neuropsychologia</source>
            <year iso-8601-date="2009">2009</year>
            <volume>47</volume>
            <pub-id pub-id-type="doi">10.1016/j.neuropsychologia.2008.12.027</pub-id>
            <fpage>849</fpage>
            <lpage>858</lpage>
          </element-citation>
        </ref>
        <ref id="ref-quek2021a-nb-article">
          <element-citation publication-type="article-journal">
            <person-group person-group-type="author">
              <name>
                <surname>Quek</surname>
                <given-names>G. L.</given-names>
              </name>
              <name>
                <surname>Rossion</surname>
                <given-names>B.</given-names>
              </name>
              <name>
                <surname>Liu-Shuang</surname>
                <given-names>J.</given-names>
              </name>
            </person-group>
            <article-title>Critical information thresholds underlying generic and familiar face categorisation at the same face encounter</article-title>
            <source>NeuroImage</source>
            <year iso-8601-date="2021">2021</year>
            <volume>243</volume>
            <pub-id pub-id-type="doi">10.1016/j.neuroimage.2021.118481</pub-id>
            <fpage>1</fpage>
            <lpage>14</lpage>
          </element-citation>
        </ref>
        <ref id="ref-ramon2011a-nb-article">
          <element-citation publication-type="article-journal">
            <person-group person-group-type="author">
              <name>
                <surname>Ramon</surname>
                <given-names>M.</given-names>
              </name>
              <name>
                <surname>Caharel</surname>
                <given-names>S.</given-names>
              </name>
              <name>
                <surname>Rossion</surname>
                <given-names>B.</given-names>
              </name>
            </person-group>
            <article-title>The speed of recognition of personally familiar faces</article-title>
            <source>Perception</source>
            <year iso-8601-date="2011">2011</year>
            <volume>40</volume>
            <pub-id pub-id-type="doi">10.1068/p6794</pub-id>
            <fpage>437</fpage>
            <lpage>449</lpage>
          </element-citation>
        </ref>
        <ref id="ref-ramon2016a-nb-article">
          <element-citation publication-type="article-journal">
            <person-group person-group-type="author">
              <name>
                <surname>Ramon</surname>
                <given-names>M.</given-names>
              </name>
              <name>
                <surname>Belle</surname>
                <given-names>G. van</given-names>
              </name>
            </person-group>
            <article-title>Real-life experience with personally familiar faces enhances discrimination based on global information</article-title>
            <source>PeerJ</source>
            <year iso-8601-date="2016">2016</year>
            <volume>4</volume>
            <pub-id pub-id-type="doi">10.7717/peerj.1465</pub-id>
            <fpage>1</fpage>
            <lpage>13</lpage>
          </element-citation>
        </ref>
        <ref id="ref-ramon2017a-nb-article">
          <element-citation publication-type="article-journal">
            <person-group person-group-type="author">
              <name>
                <surname>Ramon</surname>
                <given-names>M.</given-names>
              </name>
              <name>
                <surname>Gobbini</surname>
                <given-names>M. I.</given-names>
              </name>
            </person-group>
            <article-title>Familiarity matters: A review on prioritized processing of personally familiar faces</article-title>
            <source>Visual Cognition</source>
            <year iso-8601-date="2017">2017</year>
            <volume>26</volume>
            <issue>3</issue>
            <pub-id pub-id-type="doi">10.1080/13506285.2017.1405134</pub-id>
            <fpage>179</fpage>
            <lpage>195</lpage>
          </element-citation>
        </ref>
        <ref id="ref-redfern2019a-nb-article">
          <element-citation publication-type="article-journal">
            <person-group person-group-type="author">
              <name>
                <surname>Redfern</surname>
                <given-names>A. S.</given-names>
              </name>
              <name>
                <surname>Benton</surname>
                <given-names>C. P.</given-names>
              </name>
            </person-group>
            <article-title>Representation of facial identity includes expression variability</article-title>
            <source>Vision Research</source>
            <year iso-8601-date="2019">2019</year>
            <volume>157</volume>
            <pub-id pub-id-type="doi">10.1016/j.visres.2018.05.004</pub-id>
            <fpage>123</fpage>
            <lpage>131</lpage>
          </element-citation>
        </ref>
        <ref id="ref-rhodes2012a-nb-article">
          <element-citation publication-type="article-journal">
            <person-group person-group-type="author">
              <name>
                <surname>Rhodes</surname>
                <given-names>M. G.</given-names>
              </name>
              <name>
                <surname>Anastasi</surname>
                <given-names>J. S.</given-names>
              </name>
            </person-group>
            <article-title>The own-age bias in face recognition: A meta-analytic and theoretical view</article-title>
            <source>Psychological Bulletin</source>
            <year iso-8601-date="2012">2012</year>
            <volume>138</volume>
            <issue>1</issue>
            <pub-id pub-id-type="doi">10.1037/a0025750</pub-id>
            <fpage>146</fpage>
            <lpage>174</lpage>
          </element-citation>
        </ref>
        <ref id="ref-rooney2012a-nb-article">
          <element-citation publication-type="article-journal">
            <person-group person-group-type="author">
              <name>
                <surname>Rooney</surname>
                <given-names>B.</given-names>
              </name>
              <name>
                <surname>Keyes</surname>
                <given-names>H.</given-names>
              </name>
              <name>
                <surname>Brady</surname>
                <given-names>N.</given-names>
              </name>
            </person-group>
            <article-title>Shared or separate mechanisms for self-face and other-face processing? Evidence from adaptation</article-title>
            <source>Frontiers in Psychology</source>
            <year iso-8601-date="2012">2012</year>
            <volume>3</volume>
            <pub-id pub-id-type="doi">https://doi.org.10.3389.fpsyg.2012.00066</pub-id>
            <fpage>1</fpage>
            <lpage>9</lpage>
          </element-citation>
        </ref>
        <ref id="ref-sandford2014a-nb-article">
          <element-citation publication-type="article-journal">
            <person-group person-group-type="author">
              <name>
                <surname>Sandford</surname>
                <given-names>A.</given-names>
              </name>
              <name>
                <surname>Burton</surname>
                <given-names>A. M.</given-names>
              </name>
            </person-group>
            <article-title>Tolerance for distorted faces: Challenges to a configural processing account of familiar face recognition</article-title>
            <source>Cognition</source>
            <year iso-8601-date="2014">2014</year>
            <volume>132</volume>
            <issue>3</issue>
            <pub-id pub-id-type="doi">10.1016/j.cognition.2014.04.005</pub-id>
            <fpage>262</fpage>
            <lpage>268</lpage>
          </element-citation>
        </ref>
        <ref id="ref-schwartz2016a-nb-article">
          <element-citation publication-type="article-journal">
            <person-group person-group-type="author">
              <name>
                <surname>Schwartz</surname>
                <given-names>L.</given-names>
              </name>
              <name>
                <surname>Yovel</surname>
                <given-names>G.</given-names>
              </name>
            </person-group>
            <article-title>The roles of perceptual and conceptual information in face recognition</article-title>
            <source>Journal of Experimental Psychology: General</source>
            <year iso-8601-date="2016">2016</year>
            <volume>145</volume>
            <issue>11</issue>
            <pub-id pub-id-type="doi">10.1037/xge0000220</pub-id>
            <fpage>1493</fpage>
            <lpage>1511</lpage>
          </element-citation>
        </ref>
        <ref id="ref-schwartz2019a-nb-article">
          <element-citation publication-type="article-journal">
            <person-group person-group-type="author">
              <name>
                <surname>Schwartz</surname>
                <given-names>L.</given-names>
              </name>
              <name>
                <surname>Yovel</surname>
                <given-names>G.</given-names>
              </name>
            </person-group>
            <article-title>Learning faces as concepts rather than percepts improves face recognition</article-title>
            <source>Journal of Experimental Psychology: Learning, Memory, and Cognition</source>
            <year iso-8601-date="2019">2019</year>
            <volume>45</volume>
            <issue>10</issue>
            <pub-id pub-id-type="doi">10.1037/xlm0000673</pub-id>
            <fpage>1733</fpage>
            <lpage>1747</lpage>
          </element-citation>
        </ref>
        <ref id="ref-smith2016a-nb-article">
          <element-citation publication-type="article-journal">
            <person-group person-group-type="author">
              <name>
                <surname>Smith</surname>
                <given-names>M. L.</given-names>
              </name>
              <name>
                <surname>Volna</surname>
                <given-names>B.</given-names>
              </name>
              <name>
                <surname>Ewing</surname>
                <given-names>L.</given-names>
              </name>
            </person-group>
            <article-title>Distinct information critically distinguishes judgements of face familiarity and identity</article-title>
            <source>Journal of Experimental Psychology: Human Perception and Performance</source>
            <year iso-8601-date="2016">2016</year>
            <volume>42</volume>
            <issue>11</issue>
            <pub-id pub-id-type="doi">10.1037/xhp0000243</pub-id>
            <fpage>1770</fpage>
            <lpage>1779</lpage>
          </element-citation>
        </ref>
        <ref id="ref-taubert2011a-nb-article">
          <element-citation publication-type="article-journal">
            <person-group person-group-type="author">
              <name>
                <surname>Taubert</surname>
                <given-names>J.</given-names>
              </name>
              <name>
                <surname>Apthorp</surname>
                <given-names>D.</given-names>
              </name>
              <name>
                <surname>Aagten-Murphy</surname>
                <given-names>D.</given-names>
              </name>
              <name>
                <surname>Alais</surname>
                <given-names>D.</given-names>
              </name>
            </person-group>
            <article-title>The role of holistic processing in face perception: Evidence from the face inversion effect</article-title>
            <source>Vision Research</source>
            <year iso-8601-date="2011">2011</year>
            <volume>51</volume>
            <pub-id pub-id-type="doi">10.1016/j.visres.2011.04.002</pub-id>
            <fpage>1273</fpage>
            <lpage>1278</lpage>
          </element-citation>
        </ref>
        <ref id="ref-tong1999a-nb-article">
          <element-citation publication-type="article-journal">
            <person-group person-group-type="author">
              <name>
                <surname>Tong</surname>
                <given-names>F.</given-names>
              </name>
              <name>
                <surname>Nakayama</surname>
                <given-names>K.</given-names>
              </name>
            </person-group>
            <article-title>Robust representations for faces: Evidence from visual search</article-title>
            <source>Journal of Experimental Psychology: Human Perception and Performance</source>
            <year iso-8601-date="1999">1999</year>
            <volume>25</volume>
            <issue>4</issue>
            <pub-id pub-id-type="doi">10.1037//0096-1523.25.4.1016</pub-id>
            <fpage>1016</fpage>
            <lpage>1035</lpage>
          </element-citation>
        </ref>
        <ref id="ref-tottenham2009a-nb-article">
          <element-citation publication-type="article-journal">
            <person-group person-group-type="author">
              <name>
                <surname>Tottenham</surname>
                <given-names>N.</given-names>
              </name>
              <name>
                <surname>Tanaka</surname>
                <given-names>J. W.</given-names>
              </name>
              <name>
                <surname>Leon</surname>
                <given-names>A. C.</given-names>
              </name>
              <name>
                <surname>McCarry</surname>
                <given-names>T.</given-names>
              </name>
              <name>
                <surname>Nurse</surname>
                <given-names>M.</given-names>
              </name>
              <name>
                <surname>Hare</surname>
                <given-names>T. A.</given-names>
              </name>
              <name>
                <surname>Marcus</surname>
                <given-names>D. J.</given-names>
              </name>
              <name>
                <surname>Westerlund</surname>
                <given-names>A.</given-names>
              </name>
              <name>
                <surname>Casey</surname>
                <given-names>B. J.</given-names>
              </name>
              <name>
                <surname>Nelson</surname>
                <given-names>C.</given-names>
              </name>
            </person-group>
            <article-title>The NimStim set of facial expressions: Judgements from untrained research participants</article-title>
            <source>Psychiatry Research</source>
            <year iso-8601-date="2009">2009</year>
            <volume>168</volume>
            <issue>3</issue>
            <pub-id pub-id-type="doi">10.1016/j.psychres.2008.05.006</pub-id>
            <fpage>242</fpage>
            <lpage>249</lpage>
          </element-citation>
        </ref>
        <ref id="ref-tshidzumba2019a-nb-article">
          <element-citation publication-type="article-journal">
            <person-group person-group-type="author">
              <name>
                <surname>Tshidzumba</surname>
                <given-names>N. A.</given-names>
              </name>
            </person-group>
            <article-title>The selfie culture: Identity creation and status conferral on social media</article-title>
            <source>Gender &amp; Behaviour</source>
            <year iso-8601-date="2019">2019</year>
            <volume>17</volume>
            <issue>3</issue>
            <fpage>13577</fpage>
            <lpage>13584</lpage>
          </element-citation>
        </ref>
        <ref id="ref-oleggio2017a-nb-article">
          <element-citation publication-type="article-journal">
            <person-group person-group-type="author">
              <name>
                <surname>Oleggio Castello</surname>
                <given-names>M.</given-names>
              </name>
              <name>
                <surname>Wheeler</surname>
                <given-names>K. G.</given-names>
              </name>
              <name>
                <surname>Cipolli</surname>
                <given-names>C.</given-names>
              </name>
              <name>
                <surname>Gobbini</surname>
                <given-names>M. I.</given-names>
              </name>
              <name>
                <surname>Urgesi</surname>
                <given-names>C.</given-names>
              </name>
            </person-group>
            <article-title>Familiarity facilitates feature-based face processing</article-title>
            <source>PLoS One</source>
            <year iso-8601-date="2017">2017</year>
            <volume>12</volume>
            <issue>6</issue>
            <pub-id pub-id-type="doi">10.1371/journal.pone.0178895</pub-id>
            <fpage>1</fpage>
            <lpage>13</lpage>
          </element-citation>
        </ref>
        <ref id="ref-white2016a-nb-article">
          <element-citation publication-type="article-journal">
            <person-group person-group-type="author">
              <name>
                <surname>White</surname>
                <given-names>D.</given-names>
              </name>
              <name>
                <surname>Burton</surname>
                <given-names>A. L.</given-names>
              </name>
              <name>
                <surname>Kemp</surname>
                <given-names>R. I.</given-names>
              </name>
            </person-group>
            <article-title>Not looking yourself: The cost of self-selecting photographs for identity verification</article-title>
            <source>British Journal of Psychology</source>
            <year iso-8601-date="2016">2016</year>
            <volume>107</volume>
            <pub-id pub-id-type="doi">10.1111/bjop.12141</pub-id>
            <fpage>359</fpage>
            <lpage>373</lpage>
          </element-citation>
        </ref>
        <ref id="ref-wiese2019a-nb-article">
          <element-citation publication-type="article-journal">
            <person-group person-group-type="author">
              <name>
                <surname>Wiese</surname>
                <given-names>H.</given-names>
              </name>
              <name>
                <surname>Tüttenberg</surname>
                <given-names>S. C.</given-names>
              </name>
              <name>
                <surname>Ingram</surname>
                <given-names>B. T.</given-names>
              </name>
              <name>
                <surname>Chan</surname>
                <given-names>C. Y. X.</given-names>
              </name>
              <name>
                <surname>Gurbuz</surname>
                <given-names>Z.</given-names>
              </name>
              <name>
                <surname>Burton</surname>
                <given-names>A. M.</given-names>
              </name>
              <name>
                <surname>Young</surname>
                <given-names>A. W.</given-names>
              </name>
            </person-group>
            <article-title>A robust neural index of high face familiarity</article-title>
            <source>Psychological Science</source>
            <year iso-8601-date="2019">2019</year>
            <volume>30</volume>
            <issue>2</issue>
            <pub-id pub-id-type="doi">10.1177/0956797618813572</pub-id>
            <fpage>261</fpage>
            <lpage>272</lpage>
          </element-citation>
        </ref>
        <ref id="ref-wiese2021a-nb-article">
          <element-citation publication-type="article-journal">
            <person-group person-group-type="author">
              <name>
                <surname>Wiese</surname>
                <given-names>H.</given-names>
              </name>
              <name>
                <surname>Hobden</surname>
                <given-names>G.</given-names>
              </name>
              <name>
                <surname>Siilbek</surname>
                <given-names>E.</given-names>
              </name>
              <name>
                <surname>Martignac</surname>
                <given-names>V.</given-names>
              </name>
              <name>
                <surname>Flack</surname>
                <given-names>T. R.</given-names>
              </name>
              <name>
                <surname>Ritchie</surname>
                <given-names>K. L.</given-names>
              </name>
              <name>
                <surname>Young</surname>
                <given-names>A. W.</given-names>
              </name>
              <name>
                <surname>Burton</surname>
                <given-names>A. M.</given-names>
              </name>
            </person-group>
            <article-title>Familiarity is familiarity is familiarity: Event-related brain potentials reveal qualitatively similar representations of personally familiar and famous faces</article-title>
            <source>Journal of Experimental Psychology: Learning, Memory, and Cognition</source>
            <year iso-8601-date="2021">2021</year>
            <volume>48</volume>
            <issue>8</issue>
            <pub-id pub-id-type="doi">10.1037/xlm0001063</pub-id>
            <fpage>1144</fpage>
            <lpage>1164</lpage>
          </element-citation>
        </ref>
        <ref id="ref-yang2014a-nb-article">
          <element-citation publication-type="article-journal">
            <person-group person-group-type="author">
              <name>
                <surname>Yang</surname>
                <given-names>N.</given-names>
              </name>
              <name>
                <surname>Shafai</surname>
                <given-names>F.</given-names>
              </name>
              <name>
                <surname>Oruc</surname>
                <given-names>I.</given-names>
              </name>
            </person-group>
            <article-title>Size determines whether specialized expert processes are engaged for recognition of faces</article-title>
            <source>Journal of Vision</source>
            <year iso-8601-date="2014">2014</year>
            <volume>14</volume>
            <issue>8</issue>
            <pub-id pub-id-type="doi">10.1167/14.8.17</pub-id>
            <fpage>1</fpage>
            <lpage>12</lpage>
          </element-citation>
        </ref>
        <ref id="ref-young2017a-nb-article">
          <element-citation publication-type="article-journal">
            <person-group person-group-type="author">
              <name>
                <surname>Young</surname>
                <given-names>A. W.</given-names>
              </name>
              <name>
                <surname>Burton</surname>
                <given-names>A. M.</given-names>
              </name>
            </person-group>
            <article-title>Are we face experts?</article-title>
            <source>Trends in Cognitive Sciences</source>
            <year iso-8601-date="2017">2017</year>
            <volume>22</volume>
            <issue>2</issue>
            <pub-id pub-id-type="doi">10.1016/j.tics.2017.11.007</pub-id>
            <fpage>100</fpage>
            <lpage>110</lpage>
          </element-citation>
        </ref>
        <ref id="ref-zimmermann2019a-nb-article">
          <element-citation publication-type="article-journal">
            <person-group person-group-type="author">
              <name>
                <surname>Zimmermann</surname>
                <given-names>F. G. S.</given-names>
              </name>
              <name>
                <surname>Yan</surname>
                <given-names>X.</given-names>
              </name>
              <name>
                <surname>Rossion</surname>
                <given-names>B.</given-names>
              </name>
            </person-group>
            <article-title>An objective, sensitive and ecologically valid neural measure of rapid human individual face recognition</article-title>
            <source>Royal Society Open Science</source>
            <year iso-8601-date="2019">2019</year>
            <volume>6</volume>
            <pub-id pub-id-type="doi">10.1098/rsos.181904</pub-id>
            <fpage>181904</fpage>
            <lpage/>
          </element-citation>
        </ref>
      </ref-list>
    </back>
  </sub-article>
</article>
