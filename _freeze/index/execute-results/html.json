{
  "hash": "f68cd81a16bfea49232f309b51e00a45",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: Differences in the Perceptual Processing of Unfamiliar and Familiar Faces\nauthors:\n  - name: Kasey McGinness\n    affiliation: University of New England\n    roles: \n      - Conceptualization\n      - Investigation\n      - Formal Analysis\n      - Writing - original draft\n    corresponding: false\n  - name: Jessica Taubert\n    orcid: 0000-0002-6519-8068\n    affiliation: University of Queensland\n    roles: \n      - Conceptualization\n      - Methodology\n      - Writing - reviewing & editing\n    corresponding: false\n    \n  - name: Deborah Apthorp\n    orcid: 0000-0001-5785-024X\n    email: dapthorp@une.edu.au\n    affiliations: \n      - University of New England\n      - Australian National University\n    roles: \n      - Conceptualization\n      - Project administration\n      - Software\n      - Formal analysis\n      - Writing - reviewing & editing\n      - Visualization\n      - Supervision\n    corresponding: true\n    \nkeywords: \n  - Face perception\n  - Psychophysics \n  - Face inversion effect \n\nabstract: |\n  Evidence that familiar faces are processed differently from unfamiliar faces has important implications for our understanding of how we recognise the people around us. Although familiarity effects on face recognition performance have been extensively researched, the perceptual and cognitive processes that underlie these differences are comparatively unknown. Using a psychophysical staircase paradigm, we collected data from 28 female participants aged 18-65 years ($M = 43.1$, $SD = 12.7$) and probed perceptual processing by measuring the minimum amount of time required to recognise a previously seen face across three levels of familiarity (unfamiliar, familiar, and self). We also measured a second dependent variable, reaction time, which is thought to reflect both perceptual and cognitive processes. The results revealed that participants needed less time to recognise familiar faces compared to unfamiliar faces. Concomitantly, participants needed less time to respond when tasked with recognising faces compared to unfamiliar faces. As expected, inverted faces took longer to recognise than upright faces, but this effect was reduced for familiar and self-faces. Recognition times provide evidence for distinct perceptual processing based on level of familiarity and suggest that our ability to recognise familiar faces may be poorly characterised by current theories. Overall, the results emphasise the uniqueness of the self-face within the familiarity continuum, as all participants were able to recognise their own face significantly faster than other faces. In light of these results, it is clear that a full understanding of how face recognition is accomplished will require a better characterisation of how we respond to highly familiar faces.\n\nbibliography: selffaces.bib\ncsl: apa.csl\n\nformat:\n  html: default\n  docx: default\n  jats: default\n  plos-pdf:\n    keep-tex: true  \n---\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\nlibrary(readr)\nlibrary(tidyr)\nlibrary(reshape2)\n```\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\n\nAttaching package: 'reshape2'\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nThe following object is masked from 'package:tidyr':\n\n    smiths\n```\n\n\n:::\n\n```{.r .cell-code .hidden}\nlibrary(tidyverse)\n```\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ purrr     1.0.2\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.4.4     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     \n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors\n```\n\n\n:::\n\n```{.r .cell-code .hidden}\nlibrary(dplyr)\nlibrary(raincloudplots)\nlibrary (patchwork)\n\n#Define colors - unfamiliar\nunfamiliar_upright_col = '#FF3030'\nunfamiliar_inverted_col = \"#836FFF\"\n\n#Mentored Group Colors\nfamiliar_upright_col = '#EE2C2C'\nfamiliar_inverted_col = \"#6959CD\"\n\n#Control Group Colors\nself_upright_col = '#CD2626'\nself_inverted_col = \"#473C8B\"\n\nMean_Frames <- read_csv(\"Mean_Frames_Familiar_Faces_Filtered.csv\")\n```\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nRows: 28 Columns: 8\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (1): Participant\ndbl (7): Unfamiliar_Upright, Unfamiliar_Inverted, Familiar_Upright, Familiar...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n```\n\n\n:::\n\n```{.r .cell-code .hidden}\nMean_Frames_long <- melt(Mean_Frames, \n                         # ID variables - all the variables to keep but not split apart on\n                         id.vars=c(\"Participant\", \"Age\"),\n                         # The source columns\n                         measure.vars=c(\"Unfamiliar_Upright\", \"Unfamiliar_Inverted\", \n                                        \"Familiar_Upright\", \"Familiar_Inverted\", \n                                        \"Self_Upright\", \"Self_Inverted\"),\n                         # Name of the destination column that will identify the original\n                         # column that the measurement came from\n                         variable.name=\"Condition\",\n                         value.name=\"Mean_N_Frames\"               \n                         \n                         )\n\nMean_Frames_long <- Mean_Frames_long %>%\n  mutate(Orientation = case_when(Condition == 'Unfamiliar_Upright' ~ 'Upright',\n                                    Condition == 'Familiar_Upright' ~ 'Upright',\n                                    Condition == 'Self_Upright' ~ 'Upright',\n                                    TRUE ~ 'Inverted'))\n\nMean_Frames_long <- Mean_Frames_long %>%\n  mutate(Familiarity = case_when(Condition == 'Unfamiliar_Upright' ~ 'Unfamiliar',\n                                 Condition == 'Unfamiliar_Inverted' ~ 'Unfamiliar',\n                                 Condition == 'Familiar_Upright' ~ 'Familiar',\n                                 Condition == 'Familiar_Inverted' ~ 'Familiar',\n                                 TRUE ~ 'Self'))\n\nMean_Frames_long$Mean_time <- Mean_Frames_long$Mean_N_Frames*(1000/120)\n\nMeanFrames_UF_Upright <- filter(Mean_Frames_long, Condition == 'Unfamiliar_Upright')\nMeanFrames_UF_Inverted <- filter(Mean_Frames_long, Condition == 'Unfamiliar_Inverted')\nMeanFrames_F_Upright<- filter(Mean_Frames_long, Condition == 'Familiar_Upright')\nMeanFrames_F_Inverted <- filter(Mean_Frames_long, Condition == 'Familiar_Inverted')\nMeanFrames_S_Upright<- filter(Mean_Frames_long, Condition == 'Self_Upright')\nMeanFrames_S_Inverted <- filter(Mean_Frames_long, Condition == 'Self_Inverted')\n\ndf_2x3_Time_All <- data_2x2(\n  array_1 = MeanFrames_UF_Upright$Mean_time,\n  array_2 = MeanFrames_UF_Inverted$Mean_time,\n  array_3 = MeanFrames_F_Upright$Mean_time,\n  array_4 = MeanFrames_F_Inverted$Mean_time,\n  array_5 = MeanFrames_S_Upright$Mean_time,\n  array_6 = MeanFrames_S_Inverted$Mean_time,\n  labels = (c('Unfamiliar','Familiar')),\n  jit_distance = .09,\n  jit_seed = 321,\n  # spread_x_ticks = FALSE\n) \n\n\n## Raincloud plot for recognition time \nfaces_2x3_time <- raincloud_2x3_repmes(\n  data = df_2x3_Time_All,\n  colors = c(unfamiliar_upright_col, unfamiliar_inverted_col, familiar_upright_col, familiar_inverted_col, self_upright_col, self_inverted_col),\n  fills = c(unfamiliar_upright_col, unfamiliar_inverted_col, familiar_upright_col, familiar_inverted_col, self_upright_col, self_inverted_col),\n  alpha = .5) +\n  scale_x_continuous(breaks=c(1,2,3), labels=c(\"Unfamiliar\", \"Familiar\", \"Self\"), limits=c(0.5, 4)) +\n  xlab(\"Face Familiarity\") + \n  ylab(\"Mean recognition time (milliseconds)\") +\n  #labs(title = \"Threshold recognition times for face presentation\") +\n  theme_classic()\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\nMean_RTs <- read_csv(\"Mean_Reaction_Times_Familiar_Faces_Filtered.csv\")\n```\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nRows: 28 Columns: 8\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (1): Participant\ndbl (7): Unfamiliar_Upright, Unfamiliar_Inverted, Familiar_Upright, Familiar...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n```\n\n\n:::\n\n```{.r .cell-code .hidden}\nMean_RTs_long <- melt(Mean_RTs, \n                         # ID variables - all the variables to keep but not split apart on\n                         id.vars=c(\"Participant\", \"Age\"),\n                         # The source columns\n                         measure.vars=c(\"Unfamiliar_Upright\", \"Unfamiliar_Inverted\", \n                                        \"Familiar_Upright\", \"Familiar_Inverted\", \n                                        \"Self_Upright\", \"Self_Inverted\"),\n                         # Name of the destination column that will identify the original\n                         # column that the measurement came from\n                         variable.name=\"Condition\",\n                         value.name=\"Mean_RT_secs\"               \n                         \n                         )\n\nMean_RTs_long <- Mean_RTs_long %>%\n  mutate(Orientation = case_when(Condition == 'Unfamiliar_Upright' ~ 'Upright',\n                                    Condition == 'Familiar_Upright' ~ 'Upright',\n                                    Condition == 'Self_Upright' ~ 'Upright',\n                                    TRUE ~ 'Inverted'))\n\nMean_RTs_long <- Mean_RTs_long %>%\n  mutate(Familiarity = case_when(Condition == 'Unfamiliar_Upright' ~ 'Unfamiliar',\n                                 Condition == 'Unfamiliar_Inverted' ~ 'Unfamiliar',\n                                 Condition == 'Familiar_Upright' ~ 'Familiar',\n                                 Condition == 'Familiar_Inverted' ~ 'Familiar',\n                                 TRUE ~ 'Self'))\n\nMean_RTs_long$Mean_RT_ms <- Mean_RTs_long$Mean_RT_secs*(1000)\n\nMeanRTs_UF_Upright <- filter(Mean_RTs_long, Condition == 'Unfamiliar_Upright')\nMeanRTs_UF_Inverted <- filter(Mean_RTs_long, Condition == 'Unfamiliar_Inverted')\nMeanRTs_F_Upright<- filter(Mean_RTs_long, Condition == 'Familiar_Upright')\nMeanRTs_F_Inverted <- filter(Mean_RTs_long, Condition == 'Familiar_Inverted')\nMeanRTs_S_Upright<- filter(Mean_RTs_long, Condition == 'Self_Upright')\nMeanRTs_S_Inverted <- filter(Mean_RTs_long, Condition == 'Self_Inverted')\n\ndf_2x3_RTs_All <- data_2x2(\n  array_1 = MeanRTs_UF_Upright$Mean_RT_ms,\n  array_2 = MeanRTs_UF_Inverted$Mean_RT_ms,\n  array_3 = MeanRTs_F_Upright$Mean_RT_ms,\n  array_4 = MeanRTs_F_Inverted$Mean_RT_ms,\n  array_5 = MeanRTs_S_Upright$Mean_RT_ms,\n  array_6 = MeanRTs_S_Inverted$Mean_RT_ms,\n  labels = (c('Unfamiliar','Familiar')),\n  jit_distance = .09,\n  jit_seed = 321,\n  # spread_x_ticks = FALSE\n) \n\n\n## Raincloud plot for recognition time \nfaces_2x3_RTs <- raincloud_2x3_repmes(\n  data = df_2x3_RTs_All,\n  colors = c(unfamiliar_upright_col, unfamiliar_inverted_col, familiar_upright_col, familiar_inverted_col, self_upright_col, self_inverted_col),\n  fills = c(unfamiliar_upright_col, unfamiliar_inverted_col, familiar_upright_col, familiar_inverted_col, self_upright_col, self_inverted_col),\n  alpha = .5) +\n  scale_x_continuous(breaks=c(1,2,3), labels=c(\"Unfamiliar\", \"Familiar\", \"Self\"), limits=c(0.5, 4)) +\n  xlab(\"Face Familiarity\") + \n  ylab(\"Mean reaction time (milliseconds)\") +\n  #labs(title = \"Mean reaction times for face recognition\") +\n  theme_classic()\n```\n:::\n\n\n# Introduction\n\nFace recognition is the foundation of our social behaviour; it helps us identify the people around us and make inferences about their mood and focus of attention [@burton2015a; @mohr2018a]. It has been estimated that we spend 20$\\%$ of our day looking at faces, and can recognise over 4000 faces during our lifetime [@jenkins2018a; @oruc2019a]. For most of us, the ability to recognise and recall identity-specific information appears to occur almost effortlessly, with studies demonstrating that we can recognise a familiar face as quickly as 360 ms [@besson2016a; @blauch2021a; @oruc2019a; @ramon2016a]. The efficiency with which humans can discriminate within a relatively homogeneous visual category, under constantly changing viewing conditions, has earned us the reputation for being face experts [@collins2018a; @dobs2019a; @kramer2017a; @quek2021a; @rossion_what_2019; @towler_are_2019].\n\nThe precise nature of our face expertise remains poorly understood, with debate around whether the processes that govern face recognition are the same for all faces or whether there are distinct perceptual processes for familiar faces [@abudarham2019a; @blauch2021a; @collins2018a]. Central to the discussion is the idea that there may be a familiarity continuum in face recognition, whereby the brain will respond differently depending on the level of familiarity one has with the face. For example, our friends’ faces are not as familiar to us as our own face, and this difference could change the way the brain encodes and processes a face at the sensory and cognitive level [@bortolon2018a; @rooney2012a; @tong1999a]. Understanding these differences may extend beyond the benefit to basic visual cognition. For example, it is possible that the processes responsible for recognising our own face index other higher-level constructs such as self-esteem and self-identity, which are thought to underlie serious pathologies such as depression, schizophrenia, and bipolar disorder [@felisberti2014a; @oliveira2015a].\n\nThere is abundant evidence that greater levels of familiarity with a person facilitate processing efficiency, as it has been shown that the faces of personally familiar people are processed faster and more accurately than the faces of familiar celebrities, and both have an advantage over strangers faces [@bortolon2017a; @burton2015a; @tong1999a; @young2017a]. Further, changes in viewing conditions have been shown to impede unfamiliar face matching performance whereas recognition of familiar faces is extremely robust to within-identity image variability and low-quality images [@burton2013a; @jenkins2011a; @liccione2014a]. For example, @burton1999a found performance differences in their study which involved showing low resolution CCTV images to familiar and unfamiliar viewers. Unfamiliar viewers were able to accurately identify faces 50$\\%$ of the time, whereas familiar viewers could identify faces almost perfectly, suggesting that the processing of unfamiliar faces may be qualitatively different from familiar faces [@burton1999a]. The familiar face advantage has been observed across a range of image manipulations including face inversion (i.e., turning faces upside down) and geometric distortion (e.g., compressing images of faces) manipulations, highlighting familiarity as an important factor in face recognition [@allen-davidian2021a; @kramer2018a; @yang2014a; @rossion_picture-plane_2008; @hole_effects_2002].\n\nHowever, familiarity is a challenging dimension to explore because its definition is multiplexed, and it is difficult to control in an experimental context. First, there are different levels of familiarity, ranging from recently recently seen and recently learned faces to faces that are familiar but for which we have no personal knowledge (famous people, acquaintances), to the faces of those we know well (family, close friends, self-face; @ramon2011a). Levels of familiarity influence the depth of knowledge and experience we associate with an individual, which likely impacts the underlying mental representation we store in memory [@ramon2017a]. Second, each individual knows a unique collection of faces, which limits the type of stimuli that can be used in research, adding inherent variability in familiarity levels between participants [@ramon2017a]. Third, the way in which faces become familiar can differ. For example, some faces become familiar through interaction with others in our daily lives, and other faces become familiar through repeated exposure (i.e., famous faces or experimentally learned faces). In other words, coming to ‘know’ a person could be different to image-based familiarity [@kramer2018a]. Finally, to reduce noise in data, researchers often manipulate face images (e.g., cropped, hairless, expressionless) which is different to how a face appears under normal circumstances [@burton2011a; @long_database_2023]. These methodological constraints and unique challenges have contributed to the inconsistencies in face research, particularly regarding familiar face recognition performance.\n\n## Measuring Face Recognition\n\nWhile in the real world only familiar faces are recognised, in face research, “face recognition” also describes an individual’s ability to detect a previously unknown face with which they are familiarised during an experimental procedure [@burton2013a; @hancock2000a; @white_individual_2022]. Consistent with the literature, we will conceptualise face recognition as the ability to recognise previously known or recently learned faces (familiar) and previously unknown faces (unfamiliar).\n\nFace recognition has been investigated by recording how long it takes participants to accurately find targets. These tasks often involve participants seeking a target face, where detection is indicated using a go/no-go categorisation [@kloth2006a; @ramon2011a; @tong1999a]. Reaction time data has mostly shown that participants are faster to recognise familiar faces than unfamiliar faces, but reported reaction times vary [@burton2015a; @ramon2011a; @ramon2017a]. For example, @ramon2011a asked participants to accurately categorise 52 images of classmates and strangers using a go/no-go finger lift response and found observers could categorise their classmates within 360 ms, compared to 460 ms to categorise a face as unfamiliar. By contrast, @alzueta2019a asked participants to classify 450 images of their own face, friends, and strangers as quickly as possible using a keyboard button press. Results showed faster reaction times for the self-face (542 ms), but slower reaction times for friends’ faces (570 ms) compared with strangers (562 ms), providing conflicting evidence for the familiar face advantage. Together, findings highlight a common challenge in face recognition research regarding variability in reaction time data as a result of different task demands.\n\nA drawback of relying on average reaction times as a dependent variable is that the data represents the elapsed time from stimulus onset to motor output, combining perceptual processing time, cognitive decision time, and motor response, thus inflating the actual time required to recognise a face [@alzueta2019a; @burton2015a; @caharel2014a]. @taubert2011a overcame this issue in their study by using a staircase procedure to determine minimum exposure time. Their research revealed that participants could accurately discriminate between individual target faces when given 50 ms to view a stimulus [@taubert2011a]. Others have used electroencephalography (EEG) frequency tagging to compare neural responses to face images that progressively increased in image duration, to identify the threshold for successful face recognition [@quek2021a; @dobs_how_2019]. Results showed that exposures as brief as 83 ms enabled observers to consistently recognise familiar (famous) faces from unfamiliar faces [@quek2021a]. Findings of both studies revealed that processing time was much shorter than the reaction times reported in other face recognition studies [@besson2016a; @blauch2021a; @oruc2019a].Here, we employed the same method as @taubert2011a to determine whether different perceptual processes underscore the recognition of familiar and unfamiliar faces.\n\n## Effects of Different Levels of Familiarity on Face Recognition Performance\n\nThe idea that familiar faces may be more easily detected or recognised than unfamiliar faces makes intuitive sense, given the social importance of correctly identifying familiar faces, and the need for humans to efficiently process the enormous amount of visual information we are exposed to in our environment [@tong1999a]. The pursuit of identifying the neural mechanisms underlying the recognition of familiar faces has led to important discoveries regarding distinct processing capacities [@bortolon2017a; @ramon2017a]. There is growing evidence in support of a familiarity continuum in face recognition highlighting processing distinctions not only between unfamiliar and familiar faces, but within the familiar face category itself [@megraya2006a; @murphy2015a; @quek2021a; @wiese2021a].\n\n### Recently Learned Faces\n\nEvidence from behavioural studies has indicated that humans only need brief exposure for face learning to occur, as recently learned faces are more easily matched than unfamiliar faces in face matching tasks [@dowsett2016a; @kramer2017a; @murphy2015a; @quek2021a]. However, unlike recognition of familiar faces, which is robust to changes in viewing conditions such as lighting, viewpoint, and expression, face matching of recently familiar faces is hindered by even slight alterations in the appearance of the face [@burton2011a; @redfern2019a; @megraya2008a; @white2016a]. In addition to perceptual information (e.g., facial features) acquired during face learning, research shows sparse conceptual information (e.g., name and occupation) can aid recognition [@oruc2019a; @schwartz2019a]. @schwartz2016a compared the contribution of perceptual and conceptual information to face recognition performance in their study exposing participants to either perceptual information (manipulating lighting and facial angles) or conceptual information (name, occupation) about target identities. When participants were provided with new images of the same identities and tested on their recognition ability, results showed better recognition following conceptual information compared with perceptual information.\n\n### Personally Familiar Faces\n\nPersonal information acquired through repeated interaction with an identity appears to enhance familiar face recognition, as research shows that our face representations for personally familiar faces differ from those of recently learned faces and familiar celebrity faces [@cloutier2011a; @ramon2017a; @rooney2012a]. @karimi-rouzbahani2021a varied familiarity across stimuli (i.e., unfamiliar, famous, personally familiar, and self) and instructed 18 participants to categorise the stimulus as familiar or unfamiliar using a button press. EEG data, measuring brain electrical activity, showed that higher levels of familiarity (self-face and personally familiar) generated greater transfer of information flow over the visual areas of the brain compared to unfamiliar and famous identities. In contrast, @wiese2021a found substantial EEG event-related potential familiarity effects in response to the self-face, personally familiar faces, and favourite celebrities compared with other celebrities, demonstrating similar processing of personally familiar faces and favourite celebrities.\n\n## Face Processing Efficiency and the Inversion Effect\n\nThe literature provides two interpretations of face processing efficiency. The holistic processing perspective emphasises the importance of analysing the spatial relations between features, providing a unique configuration for each individual so that faces are processed whole, rather than in parts [@sandford2014a; @maurer_many_2002]. Evidence for holistic processing has been demonstrated predominantly in studies showing that when a face is inverted, disrupting its global configuration, participants find it harder to identify target faces [@taubert2011a; @tong1999a]. The face inversion effect has been reliably used in the literature to explore face processing efficiency [ ](Rossion%202008%20Acta%20Psych;%20Valentine%201988;%20Taubert,%20Van%20Belle%20et%20al%202015%20Journal%20of%20Neurophysiology)). Interestingly, studies have revealed that the effects of inversion are greater for unfamiliar faces than familiar faces, suggesting that familiar faces are not a slave to holistic processing [@ramon2016a; @oleggio2017a; @waidmann_local_2022].\n\nBy contrast, the feature-based processing perspective suggests that processing efficiency, as observed with familiar faces, can be attributed to the learning of face features, such as eyes, nose, and mouth, which are then used as unique identifiers supporting processing efficiency [@abudarham2016a]. @lee2022a explored holistic and featural processing effects in a study where participants viewed images of unfamiliar faces, friends’ faces, and the self-face in an inversion task, and a part-whole (isolated features) task. They found no significant difference in inversion effects across the unfamiliar, friend and self-face conditions, whereas, in the isolated features task, participants were faster and more accurate at recognising the self-face compared to friend and unfamiliar faces, suggesting the self-face may be processed in a more feature-based manner. Therefore, the commonly held belief that face recognition relies on holistic processing is being challenged, and it seems likely that not all faces are processed in the same way.\n\n### The Self-face\n\nOur own face is unique, as it plays an influential role in our self-consciousness and identity, and is an important tool for social engagement [@bortolon2018a]. The ‘self-face advantage’ in face recognition has been consistently observed across different contexts and task demands, however, there is conflicting evidence for distinct processing between the self-face and other familiar faces [@alzueta2019a; @tong1999a; @wiese2019a]. For example, @alzueta2019a used EEG to investigate whether the self-face elicits distinct neural processes compared to friends’ and stranger faces. The N170 component, a negative-going EEG potential typically associated with face perception, did not exhibit sensitivity to the self-face, contradicting previous research [@caharel2021a; @wiese2019a]. Findings supported an earlier behavioural study, where 40 participants were asked to attend with a friend and bring five photographs of their own face unseen by their friend. Participants viewed images of themselves, friends, famous, and unfamiliar faces and completed a face matching task [@bortolon2017a]. Results showed participants were better at matching photographs of their own face than famous and unknown faces, but were not faster or more accurate at matching their own face than their friend’s face.\n\nOur understanding of the effects of familiarity on face recognition can be improved by experimenting with personally familiar faces, compared to famous faces, which would better represent familiarity effects as a result of real-world face learning. The self-face is arguably the most familiar face to each of us, and, thus, is an important inclusion in studies seeking to understand the effects of levels of familiarity on facial processing. In addition, exploration of an alternative research method designed to isolate recognition time (i.e., perceptual processes) from reaction time (i.e., perceptual processes + cognitive decision + motor response) is warranted to provide a more precise measure of the perceptual processing time for faces. This information would add value to the debate around whether the brain processes faces differently based on the level of familiarity.\n\n## Aims and Hypotheses\n\nThe purpose of the present study was to investigate the effect of higher levels of face familiarity on face recognition by manipulating both familiarity and orientation while measuring the minimal display time required for recognition (i.e., recognition time) and how quickly participants responded (i.e., reaction time). A staircase procedure was used as an alternative method for characterising face recognition performance. Familiar and unfamiliar faces were presented in both upright and inverted orientations, with the overall expectation that participants would need less time to recognise their own face compared to familiar and unfamiliar faces, and less time to recognise familiar faces compared to unfamiliar faces. Our specific hypotheses were as follows:\n\n1.  Participants will be able to recognise their own faces at shorter face display times compared with less familiar and unfamiliar faces;\n\n2.  Participants will require shorter face display times to recognise a familiar face (that of the experimenter) compared to an unfamiliar face;\n\n3.  Participants will require longer display times to recognise all faces when the face display is inverted;\n\n4.  The face inversion effect (the difference between performance in upright and inverted trials) will be reduced for more familiar faces.\n\n# Method\n\n## Participants\n\nA power analysis using G\\*Power 3.1.9.6 [@faul2009a] determined that a repeated-measures analysis of variance (ANOVA) required 30 participants to reach a power of .90, with an alpha of .05 and an effect size of .15. This effect size was chosen based on previous studies [@campbell2021a; @zimmermann2019a]. This study was approved by the Human Research Ethics Committee (Approval No. HE23-030) at the University of New England (UNE). Written informed consent was obtained from all participants. While 30 participants completed the study, the data for two participants was excluded from the analysis based on the pre-registered exclusion criteria stating that participants will be excluded if their recognition times for the majority of their trials were slower than the starting point face display time (18 frames/66.67ms) for the majority of their trials. The final sample consisted of 28 females aged between 18 and 65 years (M = 43.1, SD = 12.7), recruited through word of mouth and via flyers distributed on campus at the University. Participants signed up using the quick response (QR) code on the flyer, which generated an email to the experimenter. Only female participants were recruited to ensure stimulus consistency across conditions and eliminate gender as a possible biasing factor in face discrimination. The experiment took approximately 45 minutes to complete, and participants were compensated with an AUD \\$25 gift card. All participants had normal or corrected-to-normal vision and no self-reported diagnosed impairment in face perception (e.g., prosopagnosia).\n\n## Design and Stimuli\n\nStimuli were presented on a 22.5-inch (diagonal) VIEWPixx display toolbox, with a display resolution of 1920 (H) x 1200 (V) pixels. Face stimuli were programmed in MATLAB using custom code. Stimuli for the unfamiliar condition consisted of 16 female face identities selected from the NimStim database (the set of calm, neutral faces; @tottenham2009a). Two photographs of the experimenter were used to create a familiar face condition. To create the self-face condition, prior to the experiment, participants were asked to send two photographs of themselves with a neutral expression, without eyewear and with no hair across the face. Several steps were taken to equate image sets across all three conditions. First, the faces were aligned at the eyes and cropped to an oval to exclude hair and clothing. Second, all face identities wore a neutral expression. Third, two images per identity were used so that responses would be more likely to indicate identity processing rather than image-based processing. Fourth, all images were greyscale and root mean square (RMS) normalised for contrast.\n\nThe images were presented within a 128-pixel rectangle and viewed from a distance of 57 centimetres. Faces were presented upright or inverted 180°. To ensure any transients from the onset of stimuli were masked, a mask stream was created using a series of 192-pixel (6°) square patches of randomly-generated noise filtered with a $1/f$ frequency spectrum (see @fig-procedure). A mask stream of 200 ms appeared after each face image in all trials. Face stimuli were randomly offset from trial to trial by between 1 and 32 pixels from their original display location to avoid the effects of low-level feature matching. Trials were presented in random order to reduce any systematic effects of practice on the results. Trials were pilot tested prior to the experiment to determine a starting point of the staircases (18 frames/66.67ms) for each trial.\n\n![The visual stimulation sequence for each trial](images/FamiliarFace_Procedure.png){#fig-procedure}\n\n## Threshold Analysis\n\nIn this study we used a staircase procedure to measure face recognition speed. The staircase began with an easily detected visual display of a target face and distractor face (see @fig-procedure), with the participant’s task being to indicate whether the target face was in the upper or lower part of the display. Subsequent face stimuli display times were reduced until the participant made an error, at which point the staircase reversed so that face stimuli were displayed for longer periods of time until the participant responded correctly, triggering another reversal. Image display times were measured in units of 8.33 millisecond video frames. The staircase used a 1-up-3-down design, where a correct response 3 times in a row generated a reduction in display time by 1 frame. If the participant made an incorrect response, stimulus display times increased by 1 frame. Each condition (unfamiliar, familiar, self-face) included four trials (two with upright faces and two with inverted faces) and each trial included two randomly interleaved staircases. The means of the thresholds for each staircase were averaged to calculate the shortest timeframe in which the face stimuli could be accurately recognised for each condition.\n\n## Procedure\n\nParticipants were verbally briefed on the aim of the research and provided with an information sheet. An overview of the task was described as involving recognition of 12 target faces in a series of displays over the course of the experiment. Participants were seated opposite a desk with the VIEWPixx display screen and a keyboard to complete a practice trial to familiarise themselves with the task (see @fig-setup). The practice trial featured a randomly selected face from the unfamiliar face set, which was then excluded from the main experiment. A random selection of target and distractor faces were chosen for each participant. Before each trial, written instructions appeared on the screen advising participants to focus on a fixation cross at the centre of the screen and use the up and down arrow keys to indicate whether the target face appeared above (up arrow) or below (down arrow) the fixation cross. Participants pressed any key to continue to initiate the display of a ‘target’ face stimulus for five seconds. After the inspection period, participants pressed any key to start the trial. Trials began with a mask stream followed by a display containing the target face and a distractor face above and below the fixation cross. The target face appeared randomly either above or below the fixation cross. Faces were displayed in either an upright or inverted position.\n\n![Depiction of experimental setup; image created by Simone Hale (2023)](images/setup.png){#fig-setup}\n\n# Results\n\n## Data Preparation\n\nData analyses were conducted using jamovi (version 2.3.21.0), with significance levels set to $\\alpha = .05$ for analysis and $\\alpha = .001$ for assumption testing. Data were examined for missing responses and no missingness was found. Two participants were excluded because their threshold scores were consistently above the starting point of the staircases (18 frames/ 66.67ms) for most of their trials. Thus, 28 of the original 30 participants were included in the analyses. Recognition time was measured using the number of frames required to complete the task as determined by the staircase procedure. Frames were then converted to milliseconds based on the monitor refresh rate of 120 Hz. Reaction time was measured in milliseconds.\n\n## Data Analysis\n\nAssumption testing for the two-way repeated-measures analysis of variance (ANOVA) indicated no violated assumptions. Visual inspection of Q-Q plots showed a normal distribution of face recognition times in each condition and no obvious outliers. Homogeneity of variance was assumed, as Fmax scores were below 10, in both upright, $F_{max} = 2.110$, and inverted, $F_{max} = 1.697$, orientations. Mauchly’s test indicated that the assumption of sphericity was not violated for the main effect of condition, $W(28) = 0.82, p = .081$ and the interaction between condition and face orientation, $W(28) = 0.93, p = .399$.\n\nA 2 x 3 repeated-measures analysis of variance (ANOVA) was used to explore the effects of face familiarity on face recognition time. The ANOVA showed a main effect of familiarity, with significant differences in face recognition times between unfamiliar, familiar and self-face conditions $F(2, 52) = 48.08, p < .001, \\eta_p^2 = .649$. In support of the first hypothesis, post hoc comparisons with Bonferroni corrections showed participants recognised their own faces at shorter display times compared with less familiar faces, $t(26) = 3.99, p = .001$, and unfamiliar faces, $t(26) = 11.12, p < .001$. The second hypothesis was also supported, as a post hoc comparison showed participants recognised the familiar face (that of the experimenter) at shorter display times than unfamiliar faces, $t(26) = 5.11, p < .001$.\n\nResults also supported the third hypothesis that participants would require longer display times to recognise all faces when displays were inverted. The ANOVA indicated a main effect of orientation for face recognition times, $F(1, 26) = 50.22, p <.001, \\eta_p^2 = .659$. In addition, the fourth hypothesis was supported: the face inversion effect was reduced for more familiar faces. The ANOVA indicated a significant interaction between condition and face orientation, $F(2, 52) = 11.21, p < .001, \\eta_p^2 = .301$. The effects of inversion on recognition time were reduced when faces were more familiar. @fig-recognition-times shows recognition times for inverted and upright face orientations for each condition.\n\n\n::: {#cell-fig-recognition-times .cell}\n\n```{.r .cell-code .hidden}\nfaces_2x3_time\n```\n\n::: {.cell-output-display}\n![Recognition Times by Orientation for Each Condition](index_files/figure-html/fig-recognition-times-1.png){#fig-recognition-times width=672}\n:::\n:::\n\n\nA small but significant interaction was also observed between age and condition, $F(2, 52) = 4.16, p = .021, \\eta_p^2 = .138$. For older participants, longer display times were required to recognise unfamiliar and familiar faces than younger participants, whereas older participants required relatively shorter display times to recognise the self-face compared to younger participants. @fig-correlations shows this interaction in more detail, illustrating the relationship between age and recognition time in each condition.\n\n\n::: {#cell-fig-correlations .cell}\n\n```{.r .cell-code .hidden}\np1 <- ggplot(Mean_Frames, aes(x=Age, y=Unfamiliar_Upright*(1000/120))) +\n  geom_point(shape=1) +    # Use hollow circles\n  geom_smooth(method=lm,color=\"black\") +  # Add linear regression line \n  #  (by default includes 95% confidence region)\n  labs(x=\"Age\", y = \"Unfamiliar Upright Frame Time (ms)\")+\n  ylim (0, 200)+\n  theme_classic() \n\np2 <- ggplot(Mean_Frames, aes(x=Age, y=Familiar_Upright*(1000/120))) +\n  geom_point(shape=1) +    # Use hollow circles\n  geom_smooth(method=lm,color=\"black\") +  # Add linear regression line \n  #  (by default includes 95% confidence region)\n  labs(x=\"Age\", y = \"Familiar Upright Frame Time (ms)\")+\n  ylim (0, 200)+\n  theme_classic() \n\n\np3 <- ggplot(Mean_Frames, aes(x=Age, y=Self_Upright*(1000/120))) +\n  geom_point(shape=1) +    # Use hollow circles\n  geom_smooth(method=lm,color=\"black\") +  # Add linear regression line \n  #  (by default includes 95% confidence region)\n  labs(x=\"Age\", y = \"Self Upright Frame Time (ms)\")+\n  ylim (0, 200)+\n  theme_classic() \n\n\np4 <- ggplot(Mean_Frames, aes(x=Age, y=Unfamiliar_Inverted*(1000/120))) +\n  geom_point(shape=1) +    # Use hollow circles\n  geom_smooth(method=lm,color=\"black\") +  # Add linear regression line \n  #  (by default includes 95% confidence region)\n  labs(x=\"Age\", y = \"Unfamiliar Inverted Frame Time (ms)\")+\n  ylim (0, 220)+\n  theme_classic() \n\np5 <- ggplot(Mean_Frames, aes(x=Age, y=Familiar_Inverted*(1000/120))) +\n  geom_point(shape=1) +    # Use hollow circles\n  geom_smooth(method=lm,color=\"black\") +  # Add linear regression line \n  #  (by default includes 95% confidence region)\n  labs(x=\"Age\", y = \"Familiar Inverted Frame Time (ms)\")+\n  ylim (0, 220)+\n  theme_classic() \n\n\np6 <- ggplot(Mean_Frames, aes(x=Age, y=Self_Inverted*(1000/120))) +\n  geom_point(shape=1) +    # Use hollow circles\n  geom_smooth(method=lm,color=\"black\") +  # Add linear regression line \n  #  (by default includes 95% confidence region)\n  labs(x=\"Age\", y = \"Self Inverted Frame Time (ms)\")+\n  ylim (0, 220)+\n  theme_classic() \n\np1 + p2 + p3 + p4 + p5 + p6\n```\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\n`geom_smooth()` using formula = 'y ~ x'\n`geom_smooth()` using formula = 'y ~ x'\n`geom_smooth()` using formula = 'y ~ x'\n`geom_smooth()` using formula = 'y ~ x'\n`geom_smooth()` using formula = 'y ~ x'\n`geom_smooth()` using formula = 'y ~ x'\n```\n\n\n:::\n\n::: {.cell-output-display}\n![Correlations between recognition times by age for each condition](index_files/figure-html/fig-correlations-1.png){#fig-correlations width=672}\n:::\n:::\n\n\n## Exploratory Analysis\n\n### Reaction Time\n\nAn identical 2 x 3 repeated measures ANOVA was conducted on participant reaction times (computed as the elapsed time between stimulus presentation and button press), to identify whether reaction times would also reveal a familiarity effect in face recognition. The ANOVA showed a main effect of face condition, with faster reaction times for the more familiar faces, $F(2, 52) = 3.85, p = .028, \\eta_p^2 = .129$. There was also a significant main effect of face orientation, with longer reaction times for inverted faces, $F(1, 26) = 18.71, p <.001, eta_p^2 = .418$. However, there was no significant interaction between condition and face orientation, $F(2, 52) = 0.14, p = .872, eta_p^2) = .005$. @fig-reaction-times shows reaction times for inverted and upright face orientations for each condition.\n\n\n::: {#cell-fig-reaction-times .cell}\n\n```{.r .cell-code .hidden}\nfaces_2x3_RTs\n```\n\n::: {.cell-output-display}\n![Reaction times by orientation for each condition](index_files/figure-html/fig-reaction-times-1.png){#fig-reaction-times width=672}\n:::\n:::\n\n\n# Discussion\n\nTo better understand the effect of greater levels of familiarity on face recognition, the present study used a staircase procedure to characterise face recognition performance. Participants responded to three different face categories manipulated by familiarity (unfamiliar, familiar, and self), and orientation (upright and inverted). Recognition time (i.e., perceptual processes) was isolated from reaction time (i.e., perceptual processes + cognitive decision + motor response) and used as an index of the familiarity effect. The overall findings confirmed predictions that more familiar faces are processed faster than less familiar and unfamiliar faces. Notably, our results underscore the self-face as a unique class of familiar face, providing compelling evidence for distinct perceptual processing.\n\n## Familiarity and Recognition Time\n\nIn support of hypothesis one, participants recognised their own faces at shorter display times compared with other faces, providing evidence for distinct perceptual processing [@alzueta2019a; @rooney2012a]. Results conflicted with an EEG study demonstrating the self-face elicited similar neural responses relative to personally familiar faces [@wiese2021a]. The self-face advantage observed in the recognition times may reflect robust self-representations developed over time, strengthened by both the amount of exposure and the nature of the exposure we have with our own face [@bortolon2017a; @tong1999a]. For example, examining our image in the mirror is a multisensory encounter, allowing us access to motor-sensory and tactile cues that enable us to update our mental representations of ourselves [@bortolon2017a]. Further, research linking self-face recognition and self-esteem revealed that when participants viewed photographs of themselves alongside images that were manipulated to look more attractive, observers chose the manipulated images as more accurate self-representations, which correlated with higher self-esteem [@felisberti2014a]. This tolerance to error, as reflected by the perceptual biases, may be a crucial and distinctive component of self-face representations that could enhance recognition performance [@felisberti2014a].\n\nFamiliarity effects were also found in the shorter display times required to recognise the familiar face (the experimenter) compared to unfamiliar faces, supporting hypothesis two. The findings align with the abundant research evidence in face recognition demonstrating a qualitative and quantitative gap between familiar and unfamiliar face processing [@burton2013a; @burton2016a; @ramon2017a]. It is possible that familiar face recognition performance was strengthened by the opportunity for participants to learn how the experimenter’s face changed in appearance (e.g., different facial expressions and viewing angles), and the conceptual information (e.g., name and research interest) shared prior to the experiment [@dowsett2016a].\n\nThe observation that older participants were faster at recognising their own face compared to younger participants was surprising given the rise in the importance of the “selfie” in popular culture [@tshidzumba2019a]. In line with previous research suggesting that we are better at discriminating faces from our own age group, it is possible that older participants found it easier to distinguish their own face from the distractor faces, which were young identities [@rhodes2012a].\n\n## Familiarity and Inversion Effects\n\nThe present study replicated the face inversion effect, a common finding in previous research that suggests human participants experience more difficulty recognising faces when they are upside down than when they are upright in their canonical orientation. Therefore, these findings support the third hypothesis, that regardless of familiarity, faces are harder to recognise upside down [@allen-davidian2021a; @kramer2018a; @taubert2011a; @young2017a]. This experiment also yielded empirical support for hypothesis four; the face inversion effect was significantly smaller for familiar faces than unfamiliar faces. Interestingly, the more familiar participants were with the face, the more immune they were to the inversion manipulation. This finding is consistent with previous studies that have also suggested that familiar faces are robust to the deleterious effects of inversion [@keyes2012a; @keyes2010a; @yang2014a]. However, results contradicted those of @alzueta2019a, who found no significant change in the size of inversion effects across unfamiliar, familiar and self-face conditions. Inconsistent findings may be explained by the difference in task complexity between the studies. For example, the staircase used in the present study involved finding a target face between two images, displayed for a short period (e.g., 66.67ms starting point), averaging performance across 12 trials, whereas @alzueta2019a allowed participants 1000ms to categorise a single face display as “me”, “friend” or “stranger”, averaging performance across 450 trials.\n\nOverall, these findings provide strong behavioural support for the idea that images of our face are processed differently to other faces, as participants were able to easily recognise their own face in the inverted position in less time than was required to recognise an upright unfamiliar face. The current results challenge the widely accepted view that all human faces are processed holistically, as the faster recognition times for inverted faces in the familiar and self-face conditions could be interpreted as evidence for stronger feature-based representations [@gerlach2022a; @tong1999a].\n\n## Reaction Time and Levels of Familiarity\n\nConsistent with recognition time results and in alignment with the literature, there was a significant difference in reaction times between unfamiliar, familiar and self-face conditions [@kloth2006a; @ramon2011a; @young2017a]. Interestingly, the reaction times were found to be longer than those reported in other studies, which is likely due to the inherent task complexity when using a staircase, compared to more simple, untimed go/no-go face categorisation tasks [@bortolon2017a; @burton2016a; @ramon2011a; @smith2016a].\n\nImportantly, the data revealed that recognition times were substantially shorter than reaction times for each condition. For example, on average, participants recognised (processed) upright familiar faces within 43.8ms but required 547ms to respond (process + decision + motor response) to the target face. These findings have important implications for future research designs, as they suggest that reaction times may be underestimating face recognition performance. Reaction times were longer for inverted faces compared to upright faces, however, the data did not reveal the interaction observed in the recognition time data, as there was no significant difference in the face inversion effect between conditions. Thus, recognition time seems to be a more sensitive measure of familiarity effects in face recognition.\n\n## Future Directions\n\nThe staircase procedure was a key strength of the research, demonstrating that the reaction times reported in research may be underestimating human face recognition ability [@besson2016a; @caharel2014a; @ramon2011a]. However, the study design could be considered difficult to compare with other face recognition research. First, recognition times cannot be directly compared with reaction times. Second, the staircase procedure only measured the ability of participants to discriminate between two stimuli, unlike other studies that require participants to identify a target face among an array of distractor faces [@megraya2006a]. Third, the time constraint imposed by the staircase is not comparable with studies involving tasks without time limits [@zimmermann2019a]. Future studies could attempt to address some of these comparability concerns by replicating the same study together with a standard go/no-go face categorisation task, to allow for a comparison of reaction times between the two tasks. Further, adapting the staircase to include a four-alternative force choice task, rather than the two alternatives used here, would provide a better comparison with studies involving recognition tasks that require discrimination between multiple exemplars. Although the study examined three levels of familiarity (unfamiliar, familiar, and self), other highly familiar faces such as famous faces were not included [@campbell2020a; @wiese2021a]. Future studies could incorporate famous faces and face stimuli of identities that are more intimately known by the perceiver such as close friends and family members, to test the effects of different levels of familiarity on face recognition in both upright and inverted orientations. This would allow further exploration of the inversion effect found in the present study. It would also assist future face recognition research in defining the familiarity construct, particularly with respect to the self-face compared with other highly familiar faces. Further, the varying levels of familiarity participants had with the experimenter created inconsistency in the construct of the familiar condition. Future studies could include a larger sample of both previously unknown and previously known participants to compare the performance of two different levels of familiarity. Including previously unknown participants also provides valuable insight into the effects of real-world face learning on recognition.\n\nFuture research should aim to involve diverse participants, including all genders and representation from all age groups. The female-only sample may have influenced results, as there is some evidence suggesting a female own-gender bias in face recognition performance [@herlitz2013a; @lov2011a; @mishra2019a]. The mean age (43.1 years) in the present study is not reflective of the average age (\\~ 21-35 years) of participants in many other face recognition studies [@kloth2006a; @mohr2018a; @pachai2017a; @platek2009a]. Including a range of age groups is warranted given the age interaction found in the present study and research suggesting an age-bias in face recognition performance [@rhodes2012a].\n\n## Conclusion\n\nOverall, the findings of the present study demonstrate the familiarity advantage in face recognition. We provide strong evidence in support of distinct perceptual processing at different levels of familiarity, as demonstrated by faster recognition times for both the self-face and familiar face compared to unfamiliar faces. The self-face appears to be processed differently to other familiar faces, validating the self-face as an important inclusion in face studies seeking to understand the familiarity effect in face recognition. The staircase procedure provided a unique insight into processing time, highlighting the potential underestimation of face recognition ability in the literature. The finding that face inversion is less disruptive to the processing of more familiar faces is further evidence of distinct perceptual processes and challenges the widely held view that faces are processed holistically. We recommend further exploration of the effects of inversion at different levels of familiarity, to enhance understanding of perceptual processing distinctions, and identify implications for holistic and featural processing theories.\n",
    "supporting": [
      "index_files/figure-html"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}